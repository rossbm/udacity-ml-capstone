{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook train four different models that make use of the pretrained embeddings with 50 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.1 Load Packages and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.join(os.getcwd(), os.pardir)\n",
    "os.chdir(PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import src.neural_networks as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2- Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and validation neural network data sets if they are present, otherwise raise an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load sequnces\n",
    "try:\n",
    "    train = joblib.load('data/processed/train_nn.pkl')\n",
    "    valid = joblib.load('data/processed/valid_nn.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load embedding matrix of 50 dimensions\n",
    "try:\n",
    "    embedding_matrix50 = joblib.load('data/interim/embeddings50.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load embedding matrix of 300 dimensions\n",
    "try:\n",
    "    embedding_matrix300 = joblib.load('data/interim/embeddings300.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Run 50d models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these arguments will be the same when creating all four 50d models\n",
    "model_args = {\"embedding_matrix\":embedding_matrix50,\n",
    "             \"n_hidden\":250}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - LSTM + Averaged Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "joke_seq (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 50)           1369800   \n",
      "_________________________________________________________________\n",
      "mask_paddings (Masking)      (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "drop_words (SpatialDropout1D (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "rnn (LSTM)                   (None, 250)               301000    \n",
      "_________________________________________________________________\n",
      "avg_pred (GlobalAverage)     (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,670,800\n",
      "Trainable params: 301,000\n",
      "Non-trainable params: 1,369,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM, average final\n",
    "model = nn.create_model(rnn_type=\"LSTM\",\n",
    "                     dense_final=False,\n",
    "                     **model_args)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these arguments will be the same when running all four models\n",
    "run_args = {\"train\":(train[\"seqs\"],train[\"labels\"]),\n",
    "            \"valid\":(valid[\"seqs\"],valid[\"labels\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171945 samples, validate on 24564 samples\n",
      "Epoch 1/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6785 - acc: 0.5628Epoch 00001: val_loss improved from inf to 0.65602, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 178s 1ms/step - loss: 0.6782 - acc: 0.5633 - val_loss: 0.6560 - val_acc: 0.5986\n",
      "Epoch 2/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6579 - acc: 0.6001Epoch 00002: val_loss improved from 0.65602 to 0.65316, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 134s 777us/step - loss: 0.6579 - acc: 0.6002 - val_loss: 0.6532 - val_acc: 0.6036\n",
      "Epoch 3/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6555 - acc: 0.6028Epoch 00003: val_loss improved from 0.65316 to 0.65258, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 131s 765us/step - loss: 0.6555 - acc: 0.6026 - val_loss: 0.6526 - val_acc: 0.6050\n",
      "Epoch 4/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6546 - acc: 0.6050Epoch 00004: val_loss improved from 0.65258 to 0.65155, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 131s 760us/step - loss: 0.6546 - acc: 0.6051 - val_loss: 0.6515 - val_acc: 0.6071\n",
      "Epoch 5/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6537 - acc: 0.6065Epoch 00005: val_loss improved from 0.65155 to 0.65095, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 131s 764us/step - loss: 0.6537 - acc: 0.6066 - val_loss: 0.6510 - val_acc: 0.6057\n",
      "Epoch 6/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6538 - acc: 0.6061Epoch 00006: val_loss improved from 0.65095 to 0.65036, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 758us/step - loss: 0.6540 - acc: 0.6059 - val_loss: 0.6504 - val_acc: 0.6099\n",
      "Epoch 7/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6530 - acc: 0.6077Epoch 00007: val_loss improved from 0.65036 to 0.64950, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 758us/step - loss: 0.6530 - acc: 0.6078 - val_loss: 0.6495 - val_acc: 0.6108\n",
      "Epoch 8/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6521 - acc: 0.6081Epoch 00008: val_loss improved from 0.64950 to 0.64870, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 758us/step - loss: 0.6522 - acc: 0.6080 - val_loss: 0.6487 - val_acc: 0.6111\n",
      "Epoch 9/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6517 - acc: 0.6088Epoch 00009: val_loss improved from 0.64870 to 0.64837, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6518 - acc: 0.6088 - val_loss: 0.6484 - val_acc: 0.6111\n",
      "Epoch 10/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6509 - acc: 0.6108Epoch 00010: val_loss improved from 0.64837 to 0.64735, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6508 - acc: 0.6108 - val_loss: 0.6474 - val_acc: 0.6146\n",
      "Epoch 11/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6504 - acc: 0.6113Epoch 00011: val_loss improved from 0.64735 to 0.64701, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6505 - acc: 0.6112 - val_loss: 0.6470 - val_acc: 0.6137\n",
      "Epoch 12/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6504 - acc: 0.6123Epoch 00012: val_loss improved from 0.64701 to 0.64606, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6504 - acc: 0.6124 - val_loss: 0.6461 - val_acc: 0.6142\n",
      "Epoch 13/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6499 - acc: 0.6112Epoch 00013: val_loss improved from 0.64606 to 0.64561, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 758us/step - loss: 0.6498 - acc: 0.6112 - val_loss: 0.6456 - val_acc: 0.6153\n",
      "Epoch 14/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6496 - acc: 0.6111Epoch 00014: val_loss improved from 0.64561 to 0.64499, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 758us/step - loss: 0.6496 - acc: 0.6111 - val_loss: 0.6450 - val_acc: 0.6155\n",
      "Epoch 15/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6484 - acc: 0.6138Epoch 00015: val_loss improved from 0.64499 to 0.64413, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 758us/step - loss: 0.6484 - acc: 0.6137 - val_loss: 0.6441 - val_acc: 0.6157\n",
      "Epoch 16/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6486 - acc: 0.6123Epoch 00016: val_loss improved from 0.64413 to 0.64412, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 758us/step - loss: 0.6484 - acc: 0.6125 - val_loss: 0.6441 - val_acc: 0.6158\n",
      "Epoch 17/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6479 - acc: 0.6144Epoch 00017: val_loss improved from 0.64412 to 0.64327, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 758us/step - loss: 0.6478 - acc: 0.6145 - val_loss: 0.6433 - val_acc: 0.6172\n",
      "Epoch 18/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6476 - acc: 0.6135Epoch 00018: val_loss improved from 0.64327 to 0.64292, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 758us/step - loss: 0.6476 - acc: 0.6135 - val_loss: 0.6429 - val_acc: 0.6191\n",
      "Epoch 19/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6474 - acc: 0.6157Epoch 00019: val_loss improved from 0.64292 to 0.64292, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 759us/step - loss: 0.6474 - acc: 0.6155 - val_loss: 0.6429 - val_acc: 0.6192\n",
      "Epoch 20/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6463 - acc: 0.6156Epoch 00020: val_loss improved from 0.64292 to 0.64199, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 755us/step - loss: 0.6463 - acc: 0.6156 - val_loss: 0.6420 - val_acc: 0.6210\n",
      "Epoch 21/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6460 - acc: 0.6178Epoch 00021: val_loss improved from 0.64199 to 0.64157, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 755us/step - loss: 0.6460 - acc: 0.6178 - val_loss: 0.6416 - val_acc: 0.6187\n",
      "Epoch 22/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6457 - acc: 0.6181Epoch 00022: val_loss improved from 0.64157 to 0.64108, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 755us/step - loss: 0.6456 - acc: 0.6181 - val_loss: 0.6411 - val_acc: 0.6246\n",
      "Epoch 23/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6455 - acc: 0.6174Epoch 00023: val_loss improved from 0.64108 to 0.64070, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 755us/step - loss: 0.6455 - acc: 0.6174 - val_loss: 0.6407 - val_acc: 0.6213\n",
      "Epoch 24/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6449 - acc: 0.6179Epoch 00024: val_loss improved from 0.64070 to 0.64009, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6449 - acc: 0.6179 - val_loss: 0.6401 - val_acc: 0.6240\n",
      "Epoch 25/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6444 - acc: 0.6196Epoch 00025: val_loss improved from 0.64009 to 0.63949, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 755us/step - loss: 0.6444 - acc: 0.6195 - val_loss: 0.6395 - val_acc: 0.6243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6443 - acc: 0.6195Epoch 00026: val_loss improved from 0.63949 to 0.63882, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6442 - acc: 0.6196 - val_loss: 0.6388 - val_acc: 0.6264\n",
      "Epoch 27/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6440 - acc: 0.6208Epoch 00027: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6441 - acc: 0.6207 - val_loss: 0.6391 - val_acc: 0.6249\n",
      "Epoch 28/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6434 - acc: 0.6214Epoch 00028: val_loss improved from 0.63882 to 0.63817, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6434 - acc: 0.6214 - val_loss: 0.6382 - val_acc: 0.6277\n",
      "Epoch 29/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6437 - acc: 0.6208Epoch 00029: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6436 - acc: 0.6209 - val_loss: 0.6391 - val_acc: 0.6256\n",
      "Epoch 30/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6433 - acc: 0.6210Epoch 00030: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6432 - acc: 0.6210 - val_loss: 0.6393 - val_acc: 0.6249\n",
      "Epoch 31/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6430 - acc: 0.6212Epoch 00031: val_loss improved from 0.63817 to 0.63743, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6429 - acc: 0.6215 - val_loss: 0.6374 - val_acc: 0.6308\n",
      "Epoch 32/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6431 - acc: 0.6211Epoch 00032: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6430 - acc: 0.6211 - val_loss: 0.6376 - val_acc: 0.6300\n",
      "Epoch 33/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6429 - acc: 0.6214Epoch 00033: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6427 - acc: 0.6216 - val_loss: 0.6390 - val_acc: 0.6246\n",
      "Epoch 34/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6423 - acc: 0.6233Epoch 00034: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 755us/step - loss: 0.6423 - acc: 0.6232 - val_loss: 0.6381 - val_acc: 0.6297\n",
      "Epoch 35/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6425 - acc: 0.6221Epoch 00035: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6425 - acc: 0.6222 - val_loss: 0.6381 - val_acc: 0.6302\n",
      "Epoch 36/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6410 - acc: 0.6241Epoch 00036: val_loss improved from 0.63743 to 0.63601, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6410 - acc: 0.6240 - val_loss: 0.6360 - val_acc: 0.6319\n",
      "Epoch 37/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6413 - acc: 0.6240Epoch 00037: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6413 - acc: 0.6239 - val_loss: 0.6361 - val_acc: 0.6313\n",
      "Epoch 38/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6413 - acc: 0.6246Epoch 00038: val_loss improved from 0.63601 to 0.63572, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6414 - acc: 0.6245 - val_loss: 0.6357 - val_acc: 0.6317\n",
      "Epoch 39/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6411 - acc: 0.6237Epoch 00039: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6411 - acc: 0.6238 - val_loss: 0.6364 - val_acc: 0.6316\n",
      "Epoch 40/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6410 - acc: 0.6252Epoch 00040: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 755us/step - loss: 0.6410 - acc: 0.6252 - val_loss: 0.6359 - val_acc: 0.6312\n",
      "Epoch 41/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6401 - acc: 0.6251Epoch 00041: val_loss improved from 0.63572 to 0.63523, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6402 - acc: 0.6251 - val_loss: 0.6352 - val_acc: 0.6339\n",
      "Epoch 42/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6398 - acc: 0.6256Epoch 00042: val_loss improved from 0.63523 to 0.63518, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6398 - acc: 0.6255 - val_loss: 0.6352 - val_acc: 0.6345\n",
      "Epoch 43/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6403 - acc: 0.6252Epoch 00043: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6403 - acc: 0.6252 - val_loss: 0.6353 - val_acc: 0.6334\n",
      "Epoch 44/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6398 - acc: 0.6265Epoch 00044: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 755us/step - loss: 0.6398 - acc: 0.6264 - val_loss: 0.6361 - val_acc: 0.6322\n",
      "Epoch 45/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6395 - acc: 0.6274Epoch 00045: val_loss improved from 0.63518 to 0.63443, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6395 - acc: 0.6275 - val_loss: 0.6344 - val_acc: 0.6343\n",
      "Epoch 46/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6395 - acc: 0.6262Epoch 00046: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6394 - acc: 0.6264 - val_loss: 0.6350 - val_acc: 0.6356\n",
      "Epoch 47/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6393 - acc: 0.6272Epoch 00047: val_loss improved from 0.63443 to 0.63380, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6393 - acc: 0.6272 - val_loss: 0.6338 - val_acc: 0.6385\n",
      "Epoch 48/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6385 - acc: 0.6288Epoch 00048: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6385 - acc: 0.6287 - val_loss: 0.6340 - val_acc: 0.6380\n",
      "Epoch 49/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6389 - acc: 0.6274Epoch 00049: val_loss improved from 0.63380 to 0.63305, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 755us/step - loss: 0.6390 - acc: 0.6273 - val_loss: 0.6331 - val_acc: 0.6379\n",
      "Epoch 50/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6382 - acc: 0.6290Epoch 00050: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6382 - acc: 0.6289 - val_loss: 0.6333 - val_acc: 0.6384\n",
      "Epoch 51/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6382 - acc: 0.6291Epoch 00051: val_loss improved from 0.63305 to 0.63296, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6382 - acc: 0.6291 - val_loss: 0.6330 - val_acc: 0.6389\n",
      "Epoch 52/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6384 - acc: 0.6291Epoch 00052: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6383 - acc: 0.6292 - val_loss: 0.6346 - val_acc: 0.6364\n",
      "Epoch 53/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6381 - acc: 0.6278Epoch 00053: val_loss improved from 0.63296 to 0.63253, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6382 - acc: 0.6278 - val_loss: 0.6325 - val_acc: 0.6398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6377 - acc: 0.6294Epoch 00054: val_loss improved from 0.63253 to 0.63241, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6376 - acc: 0.6294 - val_loss: 0.6324 - val_acc: 0.6390\n",
      "Epoch 55/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6380 - acc: 0.6298Epoch 00055: val_loss improved from 0.63241 to 0.63217, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6380 - acc: 0.6298 - val_loss: 0.6322 - val_acc: 0.6394\n",
      "Epoch 56/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6379 - acc: 0.6301Epoch 00056: val_loss improved from 0.63217 to 0.63215, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6378 - acc: 0.6303 - val_loss: 0.6322 - val_acc: 0.6397\n",
      "Epoch 57/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6371 - acc: 0.6305Epoch 00057: val_loss improved from 0.63215 to 0.63176, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6371 - acc: 0.6305 - val_loss: 0.6318 - val_acc: 0.6410\n",
      "Epoch 58/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6371 - acc: 0.6298Epoch 00058: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6371 - acc: 0.6298 - val_loss: 0.6321 - val_acc: 0.6406\n",
      "Epoch 59/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6366 - acc: 0.6311Epoch 00059: val_loss improved from 0.63176 to 0.63099, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6365 - acc: 0.6310 - val_loss: 0.6310 - val_acc: 0.6403\n",
      "Epoch 60/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6365 - acc: 0.6325Epoch 00060: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6364 - acc: 0.6326 - val_loss: 0.6311 - val_acc: 0.6413\n",
      "Epoch 61/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6365 - acc: 0.6318Epoch 00061: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6365 - acc: 0.6318 - val_loss: 0.6311 - val_acc: 0.6421\n",
      "Epoch 62/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6357 - acc: 0.6331Epoch 00062: val_loss improved from 0.63099 to 0.63090, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6358 - acc: 0.6329 - val_loss: 0.6309 - val_acc: 0.6430\n",
      "Epoch 63/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6359 - acc: 0.6307Epoch 00063: val_loss improved from 0.63090 to 0.63072, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6359 - acc: 0.6308 - val_loss: 0.6307 - val_acc: 0.6429\n",
      "Epoch 64/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6351 - acc: 0.6333Epoch 00064: val_loss improved from 0.63072 to 0.63023, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6352 - acc: 0.6331 - val_loss: 0.6302 - val_acc: 0.6421\n",
      "Epoch 65/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6357 - acc: 0.6328Epoch 00065: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6357 - acc: 0.6328 - val_loss: 0.6302 - val_acc: 0.6438\n",
      "Epoch 66/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6354 - acc: 0.6326Epoch 00066: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6356 - acc: 0.6326 - val_loss: 0.6305 - val_acc: 0.6421\n",
      "Epoch 67/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6350 - acc: 0.6339Epoch 00067: val_loss improved from 0.63023 to 0.62993, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6348 - acc: 0.6342 - val_loss: 0.6299 - val_acc: 0.6442\n",
      "Epoch 68/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6353 - acc: 0.6333Epoch 00068: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6352 - acc: 0.6333 - val_loss: 0.6312 - val_acc: 0.6435\n",
      "Epoch 69/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6346 - acc: 0.6356Epoch 00069: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6345 - acc: 0.6357 - val_loss: 0.6305 - val_acc: 0.6427\n",
      "Epoch 70/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6350 - acc: 0.6333Epoch 00070: val_loss improved from 0.62993 to 0.62890, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 755us/step - loss: 0.6349 - acc: 0.6334 - val_loss: 0.6289 - val_acc: 0.6436\n",
      "Epoch 71/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6342 - acc: 0.6350Epoch 00071: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6342 - acc: 0.6349 - val_loss: 0.6293 - val_acc: 0.6442\n",
      "Epoch 72/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6345 - acc: 0.6357Epoch 00072: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6344 - acc: 0.6358 - val_loss: 0.6297 - val_acc: 0.6448\n",
      "Epoch 73/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6341 - acc: 0.6346Epoch 00073: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6340 - acc: 0.6346 - val_loss: 0.6292 - val_acc: 0.6424\n",
      "Epoch 74/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6337 - acc: 0.6355Epoch 00074: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6338 - acc: 0.6354 - val_loss: 0.6301 - val_acc: 0.6459\n",
      "Epoch 75/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6342 - acc: 0.6353Epoch 00075: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6340 - acc: 0.6356 - val_loss: 0.6301 - val_acc: 0.6427\n",
      "Epoch 76/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6335 - acc: 0.6363Epoch 00076: val_loss improved from 0.62890 to 0.62830, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6335 - acc: 0.6363 - val_loss: 0.6283 - val_acc: 0.6460\n",
      "Epoch 77/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6330 - acc: 0.6368Epoch 00077: val_loss improved from 0.62830 to 0.62816, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6330 - acc: 0.6368 - val_loss: 0.6282 - val_acc: 0.6450\n",
      "Epoch 78/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6331 - acc: 0.6370Epoch 00078: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 758us/step - loss: 0.6331 - acc: 0.6369 - val_loss: 0.6298 - val_acc: 0.6449\n",
      "Epoch 79/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6329 - acc: 0.6364Epoch 00079: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6329 - acc: 0.6364 - val_loss: 0.6285 - val_acc: 0.6462\n",
      "Epoch 80/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6327 - acc: 0.6375Epoch 00080: val_loss improved from 0.62816 to 0.62722, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6327 - acc: 0.6376 - val_loss: 0.6272 - val_acc: 0.6458\n",
      "Epoch 81/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6324 - acc: 0.6377Epoch 00081: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6324 - acc: 0.6377 - val_loss: 0.6275 - val_acc: 0.6465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6326 - acc: 0.6378Epoch 00082: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6327 - acc: 0.6378 - val_loss: 0.6273 - val_acc: 0.6461\n",
      "Epoch 83/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6316 - acc: 0.6399Epoch 00083: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6315 - acc: 0.6399 - val_loss: 0.6321 - val_acc: 0.6374\n",
      "Epoch 84/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6325 - acc: 0.6379Epoch 00084: val_loss improved from 0.62722 to 0.62657, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6326 - acc: 0.6379 - val_loss: 0.6266 - val_acc: 0.6481\n",
      "Epoch 85/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6317 - acc: 0.6395Epoch 00085: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6316 - acc: 0.6395 - val_loss: 0.6272 - val_acc: 0.6486\n",
      "Epoch 86/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6317 - acc: 0.6382Epoch 00086: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6316 - acc: 0.6382 - val_loss: 0.6274 - val_acc: 0.6471\n",
      "Epoch 87/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6316 - acc: 0.6397Epoch 00087: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6315 - acc: 0.6399 - val_loss: 0.6285 - val_acc: 0.6453\n",
      "Epoch 88/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6310 - acc: 0.6389Epoch 00088: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6311 - acc: 0.6387 - val_loss: 0.6271 - val_acc: 0.6475\n",
      "Epoch 89/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6310 - acc: 0.6393Epoch 00089: val_loss improved from 0.62657 to 0.62575, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6311 - acc: 0.6392 - val_loss: 0.6257 - val_acc: 0.6494\n",
      "Epoch 90/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6309 - acc: 0.6394Epoch 00090: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6308 - acc: 0.6397 - val_loss: 0.6271 - val_acc: 0.6458\n",
      "Epoch 91/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6304 - acc: 0.6408Epoch 00091: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6304 - acc: 0.6408 - val_loss: 0.6264 - val_acc: 0.6480\n",
      "Epoch 92/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6303 - acc: 0.6412Epoch 00092: val_loss improved from 0.62575 to 0.62522, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6302 - acc: 0.6414 - val_loss: 0.6252 - val_acc: 0.6475\n",
      "Epoch 93/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6299 - acc: 0.6418Epoch 00093: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6299 - acc: 0.6418 - val_loss: 0.6253 - val_acc: 0.6524\n",
      "Epoch 94/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6301 - acc: 0.6404Epoch 00094: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6302 - acc: 0.6403 - val_loss: 0.6254 - val_acc: 0.6495\n",
      "Epoch 95/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6302 - acc: 0.6413Epoch 00095: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6301 - acc: 0.6415 - val_loss: 0.6254 - val_acc: 0.6495\n",
      "Epoch 96/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6295 - acc: 0.6425Epoch 00096: val_loss improved from 0.62522 to 0.62485, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6294 - acc: 0.6426 - val_loss: 0.6248 - val_acc: 0.6506\n",
      "Epoch 97/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6290 - acc: 0.6426Epoch 00097: val_loss improved from 0.62485 to 0.62447, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6290 - acc: 0.6425 - val_loss: 0.6245 - val_acc: 0.6516\n",
      "Epoch 98/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6291 - acc: 0.6429Epoch 00098: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6291 - acc: 0.6429 - val_loss: 0.6286 - val_acc: 0.6437\n",
      "Epoch 99/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6294 - acc: 0.6431Epoch 00099: val_loss improved from 0.62447 to 0.62390, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6293 - acc: 0.6432 - val_loss: 0.6239 - val_acc: 0.6491\n",
      "Epoch 100/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6293 - acc: 0.6428Epoch 00100: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6292 - acc: 0.6430 - val_loss: 0.6241 - val_acc: 0.6528\n",
      "Epoch 101/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6285 - acc: 0.6427Epoch 00101: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6285 - acc: 0.6427 - val_loss: 0.6244 - val_acc: 0.6518\n",
      "Epoch 102/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6286 - acc: 0.6441Epoch 00102: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6285 - acc: 0.6443 - val_loss: 0.6247 - val_acc: 0.6488\n",
      "Epoch 103/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6284 - acc: 0.6440Epoch 00103: val_loss improved from 0.62390 to 0.62364, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6284 - acc: 0.6439 - val_loss: 0.6236 - val_acc: 0.6497\n",
      "Epoch 104/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6276 - acc: 0.6438Epoch 00104: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6276 - acc: 0.6437 - val_loss: 0.6254 - val_acc: 0.6484\n",
      "Epoch 105/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6275 - acc: 0.6459Epoch 00105: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6274 - acc: 0.6459 - val_loss: 0.6238 - val_acc: 0.6512\n",
      "Epoch 106/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6282 - acc: 0.6430Epoch 00106: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6282 - acc: 0.6430 - val_loss: 0.6241 - val_acc: 0.6502\n",
      "Epoch 107/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6275 - acc: 0.6435Epoch 00107: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6275 - acc: 0.6437 - val_loss: 0.6252 - val_acc: 0.6485\n",
      "Epoch 108/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6273 - acc: 0.6446Epoch 00108: val_loss improved from 0.62364 to 0.62286, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6274 - acc: 0.6446 - val_loss: 0.6229 - val_acc: 0.6529\n",
      "Epoch 109/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6273 - acc: 0.6457Epoch 00109: val_loss improved from 0.62286 to 0.62260, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6272 - acc: 0.6458 - val_loss: 0.6226 - val_acc: 0.6531\n",
      "Epoch 110/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6269 - acc: 0.6451Epoch 00110: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6269 - acc: 0.6452 - val_loss: 0.6234 - val_acc: 0.6509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6269 - acc: 0.6468Epoch 00111: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6268 - acc: 0.6469 - val_loss: 0.6228 - val_acc: 0.6533\n",
      "Epoch 112/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6264 - acc: 0.6458Epoch 00112: val_loss improved from 0.62260 to 0.62251, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6264 - acc: 0.6458 - val_loss: 0.6225 - val_acc: 0.6533\n",
      "Epoch 113/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6263 - acc: 0.6466Epoch 00113: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6263 - acc: 0.6465 - val_loss: 0.6225 - val_acc: 0.6533\n",
      "Epoch 114/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6261 - acc: 0.6466Epoch 00114: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6262 - acc: 0.6466 - val_loss: 0.6231 - val_acc: 0.6521\n",
      "Epoch 115/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6261 - acc: 0.6475Epoch 00115: val_loss improved from 0.62251 to 0.62187, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6259 - acc: 0.6477 - val_loss: 0.6219 - val_acc: 0.6547\n",
      "Epoch 116/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6253 - acc: 0.6468Epoch 00116: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6253 - acc: 0.6469 - val_loss: 0.6221 - val_acc: 0.6521\n",
      "Epoch 117/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6255 - acc: 0.6476Epoch 00117: val_loss improved from 0.62187 to 0.62156, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6255 - acc: 0.6476 - val_loss: 0.6216 - val_acc: 0.6542\n",
      "Epoch 118/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6250 - acc: 0.6487Epoch 00118: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6250 - acc: 0.6485 - val_loss: 0.6232 - val_acc: 0.6511\n",
      "Epoch 119/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6256 - acc: 0.6480Epoch 00119: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6255 - acc: 0.6479 - val_loss: 0.6220 - val_acc: 0.6519\n",
      "Epoch 120/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6253 - acc: 0.6483Epoch 00120: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6252 - acc: 0.6484 - val_loss: 0.6216 - val_acc: 0.6545\n",
      "Epoch 121/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6252 - acc: 0.6467Epoch 00121: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6251 - acc: 0.6467 - val_loss: 0.6225 - val_acc: 0.6525\n",
      "Epoch 122/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6241 - acc: 0.6498Epoch 00122: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6242 - acc: 0.6496 - val_loss: 0.6217 - val_acc: 0.6532\n",
      "Epoch 123/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6250 - acc: 0.6482Epoch 00123: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6250 - acc: 0.6483 - val_loss: 0.6271 - val_acc: 0.6450\n",
      "Epoch 124/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6242 - acc: 0.6498Epoch 00124: val_loss improved from 0.62156 to 0.62075, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6244 - acc: 0.6496 - val_loss: 0.6208 - val_acc: 0.6538\n",
      "Epoch 125/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6240 - acc: 0.6498Epoch 00125: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6240 - acc: 0.6498 - val_loss: 0.6225 - val_acc: 0.6538\n",
      "Epoch 126/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6237 - acc: 0.6500Epoch 00126: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6237 - acc: 0.6500 - val_loss: 0.6211 - val_acc: 0.6542\n",
      "Epoch 127/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6235 - acc: 0.6503Epoch 00127: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6235 - acc: 0.6504 - val_loss: 0.6241 - val_acc: 0.6491\n",
      "Epoch 128/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6236 - acc: 0.6518Epoch 00128: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6238 - acc: 0.6516 - val_loss: 0.6209 - val_acc: 0.6521\n",
      "Epoch 129/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6229 - acc: 0.6525Epoch 00129: val_loss improved from 0.62075 to 0.62058, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6229 - acc: 0.6525 - val_loss: 0.6206 - val_acc: 0.6535\n",
      "Epoch 130/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6237 - acc: 0.6495Epoch 00130: val_loss improved from 0.62058 to 0.61947, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6237 - acc: 0.6494 - val_loss: 0.6195 - val_acc: 0.6547\n",
      "Epoch 131/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6223 - acc: 0.6519Epoch 00131: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6225 - acc: 0.6515 - val_loss: 0.6196 - val_acc: 0.6553\n",
      "Epoch 132/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6225 - acc: 0.6523Epoch 00132: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6224 - acc: 0.6523 - val_loss: 0.6214 - val_acc: 0.6528\n",
      "Epoch 133/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6225 - acc: 0.6511Epoch 00133: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6225 - acc: 0.6510 - val_loss: 0.6224 - val_acc: 0.6525\n",
      "Epoch 134/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6223 - acc: 0.6510Epoch 00134: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6223 - acc: 0.6509 - val_loss: 0.6224 - val_acc: 0.6511\n",
      "Epoch 135/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6215 - acc: 0.6514Epoch 00135: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6215 - acc: 0.6515 - val_loss: 0.6215 - val_acc: 0.6536\n",
      "Epoch 136/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6219 - acc: 0.6524Epoch 00136: val_loss improved from 0.61947 to 0.61888, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6219 - acc: 0.6525 - val_loss: 0.6189 - val_acc: 0.6569\n",
      "Epoch 137/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6221 - acc: 0.6525Epoch 00137: val_loss improved from 0.61888 to 0.61886, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6221 - acc: 0.6524 - val_loss: 0.6189 - val_acc: 0.6567\n",
      "Epoch 138/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6220 - acc: 0.6527Epoch 00138: val_loss improved from 0.61886 to 0.61847, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6219 - acc: 0.6528 - val_loss: 0.6185 - val_acc: 0.6563\n",
      "Epoch 139/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6226 - acc: 0.6513Epoch 00139: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6226 - acc: 0.6514 - val_loss: 0.6188 - val_acc: 0.6560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6216 - acc: 0.6537Epoch 00140: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6215 - acc: 0.6539 - val_loss: 0.6187 - val_acc: 0.6566\n",
      "Epoch 141/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6216 - acc: 0.6524Epoch 00141: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6216 - acc: 0.6524 - val_loss: 0.6221 - val_acc: 0.6523\n",
      "Epoch 142/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6208 - acc: 0.6553Epoch 00142: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6206 - acc: 0.6555 - val_loss: 0.6188 - val_acc: 0.6554\n",
      "Epoch 143/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6209 - acc: 0.6537Epoch 00143: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6210 - acc: 0.6535 - val_loss: 0.6191 - val_acc: 0.6562\n",
      "Epoch 144/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6206 - acc: 0.6525Epoch 00144: val_loss improved from 0.61847 to 0.61823, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6205 - acc: 0.6526 - val_loss: 0.6182 - val_acc: 0.6578\n",
      "Epoch 145/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6212 - acc: 0.6528Epoch 00145: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6212 - acc: 0.6529 - val_loss: 0.6205 - val_acc: 0.6538\n",
      "Epoch 146/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6204 - acc: 0.6543Epoch 00146: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6202 - acc: 0.6544 - val_loss: 0.6210 - val_acc: 0.6509\n",
      "Epoch 147/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6201 - acc: 0.6547Epoch 00147: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6201 - acc: 0.6548 - val_loss: 0.6226 - val_acc: 0.6516\n",
      "Epoch 148/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6200 - acc: 0.6548Epoch 00148: val_loss improved from 0.61823 to 0.61756, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6199 - acc: 0.6548 - val_loss: 0.6176 - val_acc: 0.6575\n",
      "Epoch 149/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6194 - acc: 0.6557Epoch 00149: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6194 - acc: 0.6556 - val_loss: 0.6232 - val_acc: 0.6501\n",
      "Epoch 150/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6199 - acc: 0.6560Epoch 00150: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6199 - acc: 0.6559 - val_loss: 0.6180 - val_acc: 0.6573\n",
      "Epoch 151/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6193 - acc: 0.6565Epoch 00151: val_loss improved from 0.61756 to 0.61729, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6192 - acc: 0.6568 - val_loss: 0.6173 - val_acc: 0.6585\n",
      "Epoch 152/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6196 - acc: 0.6545Epoch 00152: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6195 - acc: 0.6546 - val_loss: 0.6178 - val_acc: 0.6583\n",
      "Epoch 153/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6189 - acc: 0.6571Epoch 00153: val_loss improved from 0.61729 to 0.61682, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6190 - acc: 0.6570 - val_loss: 0.6168 - val_acc: 0.6586\n",
      "Epoch 154/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6186 - acc: 0.6563Epoch 00154: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6186 - acc: 0.6563 - val_loss: 0.6169 - val_acc: 0.6582\n",
      "Epoch 155/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6187 - acc: 0.6552Epoch 00155: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6185 - acc: 0.6554 - val_loss: 0.6207 - val_acc: 0.6555\n",
      "Epoch 156/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6186 - acc: 0.6574Epoch 00156: val_loss improved from 0.61682 to 0.61678, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6185 - acc: 0.6575 - val_loss: 0.6168 - val_acc: 0.6588\n",
      "Epoch 157/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6182 - acc: 0.6572Epoch 00157: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6183 - acc: 0.6570 - val_loss: 0.6226 - val_acc: 0.6497\n",
      "Epoch 158/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6188 - acc: 0.6564Epoch 00158: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6187 - acc: 0.6566 - val_loss: 0.6197 - val_acc: 0.6558\n",
      "Epoch 159/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6181 - acc: 0.6581Epoch 00159: val_loss improved from 0.61678 to 0.61588, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6182 - acc: 0.6580 - val_loss: 0.6159 - val_acc: 0.6590\n",
      "Epoch 160/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6179 - acc: 0.6578Epoch 00160: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6178 - acc: 0.6580 - val_loss: 0.6200 - val_acc: 0.6525\n",
      "Epoch 161/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6172 - acc: 0.6589Epoch 00161: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6172 - acc: 0.6588 - val_loss: 0.6162 - val_acc: 0.6594\n",
      "Epoch 162/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6174 - acc: 0.6582Epoch 00162: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6174 - acc: 0.6582 - val_loss: 0.6181 - val_acc: 0.6580\n",
      "Epoch 163/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6170 - acc: 0.6589Epoch 00163: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6168 - acc: 0.6590 - val_loss: 0.6188 - val_acc: 0.6564\n",
      "Epoch 164/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6179 - acc: 0.6574Epoch 00164: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6178 - acc: 0.6574 - val_loss: 0.6164 - val_acc: 0.6593\n",
      "Epoch 165/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6169 - acc: 0.6598Epoch 00165: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6170 - acc: 0.6599 - val_loss: 0.6190 - val_acc: 0.6538\n",
      "Epoch 166/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6165 - acc: 0.6590Epoch 00166: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6165 - acc: 0.6589 - val_loss: 0.6163 - val_acc: 0.6574\n",
      "Epoch 167/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6157 - acc: 0.6612Epoch 00167: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6156 - acc: 0.6613 - val_loss: 0.6168 - val_acc: 0.6574\n",
      "Epoch 168/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6168 - acc: 0.6587Epoch 00168: val_loss improved from 0.61588 to 0.61580, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6168 - acc: 0.6588 - val_loss: 0.6158 - val_acc: 0.6578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6156 - acc: 0.6608Epoch 00169: val_loss improved from 0.61580 to 0.61529, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6155 - acc: 0.6609 - val_loss: 0.6153 - val_acc: 0.6591\n",
      "Epoch 170/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6154 - acc: 0.6600Epoch 00170: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6155 - acc: 0.6599 - val_loss: 0.6181 - val_acc: 0.6545\n",
      "Epoch 171/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6162 - acc: 0.6600Epoch 00171: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6162 - acc: 0.6598 - val_loss: 0.6171 - val_acc: 0.6563\n",
      "Epoch 172/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6157 - acc: 0.6603Epoch 00172: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6157 - acc: 0.6602 - val_loss: 0.6178 - val_acc: 0.6569\n",
      "Epoch 173/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6155 - acc: 0.6600Epoch 00173: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6156 - acc: 0.6599 - val_loss: 0.6176 - val_acc: 0.6563\n",
      "Epoch 174/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6159 - acc: 0.6595Epoch 00174: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6158 - acc: 0.6597 - val_loss: 0.6165 - val_acc: 0.6584\n",
      "Epoch 175/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6161 - acc: 0.6594Epoch 00175: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6161 - acc: 0.6594 - val_loss: 0.6225 - val_acc: 0.6486\n",
      "Epoch 176/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6150 - acc: 0.6624Epoch 00176: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6151 - acc: 0.6622 - val_loss: 0.6162 - val_acc: 0.6606\n",
      "Epoch 177/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6152 - acc: 0.6615Epoch 00177: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 756us/step - loss: 0.6154 - acc: 0.6612 - val_loss: 0.6175 - val_acc: 0.6592\n",
      "Epoch 178/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6140 - acc: 0.6628Epoch 00178: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6140 - acc: 0.6629 - val_loss: 0.6192 - val_acc: 0.6534\n",
      "Epoch 179/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6152 - acc: 0.6618Epoch 00179: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 757us/step - loss: 0.6151 - acc: 0.6618 - val_loss: 0.6164 - val_acc: 0.6575\n",
      "Epoch 180/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6152 - acc: 0.6612Epoch 00180: val_loss did not improve\n",
      "171945/171945 [==============================] - 132s 770us/step - loss: 0.6151 - acc: 0.6613 - val_loss: 0.6169 - val_acc: 0.6588\n",
      "Epoch 181/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6149 - acc: 0.6618Epoch 00181: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 759us/step - loss: 0.6147 - acc: 0.6619 - val_loss: 0.6182 - val_acc: 0.6572\n",
      "Epoch 182/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6148 - acc: 0.6615Epoch 00182: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 760us/step - loss: 0.6147 - acc: 0.6616 - val_loss: 0.6173 - val_acc: 0.6559\n",
      "Epoch 183/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6131 - acc: 0.6647Epoch 00183: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 759us/step - loss: 0.6131 - acc: 0.6648 - val_loss: 0.6162 - val_acc: 0.6573\n",
      "Epoch 184/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6143 - acc: 0.6621Epoch 00184: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 759us/step - loss: 0.6143 - acc: 0.6622 - val_loss: 0.6158 - val_acc: 0.6590\n",
      "Epoch 185/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6133 - acc: 0.6631Epoch 00185: val_loss improved from 0.61529 to 0.61517, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 759us/step - loss: 0.6133 - acc: 0.6632 - val_loss: 0.6152 - val_acc: 0.6610\n",
      "Epoch 186/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6133 - acc: 0.6637Epoch 00186: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 759us/step - loss: 0.6134 - acc: 0.6637 - val_loss: 0.6186 - val_acc: 0.6561\n",
      "Epoch 187/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6135 - acc: 0.6624Epoch 00187: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 760us/step - loss: 0.6136 - acc: 0.6624 - val_loss: 0.6167 - val_acc: 0.6580\n",
      "Epoch 188/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6125 - acc: 0.6646Epoch 00188: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 758us/step - loss: 0.6126 - acc: 0.6645 - val_loss: 0.6200 - val_acc: 0.6515\n",
      "Epoch 189/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6131 - acc: 0.6625Epoch 00189: val_loss improved from 0.61517 to 0.61455, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 759us/step - loss: 0.6133 - acc: 0.6624 - val_loss: 0.6145 - val_acc: 0.6596\n",
      "Epoch 190/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6132 - acc: 0.6639Epoch 00190: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 759us/step - loss: 0.6132 - acc: 0.6639 - val_loss: 0.6170 - val_acc: 0.6574\n",
      "Epoch 191/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6131 - acc: 0.6630Epoch 00191: val_loss did not improve\n",
      "171945/171945 [==============================] - 132s 765us/step - loss: 0.6130 - acc: 0.6632 - val_loss: 0.6163 - val_acc: 0.6584\n",
      "Epoch 192/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6117 - acc: 0.6653Epoch 00192: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 761us/step - loss: 0.6117 - acc: 0.6653 - val_loss: 0.6277 - val_acc: 0.6455\n",
      "Epoch 193/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6132 - acc: 0.6638Epoch 00193: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 759us/step - loss: 0.6131 - acc: 0.6639 - val_loss: 0.6167 - val_acc: 0.6569\n",
      "Epoch 194/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6124 - acc: 0.6644Epoch 00194: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 759us/step - loss: 0.6124 - acc: 0.6643 - val_loss: 0.6161 - val_acc: 0.6584\n",
      "Epoch 195/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6127 - acc: 0.6645Epoch 00195: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 759us/step - loss: 0.6126 - acc: 0.6647 - val_loss: 0.6156 - val_acc: 0.6602\n",
      "Epoch 196/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6130 - acc: 0.6637Epoch 00196: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 759us/step - loss: 0.6129 - acc: 0.6638 - val_loss: 0.6209 - val_acc: 0.6512\n",
      "Epoch 197/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6115 - acc: 0.6660Epoch 00197: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 759us/step - loss: 0.6117 - acc: 0.6659 - val_loss: 0.6188 - val_acc: 0.6525\n",
      "Epoch 198/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6115 - acc: 0.6660Epoch 00198: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 759us/step - loss: 0.6114 - acc: 0.6660 - val_loss: 0.6151 - val_acc: 0.6598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6120 - acc: 0.6653Epoch 00199: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 759us/step - loss: 0.6121 - acc: 0.6653 - val_loss: 0.6183 - val_acc: 0.6531\n",
      "Epoch 200/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6110 - acc: 0.6670Epoch 00200: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 760us/step - loss: 0.6110 - acc: 0.6670 - val_loss: 0.6157 - val_acc: 0.6581\n",
      "Epoch 201/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6113 - acc: 0.6662Epoch 00201: val_loss did not improve\n",
      "171945/171945 [==============================] - 132s 765us/step - loss: 0.6113 - acc: 0.6661 - val_loss: 0.6182 - val_acc: 0.6552\n",
      "Epoch 202/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6104 - acc: 0.6662Epoch 00202: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 763us/step - loss: 0.6103 - acc: 0.6663 - val_loss: 0.6159 - val_acc: 0.6615\n",
      "Epoch 203/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6107 - acc: 0.6670Epoch 00203: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 762us/step - loss: 0.6108 - acc: 0.6668 - val_loss: 0.6181 - val_acc: 0.6557\n",
      "Epoch 204/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6116 - acc: 0.6648Epoch 00204: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 763us/step - loss: 0.6115 - acc: 0.6651 - val_loss: 0.6166 - val_acc: 0.6567\n",
      "Epoch 205/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6102 - acc: 0.6676Epoch 00205: val_loss improved from 0.61455 to 0.61295, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 131s 761us/step - loss: 0.6103 - acc: 0.6674 - val_loss: 0.6129 - val_acc: 0.6629\n",
      "Epoch 206/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6107 - acc: 0.6670Epoch 00206: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 760us/step - loss: 0.6106 - acc: 0.6670 - val_loss: 0.6183 - val_acc: 0.6535\n",
      "Epoch 207/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6106 - acc: 0.6668Epoch 00207: val_loss improved from 0.61295 to 0.61285, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 759us/step - loss: 0.6105 - acc: 0.6670 - val_loss: 0.6128 - val_acc: 0.6617\n",
      "Epoch 208/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6103 - acc: 0.6669Epoch 00208: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 759us/step - loss: 0.6104 - acc: 0.6668 - val_loss: 0.6194 - val_acc: 0.6545\n",
      "Epoch 209/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6103 - acc: 0.6664Epoch 00209: val_loss improved from 0.61285 to 0.61189, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 131s 759us/step - loss: 0.6102 - acc: 0.6665 - val_loss: 0.6119 - val_acc: 0.6645\n",
      "Epoch 210/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6093 - acc: 0.6688Epoch 00210: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 759us/step - loss: 0.6095 - acc: 0.6686 - val_loss: 0.6189 - val_acc: 0.6549\n",
      "Epoch 211/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6099 - acc: 0.6686Epoch 00211: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 759us/step - loss: 0.6100 - acc: 0.6685 - val_loss: 0.6141 - val_acc: 0.6614\n",
      "Epoch 212/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6097 - acc: 0.6678Epoch 00212: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 758us/step - loss: 0.6097 - acc: 0.6678 - val_loss: 0.6163 - val_acc: 0.6596\n",
      "Epoch 213/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6092 - acc: 0.6693Epoch 00213: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 759us/step - loss: 0.6091 - acc: 0.6694 - val_loss: 0.6136 - val_acc: 0.6601\n",
      "Epoch 214/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6101 - acc: 0.6672Epoch 00214: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 759us/step - loss: 0.6102 - acc: 0.6673 - val_loss: 0.6138 - val_acc: 0.6600\n",
      "Epoch 215/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6096 - acc: 0.6675Epoch 00215: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 761us/step - loss: 0.6096 - acc: 0.6676 - val_loss: 0.6160 - val_acc: 0.6579\n",
      "Epoch 216/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6091 - acc: 0.6683Epoch 00216: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 759us/step - loss: 0.6090 - acc: 0.6684 - val_loss: 0.6183 - val_acc: 0.6511\n",
      "Epoch 217/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6100 - acc: 0.6667Epoch 00217: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 759us/step - loss: 0.6100 - acc: 0.6667 - val_loss: 0.6139 - val_acc: 0.6607\n",
      "Epoch 218/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6087 - acc: 0.6683Epoch 00218: val_loss improved from 0.61189 to 0.61168, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 130s 759us/step - loss: 0.6086 - acc: 0.6684 - val_loss: 0.6117 - val_acc: 0.6640\n",
      "Epoch 219/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6092 - acc: 0.6688Epoch 00219: val_loss did not improve\n",
      "171945/171945 [==============================] - 130s 759us/step - loss: 0.6093 - acc: 0.6687 - val_loss: 0.6168 - val_acc: 0.6549\n",
      "Epoch 220/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6085 - acc: 0.6698Epoch 00220: val_loss did not improve\n",
      "171945/171945 [==============================] - 132s 766us/step - loss: 0.6086 - acc: 0.6698 - val_loss: 0.6151 - val_acc: 0.6599\n",
      "Epoch 221/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6086 - acc: 0.6683Epoch 00221: val_loss did not improve\n",
      "171945/171945 [==============================] - 133s 776us/step - loss: 0.6085 - acc: 0.6682 - val_loss: 0.6141 - val_acc: 0.6619\n",
      "Epoch 222/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6077 - acc: 0.6706Epoch 00222: val_loss did not improve\n",
      "171945/171945 [==============================] - 133s 774us/step - loss: 0.6076 - acc: 0.6708 - val_loss: 0.6150 - val_acc: 0.6610\n",
      "Epoch 223/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6087 - acc: 0.6688Epoch 00223: val_loss did not improve\n",
      "171945/171945 [==============================] - 135s 783us/step - loss: 0.6086 - acc: 0.6687 - val_loss: 0.6147 - val_acc: 0.6587\n",
      "Epoch 224/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6076 - acc: 0.6689Epoch 00224: val_loss did not improve\n",
      "171945/171945 [==============================] - 132s 770us/step - loss: 0.6077 - acc: 0.6688 - val_loss: 0.6188 - val_acc: 0.6554\n",
      "Epoch 225/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6077 - acc: 0.6694Epoch 00225: val_loss did not improve\n",
      "171945/171945 [==============================] - 133s 774us/step - loss: 0.6076 - acc: 0.6696 - val_loss: 0.6150 - val_acc: 0.6601\n",
      "Epoch 226/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6077 - acc: 0.6711Epoch 00226: val_loss did not improve\n",
      "171945/171945 [==============================] - 134s 777us/step - loss: 0.6079 - acc: 0.6709 - val_loss: 0.6134 - val_acc: 0.6605\n",
      "Epoch 227/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6078 - acc: 0.6702Epoch 00227: val_loss did not improve\n",
      "171945/171945 [==============================] - 133s 772us/step - loss: 0.6078 - acc: 0.6701 - val_loss: 0.6192 - val_acc: 0.6540\n",
      "Epoch 228/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6082 - acc: 0.6695Epoch 00228: val_loss did not improve\n",
      "171945/171945 [==============================] - 133s 771us/step - loss: 0.6082 - acc: 0.6695 - val_loss: 0.6143 - val_acc: 0.6608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6074 - acc: 0.6702Epoch 00229: val_loss did not improve\n",
      "171945/171945 [==============================] - 132s 770us/step - loss: 0.6074 - acc: 0.6702 - val_loss: 0.6159 - val_acc: 0.6568\n",
      "Epoch 230/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6077 - acc: 0.6699Epoch 00230: val_loss did not improve\n",
      "171945/171945 [==============================] - 133s 776us/step - loss: 0.6078 - acc: 0.6696 - val_loss: 0.6158 - val_acc: 0.6593\n",
      "Epoch 231/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6076 - acc: 0.6698Epoch 00231: val_loss did not improve\n",
      "171945/171945 [==============================] - 136s 790us/step - loss: 0.6076 - acc: 0.6698 - val_loss: 0.6129 - val_acc: 0.6611\n",
      "Epoch 232/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6077 - acc: 0.6702Epoch 00232: val_loss did not improve\n",
      "171945/171945 [==============================] - 141s 821us/step - loss: 0.6077 - acc: 0.6704 - val_loss: 0.6138 - val_acc: 0.6602\n",
      "Epoch 233/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6067 - acc: 0.6703Epoch 00233: val_loss improved from 0.61168 to 0.61145, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 135s 787us/step - loss: 0.6067 - acc: 0.6705 - val_loss: 0.6114 - val_acc: 0.6636\n",
      "Epoch 234/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6060 - acc: 0.6720Epoch 00234: val_loss did not improve\n",
      "171945/171945 [==============================] - 133s 774us/step - loss: 0.6060 - acc: 0.6719 - val_loss: 0.6143 - val_acc: 0.6600\n",
      "Epoch 235/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6077 - acc: 0.6712Epoch 00235: val_loss did not improve\n",
      "171945/171945 [==============================] - 135s 785us/step - loss: 0.6077 - acc: 0.6712 - val_loss: 0.6155 - val_acc: 0.6580\n",
      "Epoch 236/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6066 - acc: 0.6723Epoch 00236: val_loss did not improve\n",
      "171945/171945 [==============================] - 134s 779us/step - loss: 0.6067 - acc: 0.6722 - val_loss: 0.6126 - val_acc: 0.6621\n",
      "Epoch 237/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6062 - acc: 0.6728Epoch 00237: val_loss did not improve\n",
      "171945/171945 [==============================] - 134s 780us/step - loss: 0.6061 - acc: 0.6727 - val_loss: 0.6131 - val_acc: 0.6608\n",
      "Epoch 238/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6070 - acc: 0.6705Epoch 00238: val_loss did not improve\n",
      "171945/171945 [==============================] - 134s 780us/step - loss: 0.6069 - acc: 0.6705 - val_loss: 0.6128 - val_acc: 0.6639\n",
      "Epoch 239/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6054 - acc: 0.6724Epoch 00239: val_loss improved from 0.61145 to 0.61027, saving model to models/nn_50d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 134s 781us/step - loss: 0.6053 - acc: 0.6724 - val_loss: 0.6103 - val_acc: 0.6642\n",
      "Epoch 240/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6057 - acc: 0.6724Epoch 00240: val_loss did not improve\n",
      "171945/171945 [==============================] - 134s 779us/step - loss: 0.6058 - acc: 0.6723 - val_loss: 0.6122 - val_acc: 0.6652\n",
      "Epoch 241/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6070 - acc: 0.6707Epoch 00241: val_loss did not improve\n",
      "171945/171945 [==============================] - 134s 777us/step - loss: 0.6068 - acc: 0.6709 - val_loss: 0.6143 - val_acc: 0.6617\n",
      "Epoch 242/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6054 - acc: 0.6738Epoch 00242: val_loss did not improve\n",
      "171945/171945 [==============================] - 135s 784us/step - loss: 0.6054 - acc: 0.6739 - val_loss: 0.6187 - val_acc: 0.6585\n",
      "Epoch 243/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6062 - acc: 0.6717Epoch 00243: val_loss did not improve\n",
      "171945/171945 [==============================] - 134s 782us/step - loss: 0.6063 - acc: 0.6717 - val_loss: 0.6125 - val_acc: 0.6636\n",
      "Epoch 244/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6054 - acc: 0.6726Epoch 00244: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 763us/step - loss: 0.6053 - acc: 0.6728 - val_loss: 0.6162 - val_acc: 0.6555\n",
      "Epoch 245/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6058 - acc: 0.6717Epoch 00245: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 764us/step - loss: 0.6058 - acc: 0.6717 - val_loss: 0.6121 - val_acc: 0.6643\n",
      "Epoch 246/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6052 - acc: 0.6731Epoch 00246: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 764us/step - loss: 0.6053 - acc: 0.6730 - val_loss: 0.6124 - val_acc: 0.6628\n",
      "Epoch 247/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6053 - acc: 0.6727Epoch 00247: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 763us/step - loss: 0.6052 - acc: 0.6728 - val_loss: 0.6112 - val_acc: 0.6632\n",
      "Epoch 248/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6048 - acc: 0.6743Epoch 00248: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 763us/step - loss: 0.6048 - acc: 0.6743 - val_loss: 0.6129 - val_acc: 0.6616\n",
      "Epoch 249/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6049 - acc: 0.6724Epoch 00249: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 763us/step - loss: 0.6051 - acc: 0.6722 - val_loss: 0.6190 - val_acc: 0.6566\n",
      "Epoch 250/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6058 - acc: 0.6730Epoch 00250: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 764us/step - loss: 0.6057 - acc: 0.6730 - val_loss: 0.6103 - val_acc: 0.6658\n",
      "Epoch 251/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6054 - acc: 0.6726Epoch 00251: val_loss did not improve\n",
      "171945/171945 [==============================] - 134s 781us/step - loss: 0.6054 - acc: 0.6727 - val_loss: 0.6105 - val_acc: 0.6648\n",
      "Epoch 252/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6051 - acc: 0.6732Epoch 00252: val_loss did not improve\n",
      "171945/171945 [==============================] - 135s 784us/step - loss: 0.6050 - acc: 0.6732 - val_loss: 0.6125 - val_acc: 0.6615\n",
      "Epoch 253/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6040 - acc: 0.6747Epoch 00253: val_loss did not improve\n",
      "171945/171945 [==============================] - 134s 780us/step - loss: 0.6041 - acc: 0.6746 - val_loss: 0.6128 - val_acc: 0.6636\n",
      "Epoch 254/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6044 - acc: 0.6742Epoch 00254: val_loss did not improve\n",
      "171945/171945 [==============================] - 136s 789us/step - loss: 0.6044 - acc: 0.6743 - val_loss: 0.6119 - val_acc: 0.6617\n",
      "Epoch 255/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6046 - acc: 0.6745Epoch 00255: val_loss did not improve\n",
      "171945/171945 [==============================] - 134s 777us/step - loss: 0.6046 - acc: 0.6744 - val_loss: 0.6116 - val_acc: 0.6623\n",
      "Epoch 256/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6041 - acc: 0.6743Epoch 00256: val_loss did not improve\n",
      "171945/171945 [==============================] - 133s 773us/step - loss: 0.6042 - acc: 0.6741 - val_loss: 0.6221 - val_acc: 0.6489\n",
      "Epoch 257/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6045 - acc: 0.6732Epoch 00257: val_loss did not improve\n",
      "171945/171945 [==============================] - 134s 778us/step - loss: 0.6045 - acc: 0.6732 - val_loss: 0.6165 - val_acc: 0.6571\n",
      "Epoch 258/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6043 - acc: 0.6744Epoch 00258: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 764us/step - loss: 0.6045 - acc: 0.6742 - val_loss: 0.6154 - val_acc: 0.6601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6039 - acc: 0.6758Epoch 00259: val_loss did not improve\n",
      "171945/171945 [==============================] - 134s 779us/step - loss: 0.6040 - acc: 0.6756 - val_loss: 0.6137 - val_acc: 0.6622\n",
      "Epoch 260/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6042 - acc: 0.6749Epoch 00260: val_loss did not improve\n",
      "171945/171945 [==============================] - 135s 784us/step - loss: 0.6041 - acc: 0.6749 - val_loss: 0.6156 - val_acc: 0.6572\n",
      "Epoch 261/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6036 - acc: 0.6745Epoch 00261: val_loss did not improve\n",
      "171945/171945 [==============================] - 135s 783us/step - loss: 0.6037 - acc: 0.6746 - val_loss: 0.6131 - val_acc: 0.6621\n",
      "Epoch 262/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6034 - acc: 0.6745Epoch 00262: val_loss did not improve\n",
      "171945/171945 [==============================] - 135s 782us/step - loss: 0.6034 - acc: 0.6746 - val_loss: 0.6150 - val_acc: 0.6593\n",
      "Epoch 263/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6038 - acc: 0.6742Epoch 00263: val_loss did not improve\n",
      "171945/171945 [==============================] - 134s 781us/step - loss: 0.6035 - acc: 0.6745 - val_loss: 0.6146 - val_acc: 0.6594\n",
      "Epoch 264/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6035 - acc: 0.6747Epoch 00264: val_loss did not improve\n",
      "171945/171945 [==============================] - 135s 786us/step - loss: 0.6035 - acc: 0.6747 - val_loss: 0.6172 - val_acc: 0.6586\n",
      "Epoch 00264: early stopping\n"
     ]
    }
   ],
   "source": [
    "nn.run_model(model=model, out_path=\"models/nn_50d_lstm_avg.hdf5\",**run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - GRU + Averaged Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second model uses GRU instead of LSTM, but maintains average final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "joke_seq (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 50)           1369800   \n",
      "_________________________________________________________________\n",
      "mask_paddings (Masking)      (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "drop_words (SpatialDropout1D (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "masking_2 (Masking)          (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "rnn (GRU)                    (None, 250)               225750    \n",
      "_________________________________________________________________\n",
      "avg_pred (GlobalAverage)     (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,595,550\n",
      "Trainable params: 225,750\n",
      "Non-trainable params: 1,369,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM, average final\n",
    "model = nn.create_model(rnn_type=\"GRU\",\n",
    "                     dense_final=False,\n",
    "                     **model_args)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171945 samples, validate on 24564 samples\n",
      "Epoch 1/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.9307 - acc: 0.5242Epoch 00001: val_loss improved from inf to 0.69116, saving model to models/nn_50d_gru_avg.hdf5\n",
      "171945/171945 [==============================] - 135s 785us/step - loss: 0.9317 - acc: 0.5243 - val_loss: 0.6912 - val_acc: 0.5394\n",
      "Epoch 2/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6909 - acc: 0.5490Epoch 00002: val_loss improved from 0.69116 to 0.68182, saving model to models/nn_50d_gru_avg.hdf5\n",
      "171945/171945 [==============================] - 92s 534us/step - loss: 0.6908 - acc: 0.5491 - val_loss: 0.6818 - val_acc: 0.5565\n",
      "Epoch 3/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6825 - acc: 0.5561Epoch 00003: val_loss improved from 0.68182 to 0.67869, saving model to models/nn_50d_gru_avg.hdf5\n",
      "171945/171945 [==============================] - 93s 538us/step - loss: 0.6825 - acc: 0.5561 - val_loss: 0.6787 - val_acc: 0.5637\n",
      "Epoch 4/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.7262 - acc: 0.5525Epoch 00004: val_loss improved from 0.67869 to 0.67744, saving model to models/nn_50d_gru_avg.hdf5\n",
      "171945/171945 [==============================] - 93s 540us/step - loss: 0.7257 - acc: 0.5526 - val_loss: 0.6774 - val_acc: 0.5643\n",
      "Epoch 5/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.9156 - acc: 0.5389Epoch 00005: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 540us/step - loss: 0.9134 - acc: 0.5389 - val_loss: 0.7275 - val_acc: 0.5164\n",
      "Epoch 6/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6887 - acc: 0.5676Epoch 00006: val_loss did not improve\n",
      "171945/171945 [==============================] - 92s 533us/step - loss: 0.6886 - acc: 0.5677 - val_loss: 0.6881 - val_acc: 0.5490\n",
      "Epoch 7/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.7084 - acc: 0.5661Epoch 00007: val_loss did not improve\n",
      "171945/171945 [==============================] - 92s 535us/step - loss: 0.7081 - acc: 0.5660 - val_loss: 0.6861 - val_acc: 0.5514\n",
      "Epoch 8/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6795 - acc: 0.5712Epoch 00008: val_loss did not improve\n",
      "171945/171945 [==============================] - 91s 528us/step - loss: 0.6827 - acc: 0.5709 - val_loss: 0.6807 - val_acc: 0.5571\n",
      "Epoch 9/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.7403 - acc: 0.5550Epoch 00009: val_loss improved from 0.67744 to 0.67736, saving model to models/nn_50d_gru_avg.hdf5\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.7411 - acc: 0.5549 - val_loss: 0.6774 - val_acc: 0.5642\n",
      "Epoch 10/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.7035 - acc: 0.5568Epoch 00010: val_loss improved from 0.67736 to 0.67582, saving model to models/nn_50d_gru_avg.hdf5\n",
      "171945/171945 [==============================] - 91s 530us/step - loss: 0.7032 - acc: 0.5569 - val_loss: 0.6758 - val_acc: 0.5664\n",
      "Epoch 11/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6809 - acc: 0.5615Epoch 00011: val_loss improved from 0.67582 to 0.67452, saving model to models/nn_50d_gru_avg.hdf5\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6809 - acc: 0.5614 - val_loss: 0.6745 - val_acc: 0.5655\n",
      "Epoch 12/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6801 - acc: 0.5654Epoch 00012: val_loss improved from 0.67452 to 0.67349, saving model to models/nn_50d_gru_avg.hdf5\n",
      "171945/171945 [==============================] - 92s 537us/step - loss: 0.6801 - acc: 0.5654 - val_loss: 0.6735 - val_acc: 0.5717\n",
      "Epoch 13/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.7128 - acc: 0.5600Epoch 00013: val_loss did not improve\n",
      "171945/171945 [==============================] - 92s 533us/step - loss: 0.7132 - acc: 0.5597 - val_loss: 0.6746 - val_acc: 0.5663\n",
      "Epoch 14/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.8285 - acc: 0.5428Epoch 00014: val_loss did not improve\n",
      "171945/171945 [==============================] - 92s 537us/step - loss: 0.8331 - acc: 0.5420 - val_loss: 0.6811 - val_acc: 0.5585\n",
      "Epoch 15/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6880 - acc: 0.5605Epoch 00015: val_loss did not improve\n",
      "171945/171945 [==============================] - 92s 537us/step - loss: 0.6879 - acc: 0.5605 - val_loss: 0.6756 - val_acc: 0.5656\n",
      "Epoch 16/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.9803 - acc: 0.5286Epoch 00016: val_loss did not improve\n",
      "171945/171945 [==============================] - 92s 536us/step - loss: 0.9788 - acc: 0.5285 - val_loss: 0.7138 - val_acc: 0.5403\n",
      "Epoch 17/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.8336 - acc: 0.5310Epoch 00017: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 542us/step - loss: 0.8321 - acc: 0.5313 - val_loss: 0.7053 - val_acc: 0.5467\n",
      "Epoch 18/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.7852 - acc: 0.5387Epoch 00018: val_loss did not improve\n",
      "171945/171945 [==============================] - 91s 531us/step - loss: 0.7843 - acc: 0.5390 - val_loss: 0.6960 - val_acc: 0.5498\n",
      "Epoch 19/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.7431 - acc: 0.5466Epoch 00019: val_loss did not improve\n",
      "171945/171945 [==============================] - 91s 527us/step - loss: 0.7430 - acc: 0.5467 - val_loss: 0.6801 - val_acc: 0.5556\n",
      "Epoch 20/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.7109 - acc: 0.5555Epoch 00020: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.7116 - acc: 0.5553 - val_loss: 0.6856 - val_acc: 0.5529\n",
      "Epoch 21/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.8813 - acc: 0.5341Epoch 00021: val_loss did not improve\n",
      "171945/171945 [==============================] - 91s 529us/step - loss: 0.8790 - acc: 0.5343 - val_loss: 0.6821 - val_acc: 0.5543\n",
      "Epoch 22/1000\n",
      "114000/171945 [==================>...........] - ETA: 28s - loss: 1.0394 - acc: 0.5224"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-36f7d6a86a3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"models/nn_50d_gru_avg.hdf5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mrun_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Datascience\\udacity-ml-capstone\\src\\neural_networks.py\u001b[0m in \u001b[0;36mrun_model\u001b[1;34m(model, train, valid, out_path, patience, optimizer)\u001b[0m\n\u001b[0;32m     71\u001b[0m             metrics=['acc'])\n\u001b[0;32m     72\u001b[0m     history = model.fit(x=train[0], y=train[1], epochs=1000, batch_size=2000,\n\u001b[1;32m---> 73\u001b[1;33m                 validation_data=(valid[0], valid[1]), callbacks=[checkpointer, earlystopper], verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2352\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn.run_model(model=model, out_path=\"models/nn_50d_gru_avg.hdf5\", **run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - LSTM + Dense Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third model uses LSTM again, but now has a dense final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = nn.create_model(rnn_type=\"LSTM\",\n",
    "                     dense_final=True,\n",
    "                     **model_args)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.run_model(model=model, out_path=\"models/nn_50d_lstm_dense.hdf5\", **run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 - GRU + Dense Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourth and final (50 dimensional) model uses GRU again, but now has a densse final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = nn.create_model(rnn_type=\"GRU\",\n",
    "                     dense_final=True,\n",
    "                     **model_args)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn.run_model(model=model, out_path=\"models/nn_50d_gru_dense.hdf5\",**run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Run 300d models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section run the neural network models that take the 300 dimensional word embeddings as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these arguments will be the same when creating all four 300d models\n",
    "model_args = {\"embedding_matrix\":embedding_matrix300, \"n_hidden\":150}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - LSTM + Averaged Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "joke_seq (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 300)          8218800   \n",
      "_________________________________________________________________\n",
      "mask_paddings (Masking)      (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "drop_words (SpatialDropout1D (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "masking_3 (Masking)          (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "rnn (LSTM)                   (None, 150)               270600    \n",
      "_________________________________________________________________\n",
      "avg_pred (GlobalAverage)     (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,489,400\n",
      "Trainable params: 270,600\n",
      "Non-trainable params: 8,218,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM, average final\n",
    "model = nn.create_model(rnn_type=\"LSTM\",\n",
    "                     dense_final=False,\n",
    "                     **model_args)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171945 samples, validate on 24564 samples\n",
      "Epoch 1/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6672 - acc: 0.5844Epoch 00001: val_loss improved from inf to 0.64888, saving model to models/nn_300d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 159s 928us/step - loss: 0.6670 - acc: 0.5847 - val_loss: 0.6489 - val_acc: 0.6164\n",
      "Epoch 2/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6486 - acc: 0.6149Epoch 00002: val_loss improved from 0.64888 to 0.64334, saving model to models/nn_300d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 98s 567us/step - loss: 0.6487 - acc: 0.6148 - val_loss: 0.6433 - val_acc: 0.6229\n",
      "Epoch 3/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6449 - acc: 0.6207Epoch 00003: val_loss improved from 0.64334 to 0.64017, saving model to models/nn_300d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 96s 560us/step - loss: 0.6449 - acc: 0.6206 - val_loss: 0.6402 - val_acc: 0.6301\n",
      "Epoch 4/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6423 - acc: 0.6246Epoch 00004: val_loss improved from 0.64017 to 0.63877, saving model to models/nn_300d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 97s 563us/step - loss: 0.6423 - acc: 0.6246 - val_loss: 0.6388 - val_acc: 0.6294\n",
      "Epoch 5/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6405 - acc: 0.6261Epoch 00005: val_loss improved from 0.63877 to 0.63664, saving model to models/nn_300d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 97s 563us/step - loss: 0.6405 - acc: 0.6261 - val_loss: 0.6366 - val_acc: 0.6343\n",
      "Epoch 6/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6390 - acc: 0.6301Epoch 00006: val_loss improved from 0.63664 to 0.63561, saving model to models/nn_300d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 98s 571us/step - loss: 0.6390 - acc: 0.6301 - val_loss: 0.6356 - val_acc: 0.6348\n",
      "Epoch 7/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6383 - acc: 0.6296Epoch 00007: val_loss improved from 0.63561 to 0.63550, saving model to models/nn_300d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 98s 570us/step - loss: 0.6383 - acc: 0.6296 - val_loss: 0.6355 - val_acc: 0.6351\n",
      "Epoch 8/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6368 - acc: 0.6322Epoch 00008: val_loss improved from 0.63550 to 0.63314, saving model to models/nn_300d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 97s 566us/step - loss: 0.6368 - acc: 0.6322 - val_loss: 0.6331 - val_acc: 0.6382\n",
      "Epoch 9/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6361 - acc: 0.6335Epoch 00009: val_loss improved from 0.63314 to 0.63246, saving model to models/nn_300d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 98s 567us/step - loss: 0.6361 - acc: 0.6335 - val_loss: 0.6325 - val_acc: 0.6388\n",
      "Epoch 10/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6351 - acc: 0.6342Epoch 00010: val_loss improved from 0.63246 to 0.63201, saving model to models/nn_300d_lstm_avg.hdf5\n",
      "171945/171945 [==============================] - 96s 561us/step - loss: 0.6351 - acc: 0.6340 - val_loss: 0.6320 - val_acc: 0.6402\n",
      "Epoch 11/1000\n",
      "118000/171945 [===================>..........] - ETA: 27s - loss: 0.6351 - acc: 0.6351"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-8b699945ea41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"models/nn_300d_lstm_avg.hdf5\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mrun_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Datascience\\udacity-ml-capstone\\src\\neural_networks.py\u001b[0m in \u001b[0;36mrun_model\u001b[1;34m(model, train, valid, out_path, patience, optimizer)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mmask2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMasking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mask_dropped_words'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mrnn_type\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"LSTM\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         rnn = LSTM(n_hidden, implementation=2, unroll=True, name='rnn', activation=\"tanh\",\n\u001b[0;32m     75\u001b[0m                   recurrent_dropout=dropout_rate*2, dropout=dropout_rate)(mask2)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2352\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn.run_model(model=model, out_path=\"models/nn_300d_lstm_avg.hdf5\",**run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - GRU + Averaged Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LSTM, average final\n",
    "model = nn.create_model(rnn_type=\"GRU\",\n",
    "                     dense_final=False,\n",
    "                     **model_args)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.run_model(model=model, out_path=\"models/nn_300d_gru_avg.hdf5\", **run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 - LSTM + Dense Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = nn.create_model(rnn_type=\"LSTM\",\n",
    "                     dense_final=True,\n",
    "                     **model_args)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.run_model(model=model, out_path=\"models/nn_300d_lstm_dense.hdf5\", **run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 - GRU + Dense Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = nn.create_model(rnn_type=\"GRU\",\n",
    "                     dense_final=True,\n",
    "                     **model_args)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.run_model(model=model, out_path=\"models/nn_300d_gru_dense.hdf5\",**run_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
