{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook train four different neural network models. They are all pretty similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.1 Load Packages and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.externals import joblib\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.join(os.getcwd(), os.pardir)\n",
    "os.chdir(PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\wertu\\\\Documents\\\\Datascience\\\\udacity-ml-capstone'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import src.neural_networks as nn\n",
    "from src.evaluation import roc_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "nn = reload(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2- Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and validation neural network data sets if they are present, otherwise raise an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load sequnces\n",
    "try:\n",
    "    train = joblib.load('data/processed/train_nn.pkl')\n",
    "    valid = joblib.load('data/processed/valid_nn.pkl')\n",
    "    test = joblib.load('data/processed/test_nn.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load embedding matrix of 50 dimensions\n",
    "try:\n",
    "    embedding_matrix50 = joblib.load('data/interim/embeddings50.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load embedding matrix of 300 dimensions\n",
    "try:\n",
    "    embedding_matrix300 = joblib.load('data/interim/embeddings300.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these arguments will be the same when training both models\n",
    "run_args = {\"train\":(train[\"seqs\"],train[\"labels\"]),\n",
    "            \"valid\":(valid[\"seqs\"],valid[\"labels\"])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Train 50d model with trainable embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will now make embedding layer of first model trainable. Dropout of inputs to recurrent layer is automatically increased when the embedding layer is trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model50_trained = nn.create_model(n_hidden=150, embedding_matrix=embedding_matrix50, train_embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "joke_seq (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 50)           1369800   \n",
      "_________________________________________________________________\n",
      "mask_paddings (Masking)      (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "drop_words (SpatialDropout1D (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "mask_dropped_words (Masking) (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "reccurrent_layer (LSTM)      (None, 150)               120600    \n",
      "_________________________________________________________________\n",
      "drop_dense (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_sigmoid (Dense)        (None, 75)                11325     \n",
      "_________________________________________________________________\n",
      "avg_pred (GlobalAverage)     (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,501,725\n",
      "Trainable params: 1,501,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Load weights\n",
    "model50_trained.load_weights('models/nn_50d_fixed.hdf5')\n",
    "model50_trained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171945 samples, validate on 24564 samples\n",
      "Epoch 1/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6256 - acc: 0.6478 val_auc: 73.0047%\n",
      "Epoch 00001: val_auc improved from -inf to 0.73005, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 145s 841us/step - loss: 0.6255 - acc: 0.6478 - val_loss: 0.6089 - val_acc: 0.6628\n",
      "Epoch 2/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6225 - acc: 0.6506 val_auc: 72.9017%\n",
      "Epoch 00002: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.6224 - acc: 0.6508 - val_loss: 0.6109 - val_acc: 0.6594\n",
      "Epoch 3/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6203 - acc: 0.6526 val_auc: 72.9213%\n",
      "Epoch 00003: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.6204 - acc: 0.6526 - val_loss: 0.6107 - val_acc: 0.6591\n",
      "Epoch 4/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6198 - acc: 0.6541 val_auc: 72.9154%\n",
      "Epoch 00004: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.6198 - acc: 0.6541 - val_loss: 0.6108 - val_acc: 0.6601\n",
      "Epoch 5/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6180 - acc: 0.6566 val_auc: 72.9379%\n",
      "Epoch 00005: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.6180 - acc: 0.6567 - val_loss: 0.6100 - val_acc: 0.6609\n",
      "Epoch 6/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6172 - acc: 0.6583 val_auc: 72.9673%\n",
      "Epoch 00006: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.6174 - acc: 0.6580 - val_loss: 0.6108 - val_acc: 0.6604\n",
      "Epoch 7/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6172 - acc: 0.6576 val_auc: 73.1014%\n",
      "Epoch 00007: val_auc improved from 0.73005 to 0.73101, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.6171 - acc: 0.6578 - val_loss: 0.6087 - val_acc: 0.6629\n",
      "Epoch 8/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6157 - acc: 0.6590 val_auc: 73.1596%\n",
      "Epoch 00008: val_auc improved from 0.73101 to 0.73160, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.6157 - acc: 0.6590 - val_loss: 0.6095 - val_acc: 0.6638\n",
      "Epoch 9/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6140 - acc: 0.6609 val_auc: 73.2520%\n",
      "Epoch 00009: val_auc improved from 0.73160 to 0.73252, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.6139 - acc: 0.6610 - val_loss: 0.6089 - val_acc: 0.6642\n",
      "Epoch 10/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6129 - acc: 0.6630 val_auc: 73.2168%\n",
      "Epoch 00010: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 596us/step - loss: 0.6129 - acc: 0.6631 - val_loss: 0.6083 - val_acc: 0.6637\n",
      "Epoch 11/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6123 - acc: 0.6630 val_auc: 73.2933%\n",
      "Epoch 00011: val_auc improved from 0.73252 to 0.73293, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 102s 594us/step - loss: 0.6122 - acc: 0.6630 - val_loss: 0.6082 - val_acc: 0.6633\n",
      "Epoch 12/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6113 - acc: 0.6639 val_auc: 73.3596%\n",
      "Epoch 00012: val_auc improved from 0.73293 to 0.73360, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.6112 - acc: 0.6640 - val_loss: 0.6095 - val_acc: 0.6631\n",
      "Epoch 13/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6106 - acc: 0.6663 val_auc: 73.4735%\n",
      "Epoch 00013: val_auc improved from 0.73360 to 0.73473, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.6103 - acc: 0.6665 - val_loss: 0.6077 - val_acc: 0.6666\n",
      "Epoch 14/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6087 - acc: 0.6668 val_auc: 73.4399%\n",
      "Epoch 00014: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.6087 - acc: 0.6668 - val_loss: 0.6070 - val_acc: 0.6667\n",
      "Epoch 15/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6082 - acc: 0.6663 val_auc: 73.4823%\n",
      "Epoch 00015: val_auc improved from 0.73473 to 0.73482, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.6083 - acc: 0.6662 - val_loss: 0.6106 - val_acc: 0.6636\n",
      "Epoch 16/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6069 - acc: 0.6690 val_auc: 73.6270%\n",
      "Epoch 00016: val_auc improved from 0.73482 to 0.73627, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.6069 - acc: 0.6690 - val_loss: 0.6096 - val_acc: 0.6647\n",
      "Epoch 17/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6069 - acc: 0.6687 val_auc: 73.7073%\n",
      "Epoch 00017: val_auc improved from 0.73627 to 0.73707, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.6071 - acc: 0.6687 - val_loss: 0.6077 - val_acc: 0.6662\n",
      "Epoch 18/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6043 - acc: 0.6730 val_auc: 73.6600%\n",
      "Epoch 00018: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.6042 - acc: 0.6730 - val_loss: 0.6059 - val_acc: 0.6679\n",
      "Epoch 19/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6040 - acc: 0.6734 val_auc: 73.7917%\n",
      "Epoch 00019: val_auc improved from 0.73707 to 0.73792, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.6039 - acc: 0.6735 - val_loss: 0.6062 - val_acc: 0.6696\n",
      "Epoch 20/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.6736 val_auc: 73.7224%\n",
      "Epoch 00020: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.6024 - acc: 0.6738 - val_loss: 0.6061 - val_acc: 0.6687\n",
      "Epoch 21/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.6755 val_auc: 73.9023%\n",
      "Epoch 00021: val_auc improved from 0.73792 to 0.73902, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.6017 - acc: 0.6754 - val_loss: 0.6062 - val_acc: 0.6697\n",
      "Epoch 22/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6004 - acc: 0.6771 val_auc: 73.9938%\n",
      "Epoch 00022: val_auc improved from 0.73902 to 0.73994, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.6005 - acc: 0.6771 - val_loss: 0.6078 - val_acc: 0.6700\n",
      "Epoch 23/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5985 - acc: 0.6779 val_auc: 74.0170%\n",
      "Epoch 00023: val_auc improved from 0.73994 to 0.74017, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5986 - acc: 0.6778 - val_loss: 0.6053 - val_acc: 0.6697\n",
      "Epoch 24/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5974 - acc: 0.6798 val_auc: 74.0041%\n",
      "Epoch 00024: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5974 - acc: 0.6797 - val_loss: 0.6070 - val_acc: 0.6702\n",
      "Epoch 25/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5966 - acc: 0.6809 val_auc: 74.1681%\n",
      "Epoch 00025: val_auc improved from 0.74017 to 0.74168, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 102s 593us/step - loss: 0.5966 - acc: 0.6808 - val_loss: 0.6063 - val_acc: 0.6715\n",
      "Epoch 26/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5962 - acc: 0.6799 val_auc: 74.2042%\n",
      "Epoch 00026: val_auc improved from 0.74168 to 0.74204, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 103s 597us/step - loss: 0.5962 - acc: 0.6799 - val_loss: 0.6054 - val_acc: 0.6714\n",
      "Epoch 27/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5953 - acc: 0.6813 val_auc: 74.2281%\n",
      "Epoch 00027: val_auc improved from 0.74204 to 0.74228, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 590us/step - loss: 0.5954 - acc: 0.6813 - val_loss: 0.6040 - val_acc: 0.6723\n",
      "Epoch 28/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5921 - acc: 0.6841 val_auc: 74.2797%\n",
      "Epoch 00028: val_auc improved from 0.74228 to 0.74280, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.5920 - acc: 0.6839 - val_loss: 0.6052 - val_acc: 0.6713\n",
      "Epoch 29/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5921 - acc: 0.6857 val_auc: 74.3947%\n",
      "Epoch 00029: val_auc improved from 0.74280 to 0.74395, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5921 - acc: 0.6857 - val_loss: 0.6063 - val_acc: 0.6714\n",
      "Epoch 30/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5909 - acc: 0.6856 val_auc: 74.3790%\n",
      "Epoch 00030: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5909 - acc: 0.6855 - val_loss: 0.6059 - val_acc: 0.6724\n",
      "Epoch 31/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5888 - acc: 0.6881 val_auc: 74.4217%\n",
      "Epoch 00031: val_auc improved from 0.74395 to 0.74422, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5888 - acc: 0.6882 - val_loss: 0.6023 - val_acc: 0.6747\n",
      "Epoch 32/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5882 - acc: 0.6888 val_auc: 74.4741%\n",
      "Epoch 00032: val_auc improved from 0.74422 to 0.74474, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5883 - acc: 0.6887 - val_loss: 0.6036 - val_acc: 0.6746\n",
      "Epoch 33/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5864 - acc: 0.6907 val_auc: 74.5216%\n",
      "Epoch 00033: val_auc improved from 0.74474 to 0.74522, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5865 - acc: 0.6906 - val_loss: 0.6051 - val_acc: 0.6748\n",
      "Epoch 34/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5858 - acc: 0.6905 val_auc: 74.7102%\n",
      "Epoch 00034: val_auc improved from 0.74522 to 0.74710, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5856 - acc: 0.6907 - val_loss: 0.6053 - val_acc: 0.6734\n",
      "Epoch 35/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5834 - acc: 0.6942 val_auc: 74.6529%\n",
      "Epoch 00035: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5834 - acc: 0.6943 - val_loss: 0.6036 - val_acc: 0.6742\n",
      "Epoch 36/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5828 - acc: 0.6924 val_auc: 74.7487%\n",
      "Epoch 00036: val_auc improved from 0.74710 to 0.74749, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5828 - acc: 0.6925 - val_loss: 0.6030 - val_acc: 0.6765\n",
      "Epoch 37/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5817 - acc: 0.6947 val_auc: 74.7796%\n",
      "Epoch 00037: val_auc improved from 0.74749 to 0.74780, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.5817 - acc: 0.6948 - val_loss: 0.6045 - val_acc: 0.6763\n",
      "Epoch 38/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5804 - acc: 0.6963 val_auc: 74.8083%\n",
      "Epoch 00038: val_auc improved from 0.74780 to 0.74808, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5803 - acc: 0.6964 - val_loss: 0.6050 - val_acc: 0.6771\n",
      "Epoch 39/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5783 - acc: 0.6984 val_auc: 74.9035%\n",
      "Epoch 00039: val_auc improved from 0.74808 to 0.74904, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5784 - acc: 0.6984 - val_loss: 0.6035 - val_acc: 0.6792\n",
      "Epoch 40/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5782 - acc: 0.6978 val_auc: 74.7027%\n",
      "Epoch 00040: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5782 - acc: 0.6978 - val_loss: 0.6058 - val_acc: 0.6760\n",
      "Epoch 41/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5759 - acc: 0.6996 val_auc: 74.8698%\n",
      "Epoch 00041: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5758 - acc: 0.6998 - val_loss: 0.6057 - val_acc: 0.6784\n",
      "Epoch 42/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5746 - acc: 0.7004 val_auc: 75.0000%\n",
      "Epoch 00042: val_auc improved from 0.74904 to 0.75000, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5746 - acc: 0.7005 - val_loss: 0.6015 - val_acc: 0.6813\n",
      "Epoch 43/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5738 - acc: 0.7022 val_auc: 75.0969%\n",
      "Epoch 00043: val_auc improved from 0.75000 to 0.75097, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5740 - acc: 0.7020 - val_loss: 0.6018 - val_acc: 0.6828\n",
      "Epoch 44/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5729 - acc: 0.7025 val_auc: 75.1273%\n",
      "Epoch 00044: val_auc improved from 0.75097 to 0.75127, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5729 - acc: 0.7025 - val_loss: 0.6012 - val_acc: 0.6826\n",
      "Epoch 45/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5716 - acc: 0.7025 val_auc: 75.1345%\n",
      "Epoch 00045: val_auc improved from 0.75127 to 0.75134, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5716 - acc: 0.7026 - val_loss: 0.6033 - val_acc: 0.6830\n",
      "Epoch 46/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5705 - acc: 0.7043 val_auc: 75.1634%\n",
      "Epoch 00046: val_auc improved from 0.75134 to 0.75163, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5707 - acc: 0.7042 - val_loss: 0.6032 - val_acc: 0.6816\n",
      "Epoch 47/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5697 - acc: 0.7050 val_auc: 75.2626%\n",
      "Epoch 00047: val_auc improved from 0.75163 to 0.75263, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5698 - acc: 0.7049 - val_loss: 0.6013 - val_acc: 0.6843\n",
      "Epoch 48/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5678 - acc: 0.7062 val_auc: 75.2752%\n",
      "Epoch 00048: val_auc improved from 0.75263 to 0.75275, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5679 - acc: 0.7062 - val_loss: 0.6027 - val_acc: 0.6830\n",
      "Epoch 49/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5662 - acc: 0.7078 val_auc: 75.1499%\n",
      "Epoch 00049: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5661 - acc: 0.7077 - val_loss: 0.6020 - val_acc: 0.6837\n",
      "Epoch 50/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5657 - acc: 0.7092 val_auc: 75.2131%\n",
      "Epoch 00050: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5660 - acc: 0.7089 - val_loss: 0.6056 - val_acc: 0.6807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5642 - acc: 0.7101 val_auc: 75.4351%\n",
      "Epoch 00051: val_auc improved from 0.75275 to 0.75435, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5644 - acc: 0.7101 - val_loss: 0.5999 - val_acc: 0.6850\n",
      "Epoch 52/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5641 - acc: 0.7096 val_auc: 75.3917%\n",
      "Epoch 00052: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5641 - acc: 0.7097 - val_loss: 0.6011 - val_acc: 0.6844\n",
      "Epoch 53/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5621 - acc: 0.7105 val_auc: 75.3561%\n",
      "Epoch 00053: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5622 - acc: 0.7105 - val_loss: 0.6018 - val_acc: 0.6840\n",
      "Epoch 54/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5593 - acc: 0.7140 val_auc: 75.5913%\n",
      "Epoch 00054: val_auc improved from 0.75435 to 0.75591, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5591 - acc: 0.7141 - val_loss: 0.6028 - val_acc: 0.6871\n",
      "Epoch 55/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5598 - acc: 0.7138 val_auc: 75.4495%\n",
      "Epoch 00055: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5598 - acc: 0.7137 - val_loss: 0.6014 - val_acc: 0.6849\n",
      "Epoch 56/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5572 - acc: 0.7155 val_auc: 75.5480%\n",
      "Epoch 00056: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5572 - acc: 0.7154 - val_loss: 0.6019 - val_acc: 0.6866\n",
      "Epoch 57/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5561 - acc: 0.7161 val_auc: 75.4041%\n",
      "Epoch 00057: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5562 - acc: 0.7162 - val_loss: 0.6029 - val_acc: 0.6860\n",
      "Epoch 58/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5560 - acc: 0.7159 val_auc: 75.4754%\n",
      "Epoch 00058: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5559 - acc: 0.7160 - val_loss: 0.6026 - val_acc: 0.6856\n",
      "Epoch 59/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5552 - acc: 0.7166 val_auc: 75.4368%\n",
      "Epoch 00059: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5550 - acc: 0.7168 - val_loss: 0.6038 - val_acc: 0.6854\n",
      "Epoch 60/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5528 - acc: 0.7197 val_auc: 75.6138%\n",
      "Epoch 00060: val_auc improved from 0.75591 to 0.75614, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5527 - acc: 0.7196 - val_loss: 0.6009 - val_acc: 0.6873\n",
      "Epoch 61/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5509 - acc: 0.7207 val_auc: 75.5208%\n",
      "Epoch 00061: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5509 - acc: 0.7206 - val_loss: 0.6032 - val_acc: 0.6872\n",
      "Epoch 62/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5499 - acc: 0.7212 val_auc: 75.5452%\n",
      "Epoch 00062: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5498 - acc: 0.7213 - val_loss: 0.6036 - val_acc: 0.6865\n",
      "Epoch 63/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5488 - acc: 0.7212 val_auc: 75.5178%\n",
      "Epoch 00063: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5488 - acc: 0.7212 - val_loss: 0.6030 - val_acc: 0.6880\n",
      "Epoch 64/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5465 - acc: 0.7226 val_auc: 75.6527%\n",
      "Epoch 00064: val_auc improved from 0.75614 to 0.75653, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5465 - acc: 0.7226 - val_loss: 0.6017 - val_acc: 0.6898\n",
      "Epoch 65/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5454 - acc: 0.7247 val_auc: 75.6551%\n",
      "Epoch 00065: val_auc improved from 0.75653 to 0.75655, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5455 - acc: 0.7245 - val_loss: 0.6051 - val_acc: 0.6871\n",
      "Epoch 66/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5451 - acc: 0.7241 val_auc: 75.6373%\n",
      "Epoch 00066: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5450 - acc: 0.7243 - val_loss: 0.6051 - val_acc: 0.6880\n",
      "Epoch 67/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5441 - acc: 0.7251 val_auc: 75.6900%\n",
      "Epoch 00067: val_auc improved from 0.75655 to 0.75690, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5443 - acc: 0.7250 - val_loss: 0.6037 - val_acc: 0.6894\n",
      "Epoch 68/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5420 - acc: 0.7265 val_auc: 75.7027%\n",
      "Epoch 00068: val_auc improved from 0.75690 to 0.75703, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5420 - acc: 0.7265 - val_loss: 0.6065 - val_acc: 0.6881\n",
      "Epoch 69/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5411 - acc: 0.7274 val_auc: 75.7033%\n",
      "Epoch 00069: val_auc improved from 0.75703 to 0.75703, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5414 - acc: 0.7273 - val_loss: 0.6057 - val_acc: 0.6882\n",
      "Epoch 70/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5405 - acc: 0.7281 val_auc: 75.7504%\n",
      "Epoch 00070: val_auc improved from 0.75703 to 0.75750, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5405 - acc: 0.7282 - val_loss: 0.6073 - val_acc: 0.6892\n",
      "Epoch 71/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5382 - acc: 0.7294 val_auc: 75.8287%\n",
      "Epoch 00071: val_auc improved from 0.75750 to 0.75829, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5382 - acc: 0.7294 - val_loss: 0.6020 - val_acc: 0.6900\n",
      "Epoch 72/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5371 - acc: 0.7305 val_auc: 75.7322%\n",
      "Epoch 00072: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5372 - acc: 0.7305 - val_loss: 0.6055 - val_acc: 0.6882\n",
      "Epoch 73/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5364 - acc: 0.7311 val_auc: 75.9095%\n",
      "Epoch 00073: val_auc improved from 0.75829 to 0.75910, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5363 - acc: 0.7311 - val_loss: 0.6081 - val_acc: 0.6882\n",
      "Epoch 74/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5347 - acc: 0.7312 val_auc: 75.7588%\n",
      "Epoch 00074: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5346 - acc: 0.7313 - val_loss: 0.6076 - val_acc: 0.6894\n",
      "Epoch 75/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5345 - acc: 0.7321 val_auc: 75.8963%\n",
      "Epoch 00075: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5344 - acc: 0.7324 - val_loss: 0.6062 - val_acc: 0.6902\n",
      "Epoch 76/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5330 - acc: 0.7349 val_auc: 75.7641%\n",
      "Epoch 00076: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5330 - acc: 0.7349 - val_loss: 0.6106 - val_acc: 0.6877\n",
      "Epoch 77/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5320 - acc: 0.7337 val_auc: 75.9302%\n",
      "Epoch 00077: val_auc improved from 0.75910 to 0.75930, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5320 - acc: 0.7336 - val_loss: 0.6061 - val_acc: 0.6906\n",
      "Epoch 78/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5303 - acc: 0.7359 val_auc: 75.6807%\n",
      "Epoch 00078: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5303 - acc: 0.7359 - val_loss: 0.6114 - val_acc: 0.6879\n",
      "Epoch 79/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5288 - acc: 0.7375 val_auc: 75.8174%\n",
      "Epoch 00079: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5288 - acc: 0.7376 - val_loss: 0.6091 - val_acc: 0.6889\n",
      "Epoch 80/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5273 - acc: 0.7385 val_auc: 75.9021%\n",
      "Epoch 00080: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5273 - acc: 0.7383 - val_loss: 0.6057 - val_acc: 0.6900\n",
      "Epoch 81/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5271 - acc: 0.7385 val_auc: 75.9132%\n",
      "Epoch 00081: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5271 - acc: 0.7384 - val_loss: 0.6089 - val_acc: 0.6894\n",
      "Epoch 82/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5254 - acc: 0.7385 val_auc: 75.8379%\n",
      "Epoch 00082: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5254 - acc: 0.7385 - val_loss: 0.6105 - val_acc: 0.6887\n",
      "Epoch 83/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5249 - acc: 0.7394 val_auc: 75.9649%\n",
      "Epoch 00083: val_auc improved from 0.75930 to 0.75965, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5250 - acc: 0.7393 - val_loss: 0.6105 - val_acc: 0.6888\n",
      "Epoch 84/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5217 - acc: 0.7419 val_auc: 75.8780%\n",
      "Epoch 00084: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5217 - acc: 0.7420 - val_loss: 0.6105 - val_acc: 0.6899\n",
      "Epoch 85/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5220 - acc: 0.7408 val_auc: 75.9237%\n",
      "Epoch 00085: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5221 - acc: 0.7408 - val_loss: 0.6093 - val_acc: 0.6903\n",
      "Epoch 86/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5203 - acc: 0.7429 val_auc: 75.9935%\n",
      "Epoch 00086: val_auc improved from 0.75965 to 0.75994, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5201 - acc: 0.7430 - val_loss: 0.6094 - val_acc: 0.6907\n",
      "Epoch 87/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5188 - acc: 0.7437 val_auc: 75.9843%\n",
      "Epoch 00087: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5187 - acc: 0.7439 - val_loss: 0.6123 - val_acc: 0.6889\n",
      "Epoch 88/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5192 - acc: 0.7426 val_auc: 75.8876%\n",
      "Epoch 00088: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5192 - acc: 0.7426 - val_loss: 0.6116 - val_acc: 0.6885\n",
      "Epoch 89/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5150 - acc: 0.7468 val_auc: 75.6937%\n",
      "Epoch 00089: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5150 - acc: 0.7467 - val_loss: 0.6144 - val_acc: 0.6882\n",
      "Epoch 90/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5147 - acc: 0.7467 val_auc: 75.9890%\n",
      "Epoch 00090: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5149 - acc: 0.7465 - val_loss: 0.6116 - val_acc: 0.6896\n",
      "Epoch 91/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5134 - acc: 0.7472 val_auc: 75.8909%\n",
      "Epoch 00091: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5135 - acc: 0.7473 - val_loss: 0.6167 - val_acc: 0.6880\n",
      "Epoch 92/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5128 - acc: 0.7488 val_auc: 76.0071%\n",
      "Epoch 00092: val_auc improved from 0.75994 to 0.76007, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5128 - acc: 0.7487 - val_loss: 0.6173 - val_acc: 0.6899\n",
      "Epoch 93/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5120 - acc: 0.7491 val_auc: 75.9065%\n",
      "Epoch 00093: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5120 - acc: 0.7491 - val_loss: 0.6146 - val_acc: 0.6898\n",
      "Epoch 94/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5091 - acc: 0.7503 val_auc: 75.8578%\n",
      "Epoch 00094: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5090 - acc: 0.7504 - val_loss: 0.6178 - val_acc: 0.6884\n",
      "Epoch 95/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5096 - acc: 0.7497 val_auc: 75.9405%\n",
      "Epoch 00095: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5095 - acc: 0.7498 - val_loss: 0.6163 - val_acc: 0.6882\n",
      "Epoch 96/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5061 - acc: 0.7509 val_auc: 75.9288%\n",
      "Epoch 00096: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5061 - acc: 0.7509 - val_loss: 0.6197 - val_acc: 0.6870\n",
      "Epoch 97/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5070 - acc: 0.7530 val_auc: 75.8510%\n",
      "Epoch 00097: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5070 - acc: 0.7528 - val_loss: 0.6183 - val_acc: 0.6877\n",
      "Epoch 98/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5052 - acc: 0.7537 val_auc: 75.8363%\n",
      "Epoch 00098: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5051 - acc: 0.7537 - val_loss: 0.6158 - val_acc: 0.6891\n",
      "Epoch 99/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5028 - acc: 0.7546 val_auc: 75.9553%\n",
      "Epoch 00099: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5028 - acc: 0.7545 - val_loss: 0.6201 - val_acc: 0.6880\n",
      "Epoch 100/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5024 - acc: 0.7551 val_auc: 75.7947%\n",
      "Epoch 00100: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5022 - acc: 0.7553 - val_loss: 0.6221 - val_acc: 0.6862\n",
      "Epoch 101/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5023 - acc: 0.7539 val_auc: 75.9491%\n",
      "Epoch 00101: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5024 - acc: 0.7538 - val_loss: 0.6211 - val_acc: 0.6893\n",
      "Epoch 102/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5015 - acc: 0.7572 val_auc: 75.9754%\n",
      "Epoch 00102: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5016 - acc: 0.7571 - val_loss: 0.6210 - val_acc: 0.6878\n",
      "Epoch 103/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4995 - acc: 0.7572 val_auc: 76.0321%\n",
      "Epoch 00103: val_auc improved from 0.76007 to 0.76032, saving model to models/nn_50d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4995 - acc: 0.7573 - val_loss: 0.6190 - val_acc: 0.6893\n",
      "Epoch 104/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4981 - acc: 0.7576 val_auc: 75.8132%\n",
      "Epoch 00104: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4978 - acc: 0.7578 - val_loss: 0.6236 - val_acc: 0.6891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4976 - acc: 0.7584 val_auc: 75.9388%\n",
      "Epoch 00105: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.4978 - acc: 0.7584 - val_loss: 0.6238 - val_acc: 0.6873\n",
      "Epoch 106/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4970 - acc: 0.7585 val_auc: 75.9454%\n",
      "Epoch 00106: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4972 - acc: 0.7583 - val_loss: 0.6211 - val_acc: 0.6895\n",
      "Epoch 107/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4958 - acc: 0.7600 val_auc: 75.9693%\n",
      "Epoch 00107: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.4956 - acc: 0.7600 - val_loss: 0.6216 - val_acc: 0.6899\n",
      "Epoch 108/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4937 - acc: 0.7596 val_auc: 75.9677%\n",
      "Epoch 00108: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.4936 - acc: 0.7597 - val_loss: 0.6227 - val_acc: 0.6900\n",
      "Epoch 109/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4926 - acc: 0.7610 val_auc: 76.0180%\n",
      "Epoch 00109: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4926 - acc: 0.7610 - val_loss: 0.6238 - val_acc: 0.6903\n",
      "Epoch 110/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4911 - acc: 0.7626 val_auc: 75.9278%\n",
      "Epoch 00110: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.4914 - acc: 0.7622 - val_loss: 0.6247 - val_acc: 0.6890\n",
      "Epoch 111/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4893 - acc: 0.7637 val_auc: 75.9033%\n",
      "Epoch 00111: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.4893 - acc: 0.7637 - val_loss: 0.6263 - val_acc: 0.6885\n",
      "Epoch 112/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4890 - acc: 0.7626 val_auc: 76.0229%\n",
      "Epoch 00112: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.4890 - acc: 0.7627 - val_loss: 0.6258 - val_acc: 0.6893\n",
      "Epoch 113/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4889 - acc: 0.7629 val_auc: 75.8669%\n",
      "Epoch 00113: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4888 - acc: 0.7629 - val_loss: 0.6274 - val_acc: 0.6883\n",
      "Epoch 114/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4851 - acc: 0.7665 val_auc: 75.8402%\n",
      "Epoch 00114: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4850 - acc: 0.7665 - val_loss: 0.6285 - val_acc: 0.6901\n",
      "Epoch 115/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4857 - acc: 0.7647 val_auc: 75.7323%\n",
      "Epoch 00115: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.4858 - acc: 0.7647 - val_loss: 0.6303 - val_acc: 0.6886\n",
      "Epoch 116/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4839 - acc: 0.7672 val_auc: 75.9030%\n",
      "Epoch 00116: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4838 - acc: 0.7673 - val_loss: 0.6309 - val_acc: 0.6901\n",
      "Epoch 117/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4836 - acc: 0.7659 val_auc: 75.7710%\n",
      "Epoch 00117: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4837 - acc: 0.7658 - val_loss: 0.6297 - val_acc: 0.6889\n",
      "Epoch 118/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4804 - acc: 0.7680 val_auc: 75.8167%\n",
      "Epoch 00118: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4804 - acc: 0.7679 - val_loss: 0.6328 - val_acc: 0.6896\n",
      "Epoch 119/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4805 - acc: 0.7681 val_auc: 75.8134%\n",
      "Epoch 00119: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4808 - acc: 0.7680 - val_loss: 0.6359 - val_acc: 0.6872\n",
      "Epoch 120/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4786 - acc: 0.7696 val_auc: 75.7657%\n",
      "Epoch 00120: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4786 - acc: 0.7696 - val_loss: 0.6352 - val_acc: 0.6882\n",
      "Epoch 121/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4777 - acc: 0.7702 val_auc: 75.7765%\n",
      "Epoch 00121: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4776 - acc: 0.7702 - val_loss: 0.6347 - val_acc: 0.6894\n",
      "Epoch 122/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4775 - acc: 0.7713 val_auc: 75.7260%\n",
      "Epoch 00122: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4776 - acc: 0.7713 - val_loss: 0.6373 - val_acc: 0.6867\n",
      "Epoch 123/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4752 - acc: 0.7717 val_auc: 75.7188%\n",
      "Epoch 00123: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4753 - acc: 0.7716 - val_loss: 0.6350 - val_acc: 0.6894\n",
      "Epoch 124/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4746 - acc: 0.7724 val_auc: 75.7282%\n",
      "Epoch 00124: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4744 - acc: 0.7726 - val_loss: 0.6401 - val_acc: 0.6879\n",
      "Epoch 125/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4721 - acc: 0.7733 val_auc: 75.5712%\n",
      "Epoch 00125: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4720 - acc: 0.7734 - val_loss: 0.6429 - val_acc: 0.6867\n",
      "Epoch 126/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4729 - acc: 0.7729 val_auc: 75.6353%\n",
      "Epoch 00126: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.4730 - acc: 0.7729 - val_loss: 0.6420 - val_acc: 0.6865\n",
      "Epoch 127/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4715 - acc: 0.7738 val_auc: 75.7843%\n",
      "Epoch 00127: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4713 - acc: 0.7739 - val_loss: 0.6400 - val_acc: 0.6880\n",
      "Epoch 128/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4701 - acc: 0.7744 val_auc: 75.6583%\n",
      "Epoch 00128: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4702 - acc: 0.7743 - val_loss: 0.6416 - val_acc: 0.6880\n",
      "Epoch 129/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4680 - acc: 0.7763 val_auc: 75.6732%\n",
      "Epoch 00129: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.4679 - acc: 0.7765 - val_loss: 0.6459 - val_acc: 0.6856\n",
      "Epoch 130/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4686 - acc: 0.7766 val_auc: 75.7404%\n",
      "Epoch 00130: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4688 - acc: 0.7765 - val_loss: 0.6434 - val_acc: 0.6889\n",
      "Epoch 131/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4659 - acc: 0.7775 val_auc: 75.7235%\n",
      "Epoch 00131: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4659 - acc: 0.7774 - val_loss: 0.6457 - val_acc: 0.6892\n",
      "Epoch 132/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4652 - acc: 0.7785 val_auc: 75.6902%\n",
      "Epoch 00132: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4653 - acc: 0.7786 - val_loss: 0.6466 - val_acc: 0.6884\n",
      "Epoch 133/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4630 - acc: 0.7799 val_auc: 75.5827%\n",
      "Epoch 00133: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4632 - acc: 0.7797 - val_loss: 0.6509 - val_acc: 0.6856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4637 - acc: 0.7782 val_auc: 75.5156%\n",
      "Epoch 00134: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4638 - acc: 0.7781 - val_loss: 0.6513 - val_acc: 0.6851\n",
      "Epoch 135/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4621 - acc: 0.7798 val_auc: 75.6635%\n",
      "Epoch 00135: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4620 - acc: 0.7799 - val_loss: 0.6463 - val_acc: 0.6892\n",
      "Epoch 136/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4623 - acc: 0.7796 val_auc: 75.5669%\n",
      "Epoch 00136: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.4622 - acc: 0.7797 - val_loss: 0.6478 - val_acc: 0.6864\n",
      "Epoch 137/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4611 - acc: 0.7800 val_auc: 75.5370%\n",
      "Epoch 00137: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4612 - acc: 0.7799 - val_loss: 0.6500 - val_acc: 0.6847\n",
      "Epoch 138/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4585 - acc: 0.7825 val_auc: 75.5210%\n",
      "Epoch 00138: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4585 - acc: 0.7824 - val_loss: 0.6531 - val_acc: 0.6843\n",
      "Epoch 139/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4571 - acc: 0.7836 val_auc: 75.3877%\n",
      "Epoch 00139: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4571 - acc: 0.7837 - val_loss: 0.6530 - val_acc: 0.6848\n",
      "Epoch 140/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4579 - acc: 0.7831 val_auc: 75.4700%\n",
      "Epoch 00140: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4579 - acc: 0.7830 - val_loss: 0.6534 - val_acc: 0.6866\n",
      "Epoch 141/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4577 - acc: 0.7827 val_auc: 75.5020%\n",
      "Epoch 00141: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4577 - acc: 0.7828 - val_loss: 0.6523 - val_acc: 0.6851\n",
      "Epoch 142/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4535 - acc: 0.7853 val_auc: 75.4939%\n",
      "Epoch 00142: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.4535 - acc: 0.7852 - val_loss: 0.6592 - val_acc: 0.6865\n",
      "Epoch 143/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4542 - acc: 0.7855 val_auc: 75.5644%\n",
      "Epoch 00143: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.4542 - acc: 0.7855 - val_loss: 0.6588 - val_acc: 0.6860\n",
      "Epoch 144/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4547 - acc: 0.7841 val_auc: 75.5003%\n",
      "Epoch 00144: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.4546 - acc: 0.7842 - val_loss: 0.6571 - val_acc: 0.6868\n",
      "Epoch 145/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4509 - acc: 0.7870 val_auc: 75.1764%\n",
      "Epoch 00145: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4508 - acc: 0.7870 - val_loss: 0.6609 - val_acc: 0.6830\n",
      "Epoch 146/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4492 - acc: 0.7883 val_auc: 75.3767%\n",
      "Epoch 00146: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4492 - acc: 0.7883 - val_loss: 0.6631 - val_acc: 0.6877\n",
      "Epoch 147/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4482 - acc: 0.7886 val_auc: 75.4334%\n",
      "Epoch 00147: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.4481 - acc: 0.7887 - val_loss: 0.6654 - val_acc: 0.6859\n",
      "Epoch 148/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4474 - acc: 0.7892 val_auc: 75.3161%\n",
      "Epoch 00148: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.4475 - acc: 0.7892 - val_loss: 0.6636 - val_acc: 0.6863\n",
      "Epoch 149/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4482 - acc: 0.7872 val_auc: 75.3306%\n",
      "Epoch 00149: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.4481 - acc: 0.7873 - val_loss: 0.6658 - val_acc: 0.6851\n",
      "Epoch 150/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4458 - acc: 0.7894 val_auc: 75.3261%\n",
      "Epoch 00150: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.4458 - acc: 0.7893 - val_loss: 0.6690 - val_acc: 0.6855\n",
      "Epoch 151/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4447 - acc: 0.7907 val_auc: 75.4287%\n",
      "Epoch 00151: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.4447 - acc: 0.7906 - val_loss: 0.6681 - val_acc: 0.6867\n",
      "Epoch 152/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4450 - acc: 0.7907 val_auc: 75.2852%\n",
      "Epoch 00152: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.4448 - acc: 0.7907 - val_loss: 0.6682 - val_acc: 0.6862\n",
      "Epoch 153/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4440 - acc: 0.7909 val_auc: 75.4590%\n",
      "Epoch 00153: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.4438 - acc: 0.7911 - val_loss: 0.6723 - val_acc: 0.6867\n",
      "Epoch 00153: early stopping\n"
     ]
    }
   ],
   "source": [
    "#now train\n",
    "#decrease learning rate from default of 0.001\n",
    "#increase patience to compensae to 50 from 25\n",
    "#and remove calculation of training auc to speed up\n",
    "history50_trained = nn.run_model(model=model50_trained,out_path=\"models/nn_50d_trainedv2.hdf5\",\n",
    "                                 patience=50, train_auc=False, **run_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/interim/nn50_trained_historyv2.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save history\n",
    "joblib.dump(history50_trained.history, \"data/interim/nn50_trained_historyv2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5 - Train 300d model with trainable embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "joke_seq (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 300)          8218800   \n",
      "_________________________________________________________________\n",
      "mask_paddings (Masking)      (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "drop_words (SpatialDropout1D (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "mask_dropped_words (Masking) (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "reccurrent_layer (LSTM)      (None, 150)               270600    \n",
      "_________________________________________________________________\n",
      "drop_dense (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_sigmoid (Dense)        (None, 75)                11325     \n",
      "_________________________________________________________________\n",
      "avg_pred (GlobalAverage)     (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,500,725\n",
      "Trainable params: 8,500,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "model300_trained = nn.create_model(embedding_matrix=embedding_matrix300, n_hidden=150, train_embed=True)\n",
    "model300_trained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load in weights\n",
    "model300_trained.load_weights('models/nn_300d_fixed.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171945 samples, validate on 24564 samples\n",
      "Epoch 1/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6173 - acc: 0.6594 val_auc: 74.1585%\n",
      "Epoch 00001: val_auc improved from -inf to 0.74158, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 163s 951us/step - loss: 0.6172 - acc: 0.6596 - val_loss: 0.6027 - val_acc: 0.6705\n",
      "Epoch 2/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6070 - acc: 0.6707 val_auc: 74.3723%\n",
      "Epoch 00002: val_auc improved from 0.74158 to 0.74372, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.6071 - acc: 0.6709 - val_loss: 0.6022 - val_acc: 0.6738\n",
      "Epoch 3/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6014 - acc: 0.6760 val_auc: 74.3898%\n",
      "Epoch 00003: val_auc improved from 0.74372 to 0.74390, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.6013 - acc: 0.6762 - val_loss: 0.6021 - val_acc: 0.6713\n",
      "Epoch 4/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5963 - acc: 0.6819 val_auc: 74.5688%\n",
      "Epoch 00004: val_auc improved from 0.74390 to 0.74569, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.5961 - acc: 0.6820 - val_loss: 0.5995 - val_acc: 0.6774\n",
      "Epoch 5/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5920 - acc: 0.6847 val_auc: 74.7091%\n",
      "Epoch 00005: val_auc improved from 0.74569 to 0.74709, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.5919 - acc: 0.6849 - val_loss: 0.5989 - val_acc: 0.6810\n",
      "Epoch 6/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5874 - acc: 0.6888 val_auc: 74.8616%\n",
      "Epoch 00006: val_auc improved from 0.74709 to 0.74862, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 116s 674us/step - loss: 0.5873 - acc: 0.6889 - val_loss: 0.6011 - val_acc: 0.6791\n",
      "Epoch 7/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5839 - acc: 0.6934 val_auc: 74.8790%\n",
      "Epoch 00007: val_auc improved from 0.74862 to 0.74879, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 672us/step - loss: 0.5840 - acc: 0.6932 - val_loss: 0.6023 - val_acc: 0.6792\n",
      "Epoch 8/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5795 - acc: 0.6960 val_auc: 74.8493%\n",
      "Epoch 00008: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.5795 - acc: 0.6960 - val_loss: 0.6031 - val_acc: 0.6785\n",
      "Epoch 9/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5749 - acc: 0.7001 val_auc: 74.9712%\n",
      "Epoch 00009: val_auc improved from 0.74879 to 0.74971, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.5751 - acc: 0.6999 - val_loss: 0.6028 - val_acc: 0.6806\n",
      "Epoch 10/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5712 - acc: 0.7042 val_auc: 75.0947%\n",
      "Epoch 00010: val_auc improved from 0.74971 to 0.75095, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.5712 - acc: 0.7042 - val_loss: 0.6009 - val_acc: 0.6823\n",
      "Epoch 11/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5704 - acc: 0.7055 val_auc: 75.1479%\n",
      "Epoch 00011: val_auc improved from 0.75095 to 0.75148, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.5704 - acc: 0.7055 - val_loss: 0.5993 - val_acc: 0.6843\n",
      "Epoch 12/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5676 - acc: 0.7076 val_auc: 75.1769%\n",
      "Epoch 00012: val_auc improved from 0.75148 to 0.75177, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.5675 - acc: 0.7077 - val_loss: 0.6049 - val_acc: 0.6828\n",
      "Epoch 13/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5634 - acc: 0.7106 val_auc: 75.2968%\n",
      "Epoch 00013: val_auc improved from 0.75177 to 0.75297, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.5632 - acc: 0.7106 - val_loss: 0.5998 - val_acc: 0.6866\n",
      "Epoch 14/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5593 - acc: 0.7143 val_auc: 75.1918%\n",
      "Epoch 00014: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.5594 - acc: 0.7142 - val_loss: 0.6042 - val_acc: 0.6835\n",
      "Epoch 15/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5562 - acc: 0.7161 val_auc: 75.2928%\n",
      "Epoch 00015: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.5561 - acc: 0.7160 - val_loss: 0.6052 - val_acc: 0.6861\n",
      "Epoch 16/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5547 - acc: 0.7177 val_auc: 75.3747%\n",
      "Epoch 00016: val_auc improved from 0.75297 to 0.75375, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.5546 - acc: 0.7178 - val_loss: 0.6070 - val_acc: 0.6843\n",
      "Epoch 17/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5507 - acc: 0.7210 val_auc: 75.3636%\n",
      "Epoch 00017: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.5508 - acc: 0.7208 - val_loss: 0.6076 - val_acc: 0.6862\n",
      "Epoch 18/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5499 - acc: 0.7217 val_auc: 75.3916%\n",
      "Epoch 00018: val_auc improved from 0.75375 to 0.75392, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.5499 - acc: 0.7218 - val_loss: 0.6060 - val_acc: 0.6887\n",
      "Epoch 19/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5465 - acc: 0.7240 val_auc: 75.4666%\n",
      "Epoch 00019: val_auc improved from 0.75392 to 0.75467, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.5464 - acc: 0.7241 - val_loss: 0.6064 - val_acc: 0.6887\n",
      "Epoch 20/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5424 - acc: 0.7274 val_auc: 75.4939%\n",
      "Epoch 00020: val_auc improved from 0.75467 to 0.75494, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.5427 - acc: 0.7271 - val_loss: 0.6081 - val_acc: 0.6883\n",
      "Epoch 21/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5399 - acc: 0.7290 val_auc: 75.4819%\n",
      "Epoch 00021: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.5400 - acc: 0.7288 - val_loss: 0.6118 - val_acc: 0.6871\n",
      "Epoch 22/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5389 - acc: 0.7286 val_auc: 75.4846%\n",
      "Epoch 00022: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.5389 - acc: 0.7285 - val_loss: 0.6098 - val_acc: 0.6889\n",
      "Epoch 23/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5368 - acc: 0.7312 val_auc: 75.5395%\n",
      "Epoch 00023: val_auc improved from 0.75494 to 0.75539, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.5368 - acc: 0.7312 - val_loss: 0.6103 - val_acc: 0.6890\n",
      "Epoch 24/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5321 - acc: 0.7340 val_auc: 75.5574%\n",
      "Epoch 00024: val_auc improved from 0.75539 to 0.75557, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.5319 - acc: 0.7341 - val_loss: 0.6135 - val_acc: 0.6873\n",
      "Epoch 25/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5304 - acc: 0.7359 val_auc: 75.4779%\n",
      "Epoch 00025: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.5304 - acc: 0.7359 - val_loss: 0.6115 - val_acc: 0.6885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5260 - acc: 0.7398 val_auc: 75.4316%\n",
      "Epoch 00026: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.5259 - acc: 0.7397 - val_loss: 0.6147 - val_acc: 0.6887\n",
      "Epoch 27/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5235 - acc: 0.7417 val_auc: 75.5575%\n",
      "Epoch 00027: val_auc improved from 0.75557 to 0.75557, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.5236 - acc: 0.7418 - val_loss: 0.6165 - val_acc: 0.6878\n",
      "Epoch 28/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5213 - acc: 0.7420 val_auc: 75.4323%\n",
      "Epoch 00028: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.5213 - acc: 0.7422 - val_loss: 0.6181 - val_acc: 0.6882\n",
      "Epoch 29/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5198 - acc: 0.7427 val_auc: 75.4517%\n",
      "Epoch 00029: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.5200 - acc: 0.7427 - val_loss: 0.6183 - val_acc: 0.6885\n",
      "Epoch 30/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5169 - acc: 0.7446 val_auc: 75.4356%\n",
      "Epoch 00030: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.5168 - acc: 0.7447 - val_loss: 0.6203 - val_acc: 0.6872\n",
      "Epoch 31/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5143 - acc: 0.7473 val_auc: 75.4846%\n",
      "Epoch 00031: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.5143 - acc: 0.7473 - val_loss: 0.6205 - val_acc: 0.6877\n",
      "Epoch 32/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5115 - acc: 0.7495 val_auc: 75.5230%\n",
      "Epoch 00032: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.5115 - acc: 0.7494 - val_loss: 0.6201 - val_acc: 0.6904\n",
      "Epoch 33/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5092 - acc: 0.7514 val_auc: 75.4969%\n",
      "Epoch 00033: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.5094 - acc: 0.7513 - val_loss: 0.6234 - val_acc: 0.6878\n",
      "Epoch 34/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5059 - acc: 0.7541 val_auc: 75.4962%\n",
      "Epoch 00034: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.5059 - acc: 0.7540 - val_loss: 0.6258 - val_acc: 0.6889\n",
      "Epoch 35/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5033 - acc: 0.7553 val_auc: 75.5441%\n",
      "Epoch 00035: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.5034 - acc: 0.7554 - val_loss: 0.6292 - val_acc: 0.6889\n",
      "Epoch 36/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5014 - acc: 0.7552 val_auc: 75.5723%\n",
      "Epoch 00036: val_auc improved from 0.75557 to 0.75572, saving model to models/nn_300d_trainedv2.hdf5\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.5014 - acc: 0.7552 - val_loss: 0.6274 - val_acc: 0.6888\n",
      "Epoch 37/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4990 - acc: 0.7573 val_auc: 75.5070%\n",
      "Epoch 00037: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4992 - acc: 0.7572 - val_loss: 0.6314 - val_acc: 0.6882\n",
      "Epoch 38/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4960 - acc: 0.7584 val_auc: 75.4174%\n",
      "Epoch 00038: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.4959 - acc: 0.7585 - val_loss: 0.6348 - val_acc: 0.6882\n",
      "Epoch 39/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4929 - acc: 0.7617 val_auc: 75.3767%\n",
      "Epoch 00039: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.4929 - acc: 0.7618 - val_loss: 0.6368 - val_acc: 0.6878\n",
      "Epoch 40/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4921 - acc: 0.7628 val_auc: 75.4303%\n",
      "Epoch 00040: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4921 - acc: 0.7629 - val_loss: 0.6380 - val_acc: 0.6878\n",
      "Epoch 41/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4885 - acc: 0.7646 val_auc: 75.4513%\n",
      "Epoch 00041: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.4885 - acc: 0.7647 - val_loss: 0.6384 - val_acc: 0.6884\n",
      "Epoch 42/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4865 - acc: 0.7657 val_auc: 75.3595%\n",
      "Epoch 00042: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4864 - acc: 0.7658 - val_loss: 0.6416 - val_acc: 0.6876\n",
      "Epoch 43/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4843 - acc: 0.7664 val_auc: 75.2122%\n",
      "Epoch 00043: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4843 - acc: 0.7663 - val_loss: 0.6435 - val_acc: 0.6862\n",
      "Epoch 44/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4817 - acc: 0.7689 val_auc: 75.2731%\n",
      "Epoch 00044: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4816 - acc: 0.7690 - val_loss: 0.6465 - val_acc: 0.6856\n",
      "Epoch 45/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4800 - acc: 0.7700 val_auc: 75.2384%\n",
      "Epoch 00045: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4800 - acc: 0.7700 - val_loss: 0.6476 - val_acc: 0.6855\n",
      "Epoch 46/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4782 - acc: 0.7713 val_auc: 75.2717%\n",
      "Epoch 00046: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.4784 - acc: 0.7712 - val_loss: 0.6458 - val_acc: 0.6872\n",
      "Epoch 47/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4739 - acc: 0.7734 val_auc: 75.1972%\n",
      "Epoch 00047: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.4740 - acc: 0.7733 - val_loss: 0.6544 - val_acc: 0.6851\n",
      "Epoch 48/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4713 - acc: 0.7753 val_auc: 75.0557%\n",
      "Epoch 00048: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4715 - acc: 0.7752 - val_loss: 0.6566 - val_acc: 0.6827\n",
      "Epoch 49/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4700 - acc: 0.7755 val_auc: 75.1359%\n",
      "Epoch 00049: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4703 - acc: 0.7753 - val_loss: 0.6587 - val_acc: 0.6841\n",
      "Epoch 50/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4679 - acc: 0.7756 val_auc: 75.1647%\n",
      "Epoch 00050: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4680 - acc: 0.7756 - val_loss: 0.6601 - val_acc: 0.6845\n",
      "Epoch 51/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4667 - acc: 0.7773 val_auc: 75.0781%\n",
      "Epoch 00051: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4667 - acc: 0.7772 - val_loss: 0.6632 - val_acc: 0.6843\n",
      "Epoch 52/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4640 - acc: 0.7802 val_auc: 75.0209%\n",
      "Epoch 00052: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4638 - acc: 0.7804 - val_loss: 0.6690 - val_acc: 0.6853\n",
      "Epoch 53/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4614 - acc: 0.7815 val_auc: 74.9509%\n",
      "Epoch 00053: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.4614 - acc: 0.7814 - val_loss: 0.6698 - val_acc: 0.6823\n",
      "Epoch 54/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4593 - acc: 0.7826 val_auc: 74.9354%\n",
      "Epoch 00054: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4592 - acc: 0.7826 - val_loss: 0.6702 - val_acc: 0.6843\n",
      "Epoch 55/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4553 - acc: 0.7849 val_auc: 74.9524%\n",
      "Epoch 00055: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.4553 - acc: 0.7848 - val_loss: 0.6737 - val_acc: 0.6842\n",
      "Epoch 56/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4556 - acc: 0.7841 val_auc: 74.9975%\n",
      "Epoch 00056: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4555 - acc: 0.7842 - val_loss: 0.6775 - val_acc: 0.6847\n",
      "Epoch 57/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4522 - acc: 0.7858 val_auc: 74.8628%\n",
      "Epoch 00057: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4521 - acc: 0.7859 - val_loss: 0.6817 - val_acc: 0.6848\n",
      "Epoch 58/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4506 - acc: 0.7874 val_auc: 74.8823%\n",
      "Epoch 00058: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.4507 - acc: 0.7874 - val_loss: 0.6803 - val_acc: 0.6855\n",
      "Epoch 59/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4483 - acc: 0.7893 val_auc: 74.7435%\n",
      "Epoch 00059: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.4485 - acc: 0.7892 - val_loss: 0.6835 - val_acc: 0.6833\n",
      "Epoch 60/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4466 - acc: 0.7903 val_auc: 74.7843%\n",
      "Epoch 00060: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4466 - acc: 0.7903 - val_loss: 0.6874 - val_acc: 0.6840\n",
      "Epoch 61/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4436 - acc: 0.7916 val_auc: 74.6870%\n",
      "Epoch 00061: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4437 - acc: 0.7916 - val_loss: 0.6915 - val_acc: 0.6836\n",
      "Epoch 62/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4425 - acc: 0.7928 val_auc: 74.6499%\n",
      "Epoch 00062: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4425 - acc: 0.7928 - val_loss: 0.6909 - val_acc: 0.6834\n",
      "Epoch 63/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4414 - acc: 0.7930 val_auc: 74.6616%\n",
      "Epoch 00063: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4416 - acc: 0.7928 - val_loss: 0.6964 - val_acc: 0.6823\n",
      "Epoch 64/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4379 - acc: 0.7955 val_auc: 74.5969%\n",
      "Epoch 00064: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4381 - acc: 0.7954 - val_loss: 0.7006 - val_acc: 0.6817\n",
      "Epoch 65/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4358 - acc: 0.7961 val_auc: 74.5422%\n",
      "Epoch 00065: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.4358 - acc: 0.7962 - val_loss: 0.6992 - val_acc: 0.6833\n",
      "Epoch 66/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4348 - acc: 0.7979 val_auc: 74.4738%\n",
      "Epoch 00066: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4348 - acc: 0.7979 - val_loss: 0.7042 - val_acc: 0.6817\n",
      "Epoch 67/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4311 - acc: 0.7991 val_auc: 74.4233%\n",
      "Epoch 00067: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4310 - acc: 0.7991 - val_loss: 0.7138 - val_acc: 0.6800\n",
      "Epoch 68/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4279 - acc: 0.8014 val_auc: 74.4372%\n",
      "Epoch 00068: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4279 - acc: 0.8013 - val_loss: 0.7144 - val_acc: 0.6799\n",
      "Epoch 69/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4286 - acc: 0.8002 val_auc: 74.3492%\n",
      "Epoch 00069: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4289 - acc: 0.8000 - val_loss: 0.7146 - val_acc: 0.6798\n",
      "Epoch 70/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4256 - acc: 0.8027 val_auc: 74.3409%\n",
      "Epoch 00070: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4257 - acc: 0.8026 - val_loss: 0.7189 - val_acc: 0.6786\n",
      "Epoch 71/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4233 - acc: 0.8041 val_auc: 74.3024%\n",
      "Epoch 00071: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4234 - acc: 0.8040 - val_loss: 0.7229 - val_acc: 0.6780\n",
      "Epoch 72/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4207 - acc: 0.8063 val_auc: 74.2239%\n",
      "Epoch 00072: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.4205 - acc: 0.8064 - val_loss: 0.7242 - val_acc: 0.6780\n",
      "Epoch 73/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4189 - acc: 0.8054 val_auc: 74.2392%\n",
      "Epoch 00073: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4189 - acc: 0.8052 - val_loss: 0.7300 - val_acc: 0.6792\n",
      "Epoch 74/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4185 - acc: 0.8059 val_auc: 74.1823%\n",
      "Epoch 00074: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.4184 - acc: 0.8059 - val_loss: 0.7326 - val_acc: 0.6779\n",
      "Epoch 75/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4157 - acc: 0.8083 val_auc: 74.0601%\n",
      "Epoch 00075: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.4157 - acc: 0.8083 - val_loss: 0.7368 - val_acc: 0.6769\n",
      "Epoch 76/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4136 - acc: 0.8079 val_auc: 74.1069%\n",
      "Epoch 00076: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.4138 - acc: 0.8078 - val_loss: 0.7409 - val_acc: 0.6775\n",
      "Epoch 77/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4128 - acc: 0.8099 val_auc: 74.1556%\n",
      "Epoch 00077: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.4125 - acc: 0.8100 - val_loss: 0.7406 - val_acc: 0.6769\n",
      "Epoch 78/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4100 - acc: 0.8102 val_auc: 74.0984%\n",
      "Epoch 00078: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4100 - acc: 0.8102 - val_loss: 0.7440 - val_acc: 0.6776\n",
      "Epoch 79/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4081 - acc: 0.8121 val_auc: 74.1418%\n",
      "Epoch 00079: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.4084 - acc: 0.8119 - val_loss: 0.7455 - val_acc: 0.6779\n",
      "Epoch 80/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4064 - acc: 0.8131 val_auc: 74.0749%\n",
      "Epoch 00080: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4066 - acc: 0.8129 - val_loss: 0.7483 - val_acc: 0.6769\n",
      "Epoch 81/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4035 - acc: 0.8151 val_auc: 74.0179%\n",
      "Epoch 00081: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.4034 - acc: 0.8152 - val_loss: 0.7540 - val_acc: 0.6764\n",
      "Epoch 82/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4040 - acc: 0.8136 val_auc: 73.9662%\n",
      "Epoch 00082: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.4040 - acc: 0.8136 - val_loss: 0.7577 - val_acc: 0.6768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4009 - acc: 0.8160 val_auc: 74.0169%\n",
      "Epoch 00083: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.4008 - acc: 0.8160 - val_loss: 0.7574 - val_acc: 0.6776\n",
      "Epoch 84/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.3987 - acc: 0.8165 val_auc: 73.8350%\n",
      "Epoch 00084: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.3986 - acc: 0.8165 - val_loss: 0.7653 - val_acc: 0.6755\n",
      "Epoch 85/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.3977 - acc: 0.8174 val_auc: 73.8901%\n",
      "Epoch 00085: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.3979 - acc: 0.8174 - val_loss: 0.7657 - val_acc: 0.6759\n",
      "Epoch 86/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.3968 - acc: 0.8177 val_auc: 73.8496%\n",
      "Epoch 00086: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.3969 - acc: 0.8177 - val_loss: 0.7705 - val_acc: 0.6774\n",
      "Epoch 00086: early stopping\n",
      "Wall time: 2h 46min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history300_trained = nn.run_model(model=model300_trained, out_path=\"models/nn_300d_trainedv2.hdf5\",\n",
    "                                  patience=50, train_auc=False, **run_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save history\n",
    "joblib.dump(history300_trained.history, \"data/interim/nn300_trained_historyv2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/interim/nn50_trainedv2_history.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1bf808ac109f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#load histories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"nn50_fixed\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"nn300_fixed\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"nn50_trainedv2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"nn300_trainedv2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhist_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/interim/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_history.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mhist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-1bf808ac109f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#load histories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"nn50_fixed\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"nn300_fixed\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"nn50_trainedv2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"nn300_trainedv2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhist_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/interim/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_history.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mhist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_basestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/interim/nn50_trainedv2_history.pkl'"
     ]
    }
   ],
   "source": [
    "#load histories\n",
    "model_names = (\"nn50_fixed\",\"nn300_fixed\",\"nn50_trained\",\"nn300_trainedv2\")\n",
    "hist_list = [joblib.load(\"data/interim/\"+hist+\"_history.pkl\") for hist in model_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model50_trained.load_weights(\"models/nn_50d_trainedv2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model50_trained.predict(test[\"seqs\"], batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6847860933993517"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.squeeze(preds > .5) == test[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1860c72ce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_plot(np.expand_dims(test[\"labels\"],1),\n",
    "                    [preds],\n",
    "                    [\"nn\"],\n",
    "                    'reports/figures/nn.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
