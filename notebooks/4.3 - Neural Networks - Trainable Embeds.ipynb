{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook train four different models that make use of the pretrained embeddings with 50 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.1 Load Packages and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.externals import joblib\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.join(os.getcwd(), os.pardir)\n",
    "os.chdir(PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import src.neural_networks as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "nn = reload(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2- Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and validation neural network data sets if they are present, otherwise raise an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load sequnces\n",
    "try:\n",
    "    train = joblib.load('data/processed/train_nn.pkl')\n",
    "    valid = joblib.load('data/processed/valid_nn.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load embedding matrix of 50 dimensions\n",
    "try:\n",
    "    embedding_matrix50 = joblib.load('data/interim/embeddings50.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load embedding matrix of 300 dimensions\n",
    "try:\n",
    "    embedding_matrix300 = joblib.load('data/interim/embeddings300.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these arguments will be the same when training both models\n",
    "run_args = {\"train\":(train[\"seqs\"],train[\"labels\"]),\n",
    "            \"valid\":(valid[\"seqs\"],valid[\"labels\"])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Train 50d model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM, average final\n",
    "model50_trained = nn.create_model(embedding_matrix=embedding_matrix50, n_hidden=150, train_embed=True)\n",
    "model50_trained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nn.run_model(model=model50_trained_embeds, out_path=\"models/nn_50d_trained.hdf5\",**run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - 300d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second model 300 dimensionhal word embeddings. However the number of hidden units is decreases in order mtianta  aprocaml the same number of trainable paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "joke_seq (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 300)          8218800   \n",
      "_________________________________________________________________\n",
      "mask_paddings (Masking)      (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "drop_words (SpatialDropout1D (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "mask_dropped_words (Masking) (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "reccurrent_layer (LSTM)      (None, 150)               270600    \n",
      "_________________________________________________________________\n",
      "drop_rnn_outputs (Dropout)   (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_sigmoid (Dense)        (None, 75)                11325     \n",
      "_________________________________________________________________\n",
      "avg_pred (GlobalAverage)     (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,500,725\n",
      "Trainable params: 8,500,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM, average final\n",
    "model300_trained = nn.create_model(embedding_matrix=embedding_matrix300, n_hidden=150, train_embed=True)\n",
    "model300_trained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171945 samples, validate on 24564 samples\n",
      "Epoch 1/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6625 - acc: 0.5963Epoch 00001: val_loss improved from inf to 0.64586, saving model to models/nn_300d_train_embeds.hdf5\n",
      "171945/171945 [==============================] - 157s 914us/step - loss: 0.6625 - acc: 0.5963 - val_loss: 0.6459 - val_acc: 0.6284\n",
      "Epoch 2/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6443 - acc: 0.6284Epoch 00002: val_loss improved from 0.64586 to 0.63680, saving model to models/nn_300d_train_embeds.hdf5\n",
      "171945/171945 [==============================] - 108s 630us/step - loss: 0.6443 - acc: 0.6285 - val_loss: 0.6368 - val_acc: 0.6431\n",
      "Epoch 3/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6353 - acc: 0.6428Epoch 00003: val_loss improved from 0.63680 to 0.62812, saving model to models/nn_300d_train_embeds.hdf5\n",
      "171945/171945 [==============================] - 108s 628us/step - loss: 0.6351 - acc: 0.6431 - val_loss: 0.6281 - val_acc: 0.6529\n",
      "Epoch 4/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6244 - acc: 0.6570Epoch 00004: val_loss improved from 0.62812 to 0.62100, saving model to models/nn_300d_train_embeds.hdf5\n",
      "171945/171945 [==============================] - 109s 636us/step - loss: 0.6244 - acc: 0.6570 - val_loss: 0.6210 - val_acc: 0.6628\n",
      "Epoch 5/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6119 - acc: 0.6714Epoch 00005: val_loss improved from 0.62100 to 0.61441, saving model to models/nn_300d_train_embeds.hdf5\n",
      "171945/171945 [==============================] - 109s 636us/step - loss: 0.6118 - acc: 0.6714 - val_loss: 0.6144 - val_acc: 0.6691\n",
      "Epoch 6/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6012 - acc: 0.6816Epoch 00006: val_loss improved from 0.61441 to 0.61023, saving model to models/nn_300d_train_embeds.hdf5\n",
      "171945/171945 [==============================] - 109s 631us/step - loss: 0.6013 - acc: 0.6815 - val_loss: 0.6102 - val_acc: 0.6763\n",
      "Epoch 7/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5948 - acc: 0.6873"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nn.run_model(model=model300_trained, out_path=\"models/nn_300d_trained.hdf5\", **run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='reports/figures/nn_300d.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
