{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook train four different models that make use of the pretrained embeddings with 50 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.1 Load Packages and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.externals import joblib\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.join(os.getcwd(), os.pardir)\n",
    "os.chdir(PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import src.neural_networks as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "nn = reload(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2- Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and validation neural network data sets if they are present, otherwise raise an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load sequnces\n",
    "try:\n",
    "    train = joblib.load('data/processed/train_nn.pkl')\n",
    "    valid = joblib.load('data/processed/valid_nn.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load embedding matrix of 50 dimensions\n",
    "try:\n",
    "    embedding_matrix50 = joblib.load('data/interim/embeddings50.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load embedding matrix of 300 dimensions\n",
    "try:\n",
    "    embedding_matrix300 = joblib.load('data/interim/embeddings300.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these arguments will be the same when training both models\n",
    "run_args = {\"train\":(train[\"seqs\"],train[\"labels\"]),\n",
    "            \"valid\":(valid[\"seqs\"],valid[\"labels\"])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Train 50d model with fixed embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "joke_seq (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 50)           1369800   \n",
      "_________________________________________________________________\n",
      "mask_paddings (Masking)      (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "drop_words (SpatialDropout1D (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "mask_dropped_words (Masking) (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "rnn (LSTM)                   (None, 150)               120600    \n",
      "_________________________________________________________________\n",
      "dense_drop (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_sigmoid (Dense)        (None, 75)                11325     \n",
      "_________________________________________________________________\n",
      "avg_pred (GlobalAverage)     (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,501,725\n",
      "Trainable params: 131,925\n",
      "Non-trainable params: 1,369,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM, average final\n",
    "model50_fixed = nn.create_model(embedding_matrix=embedding_matrix50, n_hidden=150, train_embed=False)\n",
    "model50_fixed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output model as svg plot\n",
    "plot_model(model50_fixed, to_file='reports/figures/nn_50d.svg', show_shapes =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171945 samples, validate on 24564 samples\n",
      "Epoch 1/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6646 - acc: 0.5913Epoch 00001: val_loss improved from inf to 0.65362, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 147s 853us/step - loss: 0.6645 - acc: 0.5915 - val_loss: 0.6536 - val_acc: 0.6050\n",
      "Epoch 2/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6526 - acc: 0.6063Epoch 00002: val_loss improved from 0.65362 to 0.64819, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 91s 528us/step - loss: 0.6525 - acc: 0.6063 - val_loss: 0.6482 - val_acc: 0.6091\n",
      "Epoch 3/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6486 - acc: 0.6123Epoch 00003: val_loss improved from 0.64819 to 0.64246, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 90s 522us/step - loss: 0.6486 - acc: 0.6123 - val_loss: 0.6425 - val_acc: 0.6160\n",
      "Epoch 4/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6456 - acc: 0.6157Epoch 00004: val_loss improved from 0.64246 to 0.64172, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 91s 528us/step - loss: 0.6455 - acc: 0.6158 - val_loss: 0.6417 - val_acc: 0.6219\n",
      "Epoch 5/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6443 - acc: 0.6193Epoch 00005: val_loss improved from 0.64172 to 0.63902, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 90s 522us/step - loss: 0.6444 - acc: 0.6192 - val_loss: 0.6390 - val_acc: 0.6229\n",
      "Epoch 6/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6422 - acc: 0.6222Epoch 00006: val_loss did not improve\n",
      "171945/171945 [==============================] - 91s 526us/step - loss: 0.6422 - acc: 0.6221 - val_loss: 0.6391 - val_acc: 0.6264\n",
      "Epoch 7/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6411 - acc: 0.6245Epoch 00007: val_loss improved from 0.63902 to 0.63578, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6411 - acc: 0.6245 - val_loss: 0.6358 - val_acc: 0.6308\n",
      "Epoch 8/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6391 - acc: 0.6279Epoch 00008: val_loss improved from 0.63578 to 0.63360, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 91s 527us/step - loss: 0.6391 - acc: 0.6279 - val_loss: 0.6336 - val_acc: 0.6375\n",
      "Epoch 9/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6366 - acc: 0.6315Epoch 00009: val_loss improved from 0.63360 to 0.63221, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 91s 527us/step - loss: 0.6367 - acc: 0.6315 - val_loss: 0.6322 - val_acc: 0.6380\n",
      "Epoch 10/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6359 - acc: 0.6332Epoch 00010: val_loss improved from 0.63221 to 0.63213, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 91s 529us/step - loss: 0.6360 - acc: 0.6331 - val_loss: 0.6321 - val_acc: 0.6380\n",
      "Epoch 11/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6338 - acc: 0.6379Epoch 00011: val_loss improved from 0.63213 to 0.63048, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 90s 522us/step - loss: 0.6340 - acc: 0.6377 - val_loss: 0.6305 - val_acc: 0.6394\n",
      "Epoch 12/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6321 - acc: 0.6376Epoch 00012: val_loss improved from 0.63048 to 0.62750, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 91s 529us/step - loss: 0.6321 - acc: 0.6377 - val_loss: 0.6275 - val_acc: 0.6461\n",
      "Epoch 13/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6303 - acc: 0.6417Epoch 00013: val_loss improved from 0.62750 to 0.62742, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 90s 521us/step - loss: 0.6304 - acc: 0.6415 - val_loss: 0.6274 - val_acc: 0.6418\n",
      "Epoch 14/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6288 - acc: 0.6445Epoch 00014: val_loss improved from 0.62742 to 0.62530, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 89s 518us/step - loss: 0.6287 - acc: 0.6445 - val_loss: 0.6253 - val_acc: 0.6466\n",
      "Epoch 15/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6275 - acc: 0.6450Epoch 00015: val_loss did not improve\n",
      "171945/171945 [==============================] - 89s 518us/step - loss: 0.6275 - acc: 0.6450 - val_loss: 0.6264 - val_acc: 0.6455\n",
      "Epoch 16/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6258 - acc: 0.6476Epoch 00016: val_loss improved from 0.62530 to 0.62286, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 91s 527us/step - loss: 0.6259 - acc: 0.6473 - val_loss: 0.6229 - val_acc: 0.6510\n",
      "Epoch 17/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6243 - acc: 0.6487Epoch 00017: val_loss improved from 0.62286 to 0.62252, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 90s 521us/step - loss: 0.6242 - acc: 0.6489 - val_loss: 0.6225 - val_acc: 0.6478\n",
      "Epoch 18/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6233 - acc: 0.6517Epoch 00018: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 523us/step - loss: 0.6233 - acc: 0.6517 - val_loss: 0.6227 - val_acc: 0.6485\n",
      "Epoch 19/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6218 - acc: 0.6522Epoch 00019: val_loss improved from 0.62252 to 0.62006, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 89s 517us/step - loss: 0.6218 - acc: 0.6521 - val_loss: 0.6201 - val_acc: 0.6557\n",
      "Epoch 20/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6205 - acc: 0.6544Epoch 00020: val_loss improved from 0.62006 to 0.61911, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 90s 523us/step - loss: 0.6206 - acc: 0.6543 - val_loss: 0.6191 - val_acc: 0.6556\n",
      "Epoch 21/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6197 - acc: 0.6553Epoch 00021: val_loss improved from 0.61911 to 0.61881, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 90s 523us/step - loss: 0.6197 - acc: 0.6555 - val_loss: 0.6188 - val_acc: 0.6566\n",
      "Epoch 22/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6177 - acc: 0.6568Epoch 00022: val_loss improved from 0.61881 to 0.61811, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 89s 520us/step - loss: 0.6177 - acc: 0.6567 - val_loss: 0.6181 - val_acc: 0.6557\n",
      "Epoch 23/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6174 - acc: 0.6583Epoch 00023: val_loss did not improve\n",
      "171945/171945 [==============================] - 89s 515us/step - loss: 0.6174 - acc: 0.6581 - val_loss: 0.6188 - val_acc: 0.6538\n",
      "Epoch 24/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6153 - acc: 0.6598Epoch 00024: val_loss improved from 0.61811 to 0.61743, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 90s 523us/step - loss: 0.6153 - acc: 0.6597 - val_loss: 0.6174 - val_acc: 0.6552\n",
      "Epoch 25/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6141 - acc: 0.6613Epoch 00025: val_loss improved from 0.61743 to 0.61713, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6141 - acc: 0.6613 - val_loss: 0.6171 - val_acc: 0.6582\n",
      "Epoch 26/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6132 - acc: 0.6617Epoch 00026: val_loss improved from 0.61713 to 0.61491, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 90s 523us/step - loss: 0.6133 - acc: 0.6617 - val_loss: 0.6149 - val_acc: 0.6605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6122 - acc: 0.6636Epoch 00027: val_loss did not improve\n",
      "171945/171945 [==============================] - 92s 533us/step - loss: 0.6121 - acc: 0.6636 - val_loss: 0.6171 - val_acc: 0.6565\n",
      "Epoch 28/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6112 - acc: 0.6644Epoch 00028: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6113 - acc: 0.6642 - val_loss: 0.6162 - val_acc: 0.6589\n",
      "Epoch 29/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6108 - acc: 0.6661Epoch 00029: val_loss improved from 0.61491 to 0.61397, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6106 - acc: 0.6663 - val_loss: 0.6140 - val_acc: 0.6608\n",
      "Epoch 30/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6089 - acc: 0.6677Epoch 00030: val_loss did not improve\n",
      "171945/171945 [==============================] - 91s 531us/step - loss: 0.6090 - acc: 0.6676 - val_loss: 0.6141 - val_acc: 0.6617\n",
      "Epoch 31/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6084 - acc: 0.6678Epoch 00031: val_loss improved from 0.61397 to 0.61381, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 89s 519us/step - loss: 0.6085 - acc: 0.6677 - val_loss: 0.6138 - val_acc: 0.6620\n",
      "Epoch 32/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6068 - acc: 0.6695Epoch 00032: val_loss improved from 0.61381 to 0.61252, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6069 - acc: 0.6694 - val_loss: 0.6125 - val_acc: 0.6607\n",
      "Epoch 33/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6070 - acc: 0.6689Epoch 00033: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6070 - acc: 0.6689 - val_loss: 0.6130 - val_acc: 0.6614\n",
      "Epoch 34/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6056 - acc: 0.6703Epoch 00034: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6054 - acc: 0.6705 - val_loss: 0.6125 - val_acc: 0.6622\n",
      "Epoch 35/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6052 - acc: 0.6711Epoch 00035: val_loss did not improve\n",
      "171945/171945 [==============================] - 91s 526us/step - loss: 0.6051 - acc: 0.6711 - val_loss: 0.6132 - val_acc: 0.6631\n",
      "Epoch 36/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6044 - acc: 0.6714Epoch 00036: val_loss did not improve\n",
      "171945/171945 [==============================] - 91s 527us/step - loss: 0.6045 - acc: 0.6712 - val_loss: 0.6136 - val_acc: 0.6611\n",
      "Epoch 37/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6030 - acc: 0.6738Epoch 00037: val_loss improved from 0.61252 to 0.61128, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 89s 515us/step - loss: 0.6028 - acc: 0.6740 - val_loss: 0.6113 - val_acc: 0.6635\n",
      "Epoch 38/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6025 - acc: 0.6736Epoch 00038: val_loss improved from 0.61128 to 0.61067, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 90s 523us/step - loss: 0.6026 - acc: 0.6736 - val_loss: 0.6107 - val_acc: 0.6648\n",
      "Epoch 39/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6014 - acc: 0.6758Epoch 00039: val_loss improved from 0.61067 to 0.61010, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 89s 516us/step - loss: 0.6013 - acc: 0.6760 - val_loss: 0.6101 - val_acc: 0.6648\n",
      "Epoch 40/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6003 - acc: 0.6758Epoch 00040: val_loss did not improve\n",
      "171945/171945 [==============================] - 89s 517us/step - loss: 0.6003 - acc: 0.6758 - val_loss: 0.6111 - val_acc: 0.6658\n",
      "Epoch 41/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5992 - acc: 0.6770Epoch 00041: val_loss did not improve\n",
      "171945/171945 [==============================] - 89s 515us/step - loss: 0.5991 - acc: 0.6772 - val_loss: 0.6107 - val_acc: 0.6636\n",
      "Epoch 42/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5990 - acc: 0.6788Epoch 00042: val_loss did not improve\n",
      "171945/171945 [==============================] - 89s 516us/step - loss: 0.5990 - acc: 0.6788 - val_loss: 0.6109 - val_acc: 0.6667\n",
      "Epoch 43/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5980 - acc: 0.6794Epoch 00043: val_loss did not improve\n",
      "171945/171945 [==============================] - 89s 515us/step - loss: 0.5980 - acc: 0.6794 - val_loss: 0.6113 - val_acc: 0.6632\n",
      "Epoch 44/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5984 - acc: 0.6781Epoch 00044: val_loss did not improve\n",
      "171945/171945 [==============================] - 89s 515us/step - loss: 0.5984 - acc: 0.6782 - val_loss: 0.6129 - val_acc: 0.6632\n",
      "Epoch 45/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5977 - acc: 0.6777Epoch 00045: val_loss did not improve\n",
      "171945/171945 [==============================] - 89s 515us/step - loss: 0.5976 - acc: 0.6780 - val_loss: 0.6135 - val_acc: 0.6613\n",
      "Epoch 46/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5958 - acc: 0.6817Epoch 00046: val_loss improved from 0.61010 to 0.60957, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 89s 515us/step - loss: 0.5959 - acc: 0.6816 - val_loss: 0.6096 - val_acc: 0.6654\n",
      "Epoch 47/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5952 - acc: 0.6817Epoch 00047: val_loss did not improve\n",
      "171945/171945 [==============================] - 89s 515us/step - loss: 0.5954 - acc: 0.6815 - val_loss: 0.6107 - val_acc: 0.6652\n",
      "Epoch 48/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5945 - acc: 0.6807Epoch 00048: val_loss did not improve\n",
      "171945/171945 [==============================] - 89s 517us/step - loss: 0.5947 - acc: 0.6805 - val_loss: 0.6105 - val_acc: 0.6655\n",
      "Epoch 49/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5933 - acc: 0.6825Epoch 00049: val_loss did not improve\n",
      "171945/171945 [==============================] - 89s 518us/step - loss: 0.5934 - acc: 0.6825 - val_loss: 0.6107 - val_acc: 0.6654\n",
      "Epoch 50/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5927 - acc: 0.6843Epoch 00050: val_loss did not improve\n",
      "171945/171945 [==============================] - 89s 519us/step - loss: 0.5927 - acc: 0.6843 - val_loss: 0.6138 - val_acc: 0.6642\n",
      "Epoch 51/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5931 - acc: 0.6837Epoch 00051: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.5931 - acc: 0.6837 - val_loss: 0.6099 - val_acc: 0.6670\n",
      "Epoch 52/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5916 - acc: 0.6851Epoch 00052: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.5917 - acc: 0.6851 - val_loss: 0.6115 - val_acc: 0.6643\n",
      "Epoch 53/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5917 - acc: 0.6851Epoch 00053: val_loss improved from 0.60957 to 0.60934, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 90s 523us/step - loss: 0.5919 - acc: 0.6850 - val_loss: 0.6093 - val_acc: 0.6683\n",
      "Epoch 54/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5912 - acc: 0.6856Epoch 00054: val_loss improved from 0.60934 to 0.60915, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 90s 521us/step - loss: 0.5914 - acc: 0.6856 - val_loss: 0.6092 - val_acc: 0.6679\n",
      "Epoch 55/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5901 - acc: 0.6869Epoch 00055: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 522us/step - loss: 0.5901 - acc: 0.6870 - val_loss: 0.6098 - val_acc: 0.6669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5886 - acc: 0.6876Epoch 00056: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.5886 - acc: 0.6878 - val_loss: 0.6102 - val_acc: 0.6674\n",
      "Epoch 57/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5888 - acc: 0.6876Epoch 00057: val_loss did not improve\n",
      "171945/171945 [==============================] - 89s 518us/step - loss: 0.5889 - acc: 0.6875 - val_loss: 0.6097 - val_acc: 0.6685\n",
      "Epoch 58/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5891 - acc: 0.6871Epoch 00058: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 522us/step - loss: 0.5892 - acc: 0.6869 - val_loss: 0.6111 - val_acc: 0.6669\n",
      "Epoch 59/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5888 - acc: 0.6872Epoch 00059: val_loss did not improve\n",
      "171945/171945 [==============================] - 89s 520us/step - loss: 0.5886 - acc: 0.6873 - val_loss: 0.6112 - val_acc: 0.6663\n",
      "Epoch 60/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5870 - acc: 0.6883Epoch 00060: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 521us/step - loss: 0.5871 - acc: 0.6884 - val_loss: 0.6100 - val_acc: 0.6686\n",
      "Epoch 61/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5868 - acc: 0.6893Epoch 00061: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.5868 - acc: 0.6896 - val_loss: 0.6096 - val_acc: 0.6679\n",
      "Epoch 62/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5860 - acc: 0.6897Epoch 00062: val_loss did not improve\n",
      "171945/171945 [==============================] - 91s 530us/step - loss: 0.5861 - acc: 0.6896 - val_loss: 0.6101 - val_acc: 0.6662\n",
      "Epoch 63/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5870 - acc: 0.6896Epoch 00063: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.5869 - acc: 0.6898 - val_loss: 0.6135 - val_acc: 0.6648\n",
      "Epoch 64/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5861 - acc: 0.6900Epoch 00064: val_loss improved from 0.60915 to 0.60840, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 91s 531us/step - loss: 0.5862 - acc: 0.6900 - val_loss: 0.6084 - val_acc: 0.6689\n",
      "Epoch 65/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5845 - acc: 0.6903Epoch 00065: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 541us/step - loss: 0.5845 - acc: 0.6903 - val_loss: 0.6086 - val_acc: 0.6678\n",
      "Epoch 66/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5851 - acc: 0.6907Epoch 00066: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 542us/step - loss: 0.5852 - acc: 0.6907 - val_loss: 0.6097 - val_acc: 0.6678\n",
      "Epoch 67/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5835 - acc: 0.6915Epoch 00067: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 543us/step - loss: 0.5835 - acc: 0.6916 - val_loss: 0.6099 - val_acc: 0.6688\n",
      "Epoch 68/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5838 - acc: 0.6926Epoch 00068: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 539us/step - loss: 0.5838 - acc: 0.6925 - val_loss: 0.6087 - val_acc: 0.6685\n",
      "Epoch 69/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5847 - acc: 0.6911Epoch 00069: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 542us/step - loss: 0.5846 - acc: 0.6913 - val_loss: 0.6127 - val_acc: 0.6659\n",
      "Epoch 70/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5830 - acc: 0.6928Epoch 00070: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 542us/step - loss: 0.5829 - acc: 0.6928 - val_loss: 0.6100 - val_acc: 0.6698\n",
      "Epoch 71/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5821 - acc: 0.6939Epoch 00071: val_loss did not improve\n",
      "171945/171945 [==============================] - 92s 535us/step - loss: 0.5825 - acc: 0.6937 - val_loss: 0.6117 - val_acc: 0.6687\n",
      "Epoch 72/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5824 - acc: 0.6939Epoch 00072: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 539us/step - loss: 0.5825 - acc: 0.6939 - val_loss: 0.6102 - val_acc: 0.6696\n",
      "Epoch 73/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5812 - acc: 0.6944Epoch 00073: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 542us/step - loss: 0.5812 - acc: 0.6943 - val_loss: 0.6103 - val_acc: 0.6685\n",
      "Epoch 74/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5804 - acc: 0.6944Epoch 00074: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 538us/step - loss: 0.5804 - acc: 0.6944 - val_loss: 0.6101 - val_acc: 0.6658\n",
      "Epoch 75/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5814 - acc: 0.6945Epoch 00075: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 540us/step - loss: 0.5813 - acc: 0.6946 - val_loss: 0.6116 - val_acc: 0.6675\n",
      "Epoch 76/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5805 - acc: 0.6954Epoch 00076: val_loss improved from 0.60840 to 0.60821, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 93s 540us/step - loss: 0.5804 - acc: 0.6955 - val_loss: 0.6082 - val_acc: 0.6681\n",
      "Epoch 77/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5801 - acc: 0.6961Epoch 00077: val_loss improved from 0.60821 to 0.60793, saving model to models/nn_50d_alt.hdf5\n",
      "171945/171945 [==============================] - 93s 540us/step - loss: 0.5800 - acc: 0.6962 - val_loss: 0.6079 - val_acc: 0.6714\n",
      "Epoch 78/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5790 - acc: 0.6974Epoch 00078: val_loss did not improve\n",
      "171945/171945 [==============================] - 92s 538us/step - loss: 0.5790 - acc: 0.6974 - val_loss: 0.6108 - val_acc: 0.6665\n",
      "Epoch 79/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5796 - acc: 0.6965Epoch 00079: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 541us/step - loss: 0.5797 - acc: 0.6963 - val_loss: 0.6105 - val_acc: 0.6714\n",
      "Epoch 80/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5775 - acc: 0.6977Epoch 00080: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 541us/step - loss: 0.5775 - acc: 0.6977 - val_loss: 0.6109 - val_acc: 0.6700\n",
      "Epoch 81/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5789 - acc: 0.6970Epoch 00081: val_loss did not improve\n",
      "171945/171945 [==============================] - 92s 536us/step - loss: 0.5789 - acc: 0.6970 - val_loss: 0.6127 - val_acc: 0.6665\n",
      "Epoch 82/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5779 - acc: 0.6971Epoch 00082: val_loss did not improve\n",
      "171945/171945 [==============================] - 131s 764us/step - loss: 0.5779 - acc: 0.6972 - val_loss: 0.6109 - val_acc: 0.6684\n",
      "Epoch 83/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5776 - acc: 0.6980Epoch 00083: val_loss did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5777 - acc: 0.6978 - val_loss: 0.6117 - val_acc: 0.6670\n",
      "Epoch 84/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5803 - acc: 0.6961Epoch 00084: val_loss did not improve\n",
      "171945/171945 [==============================] - 123s 718us/step - loss: 0.5802 - acc: 0.6961 - val_loss: 0.6101 - val_acc: 0.6685\n",
      "Epoch 85/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5765 - acc: 0.6970Epoch 00085: val_loss did not improve\n",
      "171945/171945 [==============================] - 157s 914us/step - loss: 0.5765 - acc: 0.6971 - val_loss: 0.6114 - val_acc: 0.6696\n",
      "Epoch 86/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5778 - acc: 0.6981Epoch 00086: val_loss did not improve\n",
      "171945/171945 [==============================] - 162s 941us/step - loss: 0.5782 - acc: 0.6978 - val_loss: 0.6095 - val_acc: 0.6695\n",
      "Epoch 87/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5766 - acc: 0.6985Epoch 00087: val_loss did not improve\n",
      "171945/171945 [==============================] - 154s 897us/step - loss: 0.5765 - acc: 0.6986 - val_loss: 0.6112 - val_acc: 0.6674\n",
      "Epoch 88/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5753 - acc: 0.7000Epoch 00088: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 539us/step - loss: 0.5753 - acc: 0.7000 - val_loss: 0.6105 - val_acc: 0.6692\n",
      "Epoch 89/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5762 - acc: 0.6999Epoch 00089: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 540us/step - loss: 0.5763 - acc: 0.6998 - val_loss: 0.6099 - val_acc: 0.6690\n",
      "Epoch 90/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5753 - acc: 0.6999Epoch 00090: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 539us/step - loss: 0.5755 - acc: 0.6998 - val_loss: 0.6127 - val_acc: 0.6659\n",
      "Epoch 91/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5745 - acc: 0.7003Epoch 00091: val_loss did not improve\n",
      "171945/171945 [==============================] - 92s 537us/step - loss: 0.5744 - acc: 0.7005 - val_loss: 0.6103 - val_acc: 0.6674\n",
      "Epoch 92/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5755 - acc: 0.6987Epoch 00092: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 542us/step - loss: 0.5755 - acc: 0.6987 - val_loss: 0.6120 - val_acc: 0.6676\n",
      "Epoch 93/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5737 - acc: 0.7005Epoch 00093: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 542us/step - loss: 0.5738 - acc: 0.7005 - val_loss: 0.6108 - val_acc: 0.6679\n",
      "Epoch 94/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5750 - acc: 0.7001Epoch 00094: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 541us/step - loss: 0.5751 - acc: 0.7000 - val_loss: 0.6118 - val_acc: 0.6690\n",
      "Epoch 95/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5748 - acc: 0.7004Epoch 00095: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 539us/step - loss: 0.5750 - acc: 0.7003 - val_loss: 0.6093 - val_acc: 0.6705\n",
      "Epoch 96/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5724 - acc: 0.7019Epoch 00096: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 541us/step - loss: 0.5724 - acc: 0.7018 - val_loss: 0.6120 - val_acc: 0.6691\n",
      "Epoch 97/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5735 - acc: 0.7007Epoch 00097: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 542us/step - loss: 0.5737 - acc: 0.7006 - val_loss: 0.6126 - val_acc: 0.6657\n",
      "Epoch 98/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5739 - acc: 0.7016Epoch 00098: val_loss did not improve\n",
      "171945/171945 [==============================] - 92s 537us/step - loss: 0.5738 - acc: 0.7017 - val_loss: 0.6107 - val_acc: 0.6695\n",
      "Epoch 99/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5730 - acc: 0.7018Epoch 00099: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 543us/step - loss: 0.5731 - acc: 0.7018 - val_loss: 0.6144 - val_acc: 0.6655\n",
      "Epoch 100/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5727 - acc: 0.7024Epoch 00100: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 541us/step - loss: 0.5727 - acc: 0.7025 - val_loss: 0.6104 - val_acc: 0.6718\n",
      "Epoch 101/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5722 - acc: 0.7025Epoch 00101: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 540us/step - loss: 0.5722 - acc: 0.7025 - val_loss: 0.6105 - val_acc: 0.6689\n",
      "Epoch 102/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5721 - acc: 0.7020Epoch 00102: val_loss did not improve\n",
      "171945/171945 [==============================] - 93s 540us/step - loss: 0.5722 - acc: 0.7019 - val_loss: 0.6113 - val_acc: 0.6689\n",
      "Epoch 00102: early stopping\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#now train\n",
    "nn.run_model50(model=model, out_path=\"models/nn_50d.hdf5\", **run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Train 300d model with fixed embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second model 300 dimensionhal word embeddings. However the number of hidden units is decreases in order mtianta  aprocaml the same number of trainable paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "joke_seq (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 300)          8218800   \n",
      "_________________________________________________________________\n",
      "mask_paddings (Masking)      (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "drop_words (SpatialDropout1D (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "mask_dropped_words (Masking) (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "rnn (LSTM)                   (None, 150)               270600    \n",
      "_________________________________________________________________\n",
      "dense_drop (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_sigmoid (Dense)        (None, 75)                11325     \n",
      "_________________________________________________________________\n",
      "avg_pred (GlobalAverage)     (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,500,725\n",
      "Trainable params: 281,925\n",
      "Non-trainable params: 8,218,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM, average final\n",
    "model300 = nn.create_model(embedding_matrix=embedding_matrix300, n_hidden=150)\n",
    "model300.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171945 samples, validate on 24564 samples\n",
      "Epoch 1/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6623 - acc: 0.5950Epoch 00001: val_loss improved from inf to 0.64881, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 175s 1ms/step - loss: 0.6622 - acc: 0.5952 - val_loss: 0.6488 - val_acc: 0.6179\n",
      "Epoch 2/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6491 - acc: 0.6155Epoch 00002: val_loss improved from 0.64881 to 0.64766, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.6491 - acc: 0.6155 - val_loss: 0.6477 - val_acc: 0.6256\n",
      "Epoch 3/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6471 - acc: 0.6178Epoch 00003: val_loss improved from 0.64766 to 0.64392, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.6470 - acc: 0.6178 - val_loss: 0.6439 - val_acc: 0.6219\n",
      "Epoch 4/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6510 - acc: 0.6142Epoch 00004: val_loss improved from 0.64392 to 0.64176, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.6509 - acc: 0.6144 - val_loss: 0.6418 - val_acc: 0.6277\n",
      "Epoch 5/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6409 - acc: 0.6285Epoch 00005: val_loss improved from 0.64176 to 0.63607, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 579us/step - loss: 0.6409 - acc: 0.6285 - val_loss: 0.6361 - val_acc: 0.6328\n",
      "Epoch 6/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6379 - acc: 0.6311Epoch 00006: val_loss improved from 0.63607 to 0.63264, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 99s 578us/step - loss: 0.6378 - acc: 0.6311 - val_loss: 0.6326 - val_acc: 0.6419\n",
      "Epoch 7/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6377 - acc: 0.6291Epoch 00007: val_loss did not improve\n",
      "171945/171945 [==============================] - 99s 578us/step - loss: 0.6377 - acc: 0.6290 - val_loss: 0.6445 - val_acc: 0.6246\n",
      "Epoch 8/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6408 - acc: 0.6277Epoch 00008: val_loss did not improve\n",
      "171945/171945 [==============================] - 99s 578us/step - loss: 0.6407 - acc: 0.6279 - val_loss: 0.6330 - val_acc: 0.6378\n",
      "Epoch 9/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6333 - acc: 0.6379Epoch 00009: val_loss improved from 0.63264 to 0.63078, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.6333 - acc: 0.6378 - val_loss: 0.6308 - val_acc: 0.6444\n",
      "Epoch 10/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6296 - acc: 0.6433Epoch 00010: val_loss improved from 0.63078 to 0.62615, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.6296 - acc: 0.6432 - val_loss: 0.6262 - val_acc: 0.6491\n",
      "Epoch 11/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6267 - acc: 0.6460Epoch 00011: val_loss improved from 0.62615 to 0.62489, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.6267 - acc: 0.6460 - val_loss: 0.6249 - val_acc: 0.6494\n",
      "Epoch 12/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6240 - acc: 0.6514Epoch 00012: val_loss improved from 0.62489 to 0.62278, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 99s 577us/step - loss: 0.6239 - acc: 0.6515 - val_loss: 0.6228 - val_acc: 0.6548\n",
      "Epoch 13/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6208 - acc: 0.6545Epoch 00013: val_loss improved from 0.62278 to 0.61972, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.6207 - acc: 0.6547 - val_loss: 0.6197 - val_acc: 0.6555\n",
      "Epoch 14/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6175 - acc: 0.6595Epoch 00014: val_loss did not improve\n",
      "171945/171945 [==============================] - 99s 578us/step - loss: 0.6176 - acc: 0.6593 - val_loss: 0.6199 - val_acc: 0.6550\n",
      "Epoch 15/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6149 - acc: 0.6611Epoch 00015: val_loss improved from 0.61972 to 0.61630, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.6150 - acc: 0.6609 - val_loss: 0.6163 - val_acc: 0.6571\n",
      "Epoch 16/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6122 - acc: 0.6640Epoch 00016: val_loss improved from 0.61630 to 0.61429, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.6121 - acc: 0.6642 - val_loss: 0.6143 - val_acc: 0.6602\n",
      "Epoch 17/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6087 - acc: 0.6683Epoch 00017: val_loss improved from 0.61429 to 0.61304, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.6087 - acc: 0.6683 - val_loss: 0.6130 - val_acc: 0.6602\n",
      "Epoch 18/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6058 - acc: 0.6700Epoch 00018: val_loss improved from 0.61304 to 0.61272, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.6058 - acc: 0.6699 - val_loss: 0.6127 - val_acc: 0.6656\n",
      "Epoch 19/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6020 - acc: 0.6748Epoch 00019: val_loss improved from 0.61272 to 0.60930, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.6019 - acc: 0.6749 - val_loss: 0.6093 - val_acc: 0.6669\n",
      "Epoch 20/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6001 - acc: 0.6766Epoch 00020: val_loss did not improve\n",
      "171945/171945 [==============================] - 99s 578us/step - loss: 0.6001 - acc: 0.6767 - val_loss: 0.6099 - val_acc: 0.6664\n",
      "Epoch 21/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5971 - acc: 0.6795Epoch 00021: val_loss improved from 0.60930 to 0.60694, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.5970 - acc: 0.6795 - val_loss: 0.6069 - val_acc: 0.6684\n",
      "Epoch 22/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5939 - acc: 0.6826Epoch 00022: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5938 - acc: 0.6828 - val_loss: 0.6083 - val_acc: 0.6692\n",
      "Epoch 23/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5905 - acc: 0.6867Epoch 00023: val_loss improved from 0.60694 to 0.60593, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.5906 - acc: 0.6866 - val_loss: 0.6059 - val_acc: 0.6683\n",
      "Epoch 24/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5867 - acc: 0.6900Epoch 00024: val_loss improved from 0.60593 to 0.60513, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.5867 - acc: 0.6898 - val_loss: 0.6051 - val_acc: 0.6701\n",
      "Epoch 25/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5853 - acc: 0.6909Epoch 00025: val_loss improved from 0.60513 to 0.60372, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5852 - acc: 0.6910 - val_loss: 0.6037 - val_acc: 0.6702\n",
      "Epoch 26/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5808 - acc: 0.6950Epoch 00026: val_loss improved from 0.60372 to 0.60366, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 579us/step - loss: 0.5807 - acc: 0.6950 - val_loss: 0.6037 - val_acc: 0.6730\n",
      "Epoch 27/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5779 - acc: 0.6967Epoch 00027: val_loss improved from 0.60366 to 0.60366, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 99s 577us/step - loss: 0.5779 - acc: 0.6968 - val_loss: 0.6037 - val_acc: 0.6716\n",
      "Epoch 28/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5749 - acc: 0.7008Epoch 00028: val_loss improved from 0.60366 to 0.60215, saving model to models/nn_300d.hdf5\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.5751 - acc: 0.7006 - val_loss: 0.6022 - val_acc: 0.6728\n",
      "Epoch 29/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5718 - acc: 0.7021Epoch 00029: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 579us/step - loss: 0.5717 - acc: 0.7022 - val_loss: 0.6063 - val_acc: 0.6738\n",
      "Epoch 30/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5683 - acc: 0.7054Epoch 00030: val_loss did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5685 - acc: 0.7053 - val_loss: 0.6069 - val_acc: 0.6727\n",
      "Epoch 31/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5661 - acc: 0.7081Epoch 00031: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5661 - acc: 0.7082 - val_loss: 0.6085 - val_acc: 0.6724\n",
      "Epoch 32/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5640 - acc: 0.7099Epoch 00032: val_loss did not improve\n",
      "171945/171945 [==============================] - 99s 578us/step - loss: 0.5640 - acc: 0.7099 - val_loss: 0.6052 - val_acc: 0.6724\n",
      "Epoch 33/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5604 - acc: 0.7126Epoch 00033: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5606 - acc: 0.7127 - val_loss: 0.6110 - val_acc: 0.6705\n",
      "Epoch 34/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5576 - acc: 0.7137Epoch 00034: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.5580 - acc: 0.7134 - val_loss: 0.6024 - val_acc: 0.6766\n",
      "Epoch 35/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5545 - acc: 0.7185Epoch 00035: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.5546 - acc: 0.7184 - val_loss: 0.6045 - val_acc: 0.6774\n",
      "Epoch 36/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5511 - acc: 0.7197Epoch 00036: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.5511 - acc: 0.7196 - val_loss: 0.6114 - val_acc: 0.6738\n",
      "Epoch 37/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5495 - acc: 0.7223Epoch 00037: val_loss did not improve\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5493 - acc: 0.7225 - val_loss: 0.6087 - val_acc: 0.6761\n",
      "Epoch 38/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5463 - acc: 0.7238Epoch 00038: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.5464 - acc: 0.7236 - val_loss: 0.6111 - val_acc: 0.6744\n",
      "Epoch 39/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5430 - acc: 0.7262Epoch 00039: val_loss did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5428 - acc: 0.7265 - val_loss: 0.6082 - val_acc: 0.6772\n",
      "Epoch 40/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5405 - acc: 0.7283Epoch 00040: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 579us/step - loss: 0.5407 - acc: 0.7282 - val_loss: 0.6126 - val_acc: 0.6725\n",
      "Epoch 41/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5394 - acc: 0.7294Epoch 00041: val_loss did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5391 - acc: 0.7296 - val_loss: 0.6130 - val_acc: 0.6755\n",
      "Epoch 42/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5368 - acc: 0.7313Epoch 00042: val_loss did not improve\n",
      "171945/171945 [==============================] - 99s 578us/step - loss: 0.5369 - acc: 0.7313 - val_loss: 0.6159 - val_acc: 0.6711\n",
      "Epoch 43/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5333 - acc: 0.7337Epoch 00043: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.5335 - acc: 0.7336 - val_loss: 0.6150 - val_acc: 0.6751\n",
      "Epoch 44/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5322 - acc: 0.7355Epoch 00044: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.5322 - acc: 0.7354 - val_loss: 0.6150 - val_acc: 0.6764\n",
      "Epoch 45/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5291 - acc: 0.7375Epoch 00045: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 579us/step - loss: 0.5290 - acc: 0.7375 - val_loss: 0.6158 - val_acc: 0.6757\n",
      "Epoch 46/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5272 - acc: 0.7384Epoch 00046: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5273 - acc: 0.7382 - val_loss: 0.6177 - val_acc: 0.6757\n",
      "Epoch 47/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5247 - acc: 0.7406Epoch 00047: val_loss did not improve\n",
      "171945/171945 [==============================] - 99s 578us/step - loss: 0.5247 - acc: 0.7405 - val_loss: 0.6183 - val_acc: 0.6740\n",
      "Epoch 48/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5236 - acc: 0.7404Epoch 00048: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.5237 - acc: 0.7403 - val_loss: 0.6171 - val_acc: 0.6753\n",
      "Epoch 49/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5204 - acc: 0.7429Epoch 00049: val_loss did not improve\n",
      "171945/171945 [==============================] - 99s 578us/step - loss: 0.5207 - acc: 0.7427 - val_loss: 0.6216 - val_acc: 0.6730\n",
      "Epoch 50/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5179 - acc: 0.7448Epoch 00050: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.5180 - acc: 0.7448 - val_loss: 0.6237 - val_acc: 0.6741\n",
      "Epoch 51/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5173 - acc: 0.7460Epoch 00051: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.5174 - acc: 0.7458 - val_loss: 0.6190 - val_acc: 0.6776\n",
      "Epoch 52/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5149 - acc: 0.7470Epoch 00052: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.5146 - acc: 0.7473 - val_loss: 0.6252 - val_acc: 0.6747\n",
      "Epoch 53/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5120 - acc: 0.7490Epoch 00053: val_loss did not improve\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.5122 - acc: 0.7488 - val_loss: 0.6244 - val_acc: 0.6747\n",
      "Epoch 00053: early stopping\n",
      "Wall time: 1h 30min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#now train\n",
    "nn.run_model(model=model300, out_path=\"models/nn_300d.hdf5\", **run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Train 50d model with trainable embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-9b3fda2341d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'reports/figures/nn_300d.svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \"\"\"\n\u001b[1;32m--> 131\u001b[1;33m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# pydot raises a generic Exception here,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# so no specific class can be caught.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[0;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "#LSTM, average final\n",
    "model50_trained = nn.create_model(embedding_matrix=embedding_matrix50, n_hidden=150, train_embed=True)\n",
    "model50_trained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nn.run_model(model=model50_trained_embeds, out_path=\"models/nn_50d_trained.hdf5\",**run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5 - Train 300d model with trainable embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LSTM, average final\n",
    "model300_trained = nn.create_model(embedding_matrix=embedding_matrix300, n_hidden=150, train_embed=True)\n",
    "model300_trained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nn.run_model(model=model300_trained, out_path=\"models/nn_300d_trained.hdf5\", **run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 -  Analyze Best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
