{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook train four different neural network models. They are all pretty similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.1 Load Packages and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from nltk import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.join(os.getcwd(), os.pardir)\n",
    "os.chdir(PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\wertu\\\\Documents\\\\Datascience\\\\udacity-ml-capstone'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import src.neural_networks as nn\n",
    "from src.evaluation import roc_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "nn = reload(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2- Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and validation neural network data sets if they are present, otherwise raise an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load sequnces\n",
    "try:\n",
    "    train = joblib.load('data/processed/train_nn.pkl')\n",
    "    valid = joblib.load('data/processed/valid_nn.pkl')\n",
    "    test = joblib.load('data/processed/test_nn.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load embedding matrix of 50 dimensions\n",
    "try:\n",
    "    embedding_matrix50 = joblib.load('data/interim/embeddings50.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load embedding matrix of 300 dimensions\n",
    "try:\n",
    "    embedding_matrix300 = joblib.load('data/interim/embeddings300.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these arguments will be the same when training both models\n",
    "run_args = {\"train\":(train[\"seqs\"],train[\"labels\"]),\n",
    "            \"valid\":(valid[\"seqs\"],valid[\"labels\"])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Train 50d model with fixed embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "joke_seq (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 50)           1369800   \n",
      "_________________________________________________________________\n",
      "mask_paddings (Masking)      (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "drop_words (SpatialDropout1D (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "mask_dropped_words (Masking) (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "reccurrent_layer (LSTM)      (None, 150)               120600    \n",
      "_________________________________________________________________\n",
      "drop_dense (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_sigmoid (Dense)        (None, 75)                11325     \n",
      "_________________________________________________________________\n",
      "avg_pred (GlobalAverage)     (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,501,725\n",
      "Trainable params: 131,925\n",
      "Non-trainable params: 1,369,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM, average final\n",
    "model50_fixed = nn.create_model(embedding_matrix=embedding_matrix50, n_hidden=150, train_embed=False)\n",
    "model50_fixed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output model as svg plot\n",
    "plot_model(model50_fixed, to_file='reports/figures/nn_50d.svg', show_shapes =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171945 samples, validate on 24564 samples\n",
      "Epoch 1/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6726 - acc: 0.5767\n",
      "auc: 64.3588% - val_auc: 64.5214% \n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.64521, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 203s 1ms/step - loss: 0.6726 - acc: 0.5768 - val_loss: 0.6573 - val_acc: 0.6029\n",
      "Epoch 2/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6621 - acc: 0.5952\n",
      "auc: 64.8983% - val_auc: 65.0197% \n",
      "\n",
      "Epoch 00002: val_auc improved from 0.64521 to 0.65020, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 154s 894us/step - loss: 0.6620 - acc: 0.5952 - val_loss: 0.6543 - val_acc: 0.6019\n",
      "Epoch 3/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6578 - acc: 0.5980\n",
      "auc: 65.2484% - val_auc: 65.3539% \n",
      "\n",
      "Epoch 00003: val_auc improved from 0.65020 to 0.65354, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 156s 909us/step - loss: 0.6577 - acc: 0.5981 - val_loss: 0.6545 - val_acc: 0.6034\n",
      "Epoch 4/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6549 - acc: 0.6022\n",
      "auc: 66.1722% - val_auc: 66.3117% \n",
      "\n",
      "Epoch 00004: val_auc improved from 0.65354 to 0.66312, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 151s 876us/step - loss: 0.6549 - acc: 0.6021 - val_loss: 0.6475 - val_acc: 0.6106\n",
      "Epoch 5/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6530 - acc: 0.6038\n",
      "auc: 66.4687% - val_auc: 66.5221% \n",
      "\n",
      "Epoch 00005: val_auc improved from 0.66312 to 0.66522, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 153s 891us/step - loss: 0.6531 - acc: 0.6039 - val_loss: 0.6466 - val_acc: 0.6124\n",
      "Epoch 6/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6514 - acc: 0.6068\n",
      "auc: 66.6836% - val_auc: 66.8238% \n",
      "\n",
      "Epoch 00006: val_auc improved from 0.66522 to 0.66824, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 150s 874us/step - loss: 0.6515 - acc: 0.6067 - val_loss: 0.6456 - val_acc: 0.6166\n",
      "Epoch 7/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6501 - acc: 0.6093\n",
      "auc: 66.9846% - val_auc: 67.0770% \n",
      "\n",
      "Epoch 00007: val_auc improved from 0.66824 to 0.67077, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 150s 874us/step - loss: 0.6500 - acc: 0.6095 - val_loss: 0.6435 - val_acc: 0.6192\n",
      "Epoch 8/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6488 - acc: 0.6110\n",
      "auc: 67.1769% - val_auc: 67.1954% \n",
      "\n",
      "Epoch 00008: val_auc improved from 0.67077 to 0.67195, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 150s 874us/step - loss: 0.6489 - acc: 0.6110 - val_loss: 0.6433 - val_acc: 0.6206\n",
      "Epoch 9/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6477 - acc: 0.6135\n",
      "auc: 67.4391% - val_auc: 67.4829% \n",
      "\n",
      "Epoch 00009: val_auc improved from 0.67195 to 0.67483, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 150s 873us/step - loss: 0.6478 - acc: 0.6133 - val_loss: 0.6417 - val_acc: 0.6218\n",
      "Epoch 10/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6481 - acc: 0.6119\n",
      "auc: 67.5899% - val_auc: 67.5042% \n",
      "\n",
      "Epoch 00010: val_auc improved from 0.67483 to 0.67504, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 151s 876us/step - loss: 0.6481 - acc: 0.6121 - val_loss: 0.6412 - val_acc: 0.6231\n",
      "Epoch 11/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6494 - acc: 0.6113\n",
      "auc: 67.4495% - val_auc: 67.5065% \n",
      "\n",
      "Epoch 00011: val_auc improved from 0.67504 to 0.67506, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 150s 875us/step - loss: 0.6494 - acc: 0.6113 - val_loss: 0.6410 - val_acc: 0.6240\n",
      "Epoch 12/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6473 - acc: 0.6131\n",
      "auc: 67.8953% - val_auc: 67.9425% \n",
      "\n",
      "Epoch 00012: val_auc improved from 0.67506 to 0.67943, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 150s 874us/step - loss: 0.6473 - acc: 0.6130 - val_loss: 0.6392 - val_acc: 0.6265\n",
      "Epoch 13/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6464 - acc: 0.6157\n",
      "auc: 67.9447% - val_auc: 67.9494% \n",
      "\n",
      "Epoch 00013: val_auc improved from 0.67943 to 0.67949, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 150s 874us/step - loss: 0.6465 - acc: 0.6157 - val_loss: 0.6391 - val_acc: 0.6268\n",
      "Epoch 14/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6450 - acc: 0.6187\n",
      "auc: 68.1526% - val_auc: 68.1172% \n",
      "\n",
      "Epoch 00014: val_auc improved from 0.67949 to 0.68117, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 150s 875us/step - loss: 0.6450 - acc: 0.6188 - val_loss: 0.6386 - val_acc: 0.6273\n",
      "Epoch 15/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6442 - acc: 0.6187\n",
      "auc: 68.3657% - val_auc: 68.3017% \n",
      "\n",
      "Epoch 00015: val_auc improved from 0.68117 to 0.68302, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 150s 873us/step - loss: 0.6442 - acc: 0.6187 - val_loss: 0.6378 - val_acc: 0.6292\n",
      "Epoch 16/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6436 - acc: 0.6202\n",
      "auc: 68.5110% - val_auc: 68.3963% \n",
      "\n",
      "Epoch 00016: val_auc improved from 0.68302 to 0.68396, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 150s 875us/step - loss: 0.6435 - acc: 0.6201 - val_loss: 0.6364 - val_acc: 0.6321\n",
      "Epoch 17/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6428 - acc: 0.6211\n",
      "auc: 68.7324% - val_auc: 68.5583% \n",
      "\n",
      "Epoch 00017: val_auc improved from 0.68396 to 0.68558, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 150s 872us/step - loss: 0.6430 - acc: 0.6211 - val_loss: 0.6359 - val_acc: 0.6338\n",
      "Epoch 18/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6422 - acc: 0.6221\n",
      "auc: 68.8414% - val_auc: 68.6735% \n",
      "\n",
      "Epoch 00018: val_auc improved from 0.68558 to 0.68674, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.6424 - acc: 0.6220 - val_loss: 0.6352 - val_acc: 0.6343\n",
      "Epoch 19/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6418 - acc: 0.6228\n",
      "auc: 68.9150% - val_auc: 68.7002% \n",
      "\n",
      "Epoch 00019: val_auc improved from 0.68674 to 0.68700, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6418 - acc: 0.6227 - val_loss: 0.6359 - val_acc: 0.6331\n",
      "Epoch 20/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6415 - acc: 0.6242\n",
      "auc: 69.0970% - val_auc: 68.8627% \n",
      "\n",
      "Epoch 00020: val_auc improved from 0.68700 to 0.68863, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 864us/step - loss: 0.6415 - acc: 0.6242 - val_loss: 0.6339 - val_acc: 0.6356\n",
      "Epoch 21/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6406 - acc: 0.6251\n",
      "auc: 69.2528% - val_auc: 68.9352% \n",
      "\n",
      "Epoch 00021: val_auc improved from 0.68863 to 0.68935, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6406 - acc: 0.6252 - val_loss: 0.6339 - val_acc: 0.6352\n",
      "Epoch 22/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6403 - acc: 0.6260\n",
      "auc: 69.4428% - val_auc: 69.0908% \n",
      "\n",
      "Epoch 00022: val_auc improved from 0.68935 to 0.69091, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6402 - acc: 0.6258 - val_loss: 0.6328 - val_acc: 0.6382\n",
      "Epoch 23/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6393 - acc: 0.6267\n",
      "auc: 69.5153% - val_auc: 69.1601% \n",
      "\n",
      "Epoch 00023: val_auc improved from 0.69091 to 0.69160, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6391 - acc: 0.6270 - val_loss: 0.6331 - val_acc: 0.6393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6387 - acc: 0.6285\n",
      "auc: 69.6013% - val_auc: 69.1988% \n",
      "\n",
      "Epoch 00024: val_auc improved from 0.69160 to 0.69199, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6387 - acc: 0.6285 - val_loss: 0.6331 - val_acc: 0.6374\n",
      "Epoch 25/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6382 - acc: 0.6308\n",
      "auc: 69.8402% - val_auc: 69.3207% \n",
      "\n",
      "Epoch 00025: val_auc improved from 0.69199 to 0.69321, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6381 - acc: 0.6308 - val_loss: 0.6327 - val_acc: 0.6377\n",
      "Epoch 26/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6375 - acc: 0.6305\n",
      "auc: 69.9474% - val_auc: 69.4143% \n",
      "\n",
      "Epoch 00026: val_auc improved from 0.69321 to 0.69414, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6375 - acc: 0.6306 - val_loss: 0.6320 - val_acc: 0.6383\n",
      "Epoch 27/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6367 - acc: 0.6323\n",
      "auc: 70.0697% - val_auc: 69.5207% \n",
      "\n",
      "Epoch 00027: val_auc improved from 0.69414 to 0.69521, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6366 - acc: 0.6325 - val_loss: 0.6303 - val_acc: 0.6408\n",
      "Epoch 28/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6369 - acc: 0.6302\n",
      "auc: 70.2999% - val_auc: 69.6462% \n",
      "\n",
      "Epoch 00028: val_auc improved from 0.69521 to 0.69646, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6370 - acc: 0.6302 - val_loss: 0.6302 - val_acc: 0.6399\n",
      "Epoch 29/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6361 - acc: 0.6311\n",
      "auc: 70.3470% - val_auc: 69.6863% \n",
      "\n",
      "Epoch 00029: val_auc improved from 0.69646 to 0.69686, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6362 - acc: 0.6311 - val_loss: 0.6296 - val_acc: 0.6399\n",
      "Epoch 30/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6355 - acc: 0.6333\n",
      "auc: 70.5547% - val_auc: 69.8402% \n",
      "\n",
      "Epoch 00030: val_auc improved from 0.69686 to 0.69840, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6354 - acc: 0.6333 - val_loss: 0.6296 - val_acc: 0.6388\n",
      "Epoch 31/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6353 - acc: 0.6330\n",
      "auc: 70.6985% - val_auc: 69.8579% \n",
      "\n",
      "Epoch 00031: val_auc improved from 0.69840 to 0.69858, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6354 - acc: 0.6328 - val_loss: 0.6295 - val_acc: 0.6424\n",
      "Epoch 32/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6340 - acc: 0.6344\n",
      "auc: 70.8251% - val_auc: 69.9660% \n",
      "\n",
      "Epoch 00032: val_auc improved from 0.69858 to 0.69966, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6340 - acc: 0.6345 - val_loss: 0.6275 - val_acc: 0.6437\n",
      "Epoch 33/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6338 - acc: 0.6360\n",
      "auc: 70.9364% - val_auc: 70.0785% \n",
      "\n",
      "Epoch 00033: val_auc improved from 0.69966 to 0.70078, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6338 - acc: 0.6361 - val_loss: 0.6271 - val_acc: 0.6421\n",
      "Epoch 34/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6339 - acc: 0.6354\n",
      "auc: 70.9830% - val_auc: 70.0832% \n",
      "\n",
      "Epoch 00034: val_auc improved from 0.70078 to 0.70083, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6338 - acc: 0.6356 - val_loss: 0.6277 - val_acc: 0.6441\n",
      "Epoch 35/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6329 - acc: 0.6377\n",
      "auc: 71.1541% - val_auc: 70.1214% \n",
      "\n",
      "Epoch 00035: val_auc improved from 0.70083 to 0.70121, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6330 - acc: 0.6375 - val_loss: 0.6282 - val_acc: 0.6419\n",
      "Epoch 36/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6326 - acc: 0.6380\n",
      "auc: 71.2894% - val_auc: 70.2160% \n",
      "\n",
      "Epoch 00036: val_auc improved from 0.70121 to 0.70216, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6326 - acc: 0.6381 - val_loss: 0.6266 - val_acc: 0.6441\n",
      "Epoch 37/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6318 - acc: 0.6384\n",
      "auc: 71.3835% - val_auc: 70.3344% \n",
      "\n",
      "Epoch 00037: val_auc improved from 0.70216 to 0.70334, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6318 - acc: 0.6385 - val_loss: 0.6261 - val_acc: 0.6458\n",
      "Epoch 38/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6316 - acc: 0.6395\n",
      "auc: 71.5374% - val_auc: 70.4061% \n",
      "\n",
      "Epoch 00038: val_auc improved from 0.70334 to 0.70406, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6316 - acc: 0.6395 - val_loss: 0.6250 - val_acc: 0.6462\n",
      "Epoch 39/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6312 - acc: 0.6409\n",
      "auc: 71.6724% - val_auc: 70.5050% \n",
      "\n",
      "Epoch 00039: val_auc improved from 0.70406 to 0.70505, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6313 - acc: 0.6409 - val_loss: 0.6263 - val_acc: 0.6448\n",
      "Epoch 40/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6310 - acc: 0.6405\n",
      "auc: 71.6585% - val_auc: 70.5654% \n",
      "\n",
      "Epoch 00040: val_auc improved from 0.70505 to 0.70565, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6310 - acc: 0.6406 - val_loss: 0.6237 - val_acc: 0.6486\n",
      "Epoch 41/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6301 - acc: 0.6414\n",
      "auc: 71.7970% - val_auc: 70.5591% \n",
      "\n",
      "Epoch 00041: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6303 - acc: 0.6413 - val_loss: 0.6255 - val_acc: 0.6488\n",
      "Epoch 42/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6297 - acc: 0.6419\n",
      "auc: 72.0944% - val_auc: 70.6858% \n",
      "\n",
      "Epoch 00042: val_auc improved from 0.70565 to 0.70686, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6297 - acc: 0.6420 - val_loss: 0.6235 - val_acc: 0.6499\n",
      "Epoch 43/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6294 - acc: 0.6416\n",
      "auc: 72.1268% - val_auc: 70.7325% \n",
      "\n",
      "Epoch 00043: val_auc improved from 0.70686 to 0.70732, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6294 - acc: 0.6416 - val_loss: 0.6227 - val_acc: 0.6498\n",
      "Epoch 44/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6289 - acc: 0.6428\n",
      "auc: 72.2032% - val_auc: 70.8053% \n",
      "\n",
      "Epoch 00044: val_auc improved from 0.70732 to 0.70805, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6290 - acc: 0.6428 - val_loss: 0.6222 - val_acc: 0.6499\n",
      "Epoch 45/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6284 - acc: 0.6440\n",
      "auc: 72.2876% - val_auc: 70.8356% \n",
      "\n",
      "Epoch 00045: val_auc improved from 0.70805 to 0.70836, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6284 - acc: 0.6439 - val_loss: 0.6231 - val_acc: 0.6502\n",
      "Epoch 46/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6282 - acc: 0.6440\n",
      "auc: 72.4034% - val_auc: 70.9390% \n",
      "\n",
      "Epoch 00046: val_auc improved from 0.70836 to 0.70939, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6281 - acc: 0.6440 - val_loss: 0.6214 - val_acc: 0.6515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6280 - acc: 0.6442\n",
      "auc: 72.4031% - val_auc: 70.9003% \n",
      "\n",
      "Epoch 00047: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6279 - acc: 0.6443 - val_loss: 0.6219 - val_acc: 0.6531\n",
      "Epoch 48/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6275 - acc: 0.6450\n",
      "auc: 72.6971% - val_auc: 71.0530% \n",
      "\n",
      "Epoch 00048: val_auc improved from 0.70939 to 0.71053, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6275 - acc: 0.6452 - val_loss: 0.6216 - val_acc: 0.6514\n",
      "Epoch 49/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6274 - acc: 0.6457\n",
      "auc: 72.7362% - val_auc: 71.1109% \n",
      "\n",
      "Epoch 00049: val_auc improved from 0.71053 to 0.71111, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.6273 - acc: 0.6458 - val_loss: 0.6207 - val_acc: 0.6520\n",
      "Epoch 50/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6266 - acc: 0.6465\n",
      "auc: 72.8092% - val_auc: 71.1751% \n",
      "\n",
      "Epoch 00050: val_auc improved from 0.71111 to 0.71175, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6267 - acc: 0.6464 - val_loss: 0.6221 - val_acc: 0.6510\n",
      "Epoch 51/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6258 - acc: 0.6464\n",
      "auc: 72.9123% - val_auc: 71.1684% \n",
      "\n",
      "Epoch 00051: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6257 - acc: 0.6465 - val_loss: 0.6206 - val_acc: 0.6540\n",
      "Epoch 52/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6258 - acc: 0.6471\n",
      "auc: 73.0194% - val_auc: 71.2497% \n",
      "\n",
      "Epoch 00052: val_auc improved from 0.71175 to 0.71250, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6259 - acc: 0.6469 - val_loss: 0.6213 - val_acc: 0.6514\n",
      "Epoch 53/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6251 - acc: 0.6479\n",
      "auc: 73.1553% - val_auc: 71.2578% \n",
      "\n",
      "Epoch 00053: val_auc improved from 0.71250 to 0.71258, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6251 - acc: 0.6477 - val_loss: 0.6203 - val_acc: 0.6524\n",
      "Epoch 54/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6242 - acc: 0.6468\n",
      "auc: 73.2128% - val_auc: 71.2847% \n",
      "\n",
      "Epoch 00054: val_auc improved from 0.71258 to 0.71285, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6242 - acc: 0.6467 - val_loss: 0.6197 - val_acc: 0.6534\n",
      "Epoch 55/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6243 - acc: 0.6487\n",
      "auc: 73.2881% - val_auc: 71.2418% \n",
      "\n",
      "Epoch 00055: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6243 - acc: 0.6487 - val_loss: 0.6211 - val_acc: 0.6501\n",
      "Epoch 56/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6248 - acc: 0.6483\n",
      "auc: 73.3262% - val_auc: 71.4016% \n",
      "\n",
      "Epoch 00056: val_auc improved from 0.71285 to 0.71402, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6248 - acc: 0.6482 - val_loss: 0.6203 - val_acc: 0.6532\n",
      "Epoch 57/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6239 - acc: 0.6481\n",
      "auc: 73.4650% - val_auc: 71.4439% \n",
      "\n",
      "Epoch 00057: val_auc improved from 0.71402 to 0.71444, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6240 - acc: 0.6481 - val_loss: 0.6189 - val_acc: 0.6550\n",
      "Epoch 58/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6229 - acc: 0.6504\n",
      "auc: 73.6425% - val_auc: 71.4853% \n",
      "\n",
      "Epoch 00058: val_auc improved from 0.71444 to 0.71485, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6230 - acc: 0.6505 - val_loss: 0.6193 - val_acc: 0.6518\n",
      "Epoch 59/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6227 - acc: 0.6513\n",
      "auc: 73.6666% - val_auc: 71.4589% \n",
      "\n",
      "Epoch 00059: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6227 - acc: 0.6513 - val_loss: 0.6187 - val_acc: 0.6532\n",
      "Epoch 60/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6226 - acc: 0.6517\n",
      "auc: 73.7262% - val_auc: 71.5730% \n",
      "\n",
      "Epoch 00060: val_auc improved from 0.71485 to 0.71573, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6226 - acc: 0.6515 - val_loss: 0.6174 - val_acc: 0.6545\n",
      "Epoch 61/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6222 - acc: 0.6498\n",
      "auc: 73.8116% - val_auc: 71.5627% \n",
      "\n",
      "Epoch 00061: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6222 - acc: 0.6497 - val_loss: 0.6185 - val_acc: 0.6554\n",
      "Epoch 62/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6229 - acc: 0.6517\n",
      "auc: 73.8471% - val_auc: 71.5839% \n",
      "\n",
      "Epoch 00062: val_auc improved from 0.71573 to 0.71584, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6229 - acc: 0.6517 - val_loss: 0.6179 - val_acc: 0.6563\n",
      "Epoch 63/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6222 - acc: 0.6515\n",
      "auc: 73.9677% - val_auc: 71.5868% \n",
      "\n",
      "Epoch 00063: val_auc improved from 0.71584 to 0.71587, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6223 - acc: 0.6513 - val_loss: 0.6178 - val_acc: 0.6554\n",
      "Epoch 64/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6219 - acc: 0.6513\n",
      "auc: 73.9715% - val_auc: 71.6448% \n",
      "\n",
      "Epoch 00064: val_auc improved from 0.71587 to 0.71645, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6220 - acc: 0.6511 - val_loss: 0.6190 - val_acc: 0.6531\n",
      "Epoch 65/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6212 - acc: 0.6535\n",
      "auc: 74.1416% - val_auc: 71.7151% \n",
      "\n",
      "Epoch 00065: val_auc improved from 0.71645 to 0.71715, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6213 - acc: 0.6532 - val_loss: 0.6167 - val_acc: 0.6565\n",
      "Epoch 66/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6205 - acc: 0.6544\n",
      "auc: 74.2090% - val_auc: 71.7116% \n",
      "\n",
      "Epoch 00066: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6205 - acc: 0.6544 - val_loss: 0.6176 - val_acc: 0.6534\n",
      "Epoch 67/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6204 - acc: 0.6531\n",
      "auc: 74.2057% - val_auc: 71.6600% \n",
      "\n",
      "Epoch 00067: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6203 - acc: 0.6532 - val_loss: 0.6186 - val_acc: 0.6548\n",
      "Epoch 68/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6197 - acc: 0.6543\n",
      "auc: 74.3314% - val_auc: 71.6979% \n",
      "\n",
      "Epoch 00068: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6197 - acc: 0.6543 - val_loss: 0.6183 - val_acc: 0.6532\n",
      "Epoch 69/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6190 - acc: 0.6548\n",
      "auc: 74.5522% - val_auc: 71.8438% \n",
      "\n",
      "Epoch 00069: val_auc improved from 0.71715 to 0.71844, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6190 - acc: 0.6546 - val_loss: 0.6176 - val_acc: 0.6527\n",
      "Epoch 70/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6204 - acc: 0.6533\n",
      "auc: 74.5319% - val_auc: 71.8453% \n",
      "\n",
      "Epoch 00070: val_auc improved from 0.71844 to 0.71845, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6204 - acc: 0.6533 - val_loss: 0.6160 - val_acc: 0.6570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6194 - acc: 0.6556\n",
      "auc: 74.5669% - val_auc: 71.7253% \n",
      "\n",
      "Epoch 00071: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6193 - acc: 0.6558 - val_loss: 0.6174 - val_acc: 0.6529\n",
      "Epoch 72/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6198 - acc: 0.6527\n",
      "auc: 74.6314% - val_auc: 71.8800% \n",
      "\n",
      "Epoch 00072: val_auc improved from 0.71845 to 0.71880, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6197 - acc: 0.6529 - val_loss: 0.6162 - val_acc: 0.6564\n",
      "Epoch 73/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6186 - acc: 0.6568\n",
      "auc: 74.7706% - val_auc: 71.8892% \n",
      "\n",
      "Epoch 00073: val_auc improved from 0.71880 to 0.71889, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.6186 - acc: 0.6567 - val_loss: 0.6155 - val_acc: 0.6558\n",
      "Epoch 74/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6190 - acc: 0.6540\n",
      "auc: 74.7455% - val_auc: 71.9021% \n",
      "\n",
      "Epoch 00074: val_auc improved from 0.71889 to 0.71902, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6189 - acc: 0.6541 - val_loss: 0.6166 - val_acc: 0.6561\n",
      "Epoch 75/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6171 - acc: 0.6566\n",
      "auc: 74.9128% - val_auc: 71.9563% \n",
      "\n",
      "Epoch 00075: val_auc improved from 0.71902 to 0.71956, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6172 - acc: 0.6566 - val_loss: 0.6151 - val_acc: 0.6579\n",
      "Epoch 76/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6180 - acc: 0.6555\n",
      "auc: 74.9138% - val_auc: 71.9301% \n",
      "\n",
      "Epoch 00076: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6181 - acc: 0.6555 - val_loss: 0.6149 - val_acc: 0.6584\n",
      "Epoch 77/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6182 - acc: 0.6569\n",
      "auc: 74.9276% - val_auc: 72.0051% \n",
      "\n",
      "Epoch 00077: val_auc improved from 0.71956 to 0.72005, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6181 - acc: 0.6567 - val_loss: 0.6164 - val_acc: 0.6567\n",
      "Epoch 78/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6187 - acc: 0.6563\n",
      "auc: 74.9562% - val_auc: 72.0721% \n",
      "\n",
      "Epoch 00078: val_auc improved from 0.72005 to 0.72072, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6187 - acc: 0.6562 - val_loss: 0.6151 - val_acc: 0.6577\n",
      "Epoch 79/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6186 - acc: 0.6547\n",
      "auc: 75.1085% - val_auc: 72.0590% \n",
      "\n",
      "Epoch 00079: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6185 - acc: 0.6548 - val_loss: 0.6144 - val_acc: 0.6573\n",
      "Epoch 80/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6178 - acc: 0.6565\n",
      "auc: 75.1614% - val_auc: 72.1030% \n",
      "\n",
      "Epoch 00080: val_auc improved from 0.72072 to 0.72103, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6178 - acc: 0.6566 - val_loss: 0.6139 - val_acc: 0.6591\n",
      "Epoch 81/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6170 - acc: 0.6581\n",
      "auc: 75.2541% - val_auc: 72.1413% \n",
      "\n",
      "Epoch 00081: val_auc improved from 0.72103 to 0.72141, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6171 - acc: 0.6579 - val_loss: 0.6139 - val_acc: 0.6591\n",
      "Epoch 82/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6169 - acc: 0.6574\n",
      "auc: 75.2673% - val_auc: 72.1019% \n",
      "\n",
      "Epoch 00082: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6169 - acc: 0.6574 - val_loss: 0.6150 - val_acc: 0.6569\n",
      "Epoch 83/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6161 - acc: 0.6578\n",
      "auc: 75.5056% - val_auc: 72.1938% \n",
      "\n",
      "Epoch 00083: val_auc improved from 0.72141 to 0.72194, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6161 - acc: 0.6580 - val_loss: 0.6136 - val_acc: 0.6587\n",
      "Epoch 84/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6157 - acc: 0.6598\n",
      "auc: 75.4699% - val_auc: 72.1587% \n",
      "\n",
      "Epoch 00084: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6158 - acc: 0.6598 - val_loss: 0.6150 - val_acc: 0.6572\n",
      "Epoch 85/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6163 - acc: 0.6587\n",
      "auc: 75.5529% - val_auc: 72.2251% \n",
      "\n",
      "Epoch 00085: val_auc improved from 0.72194 to 0.72225, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6163 - acc: 0.6587 - val_loss: 0.6127 - val_acc: 0.6600\n",
      "Epoch 86/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6151 - acc: 0.6596\n",
      "auc: 75.5970% - val_auc: 72.2041% \n",
      "\n",
      "Epoch 00086: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6152 - acc: 0.6595 - val_loss: 0.6147 - val_acc: 0.6549\n",
      "Epoch 87/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6159 - acc: 0.6596\n",
      "auc: 75.6554% - val_auc: 72.2411% \n",
      "\n",
      "Epoch 00087: val_auc improved from 0.72225 to 0.72241, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6157 - acc: 0.6598 - val_loss: 0.6130 - val_acc: 0.6605\n",
      "Epoch 88/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6159 - acc: 0.6588\n",
      "auc: 75.7336% - val_auc: 72.2478% \n",
      "\n",
      "Epoch 00088: val_auc improved from 0.72241 to 0.72248, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6158 - acc: 0.6588 - val_loss: 0.6131 - val_acc: 0.6584\n",
      "Epoch 89/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6151 - acc: 0.6588\n",
      "auc: 75.6889% - val_auc: 72.3108% \n",
      "\n",
      "Epoch 00089: val_auc improved from 0.72248 to 0.72311, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6151 - acc: 0.6588 - val_loss: 0.6126 - val_acc: 0.6605\n",
      "Epoch 90/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6147 - acc: 0.6596\n",
      "auc: 75.8321% - val_auc: 72.3189% \n",
      "\n",
      "Epoch 00090: val_auc improved from 0.72311 to 0.72319, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6147 - acc: 0.6595 - val_loss: 0.6151 - val_acc: 0.6556\n",
      "Epoch 91/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6149 - acc: 0.6586\n",
      "auc: 75.8662% - val_auc: 72.3293% \n",
      "\n",
      "Epoch 00091: val_auc improved from 0.72319 to 0.72329, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.6150 - acc: 0.6586 - val_loss: 0.6123 - val_acc: 0.6589\n",
      "Epoch 92/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6140 - acc: 0.6605\n",
      "auc: 75.8040% - val_auc: 72.3613% \n",
      "\n",
      "Epoch 00092: val_auc improved from 0.72329 to 0.72361, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6142 - acc: 0.6603 - val_loss: 0.6137 - val_acc: 0.6580\n",
      "Epoch 93/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6155 - acc: 0.6590\n",
      "auc: 75.9324% - val_auc: 72.3064% \n",
      "\n",
      "Epoch 00093: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6154 - acc: 0.6591 - val_loss: 0.6127 - val_acc: 0.6599\n",
      "Epoch 94/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6137 - acc: 0.6617\n",
      "auc: 75.9949% - val_auc: 72.2617% \n",
      "\n",
      "Epoch 00094: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6140 - acc: 0.6615 - val_loss: 0.6135 - val_acc: 0.6573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6136 - acc: 0.6613\n",
      "auc: 76.1158% - val_auc: 72.2926% \n",
      "\n",
      "Epoch 00095: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6135 - acc: 0.6614 - val_loss: 0.6141 - val_acc: 0.6571\n",
      "Epoch 96/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6137 - acc: 0.6607\n",
      "auc: 76.1594% - val_auc: 72.4189% \n",
      "\n",
      "Epoch 00096: val_auc improved from 0.72361 to 0.72419, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6137 - acc: 0.6608 - val_loss: 0.6121 - val_acc: 0.6604\n",
      "Epoch 97/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6133 - acc: 0.6619\n",
      "auc: 76.2176% - val_auc: 72.3839% \n",
      "\n",
      "Epoch 00097: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6131 - acc: 0.6620 - val_loss: 0.6136 - val_acc: 0.6565\n",
      "Epoch 98/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6128 - acc: 0.6633\n",
      "auc: 76.2781% - val_auc: 72.4342% \n",
      "\n",
      "Epoch 00098: val_auc improved from 0.72419 to 0.72434, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6127 - acc: 0.6634 - val_loss: 0.6128 - val_acc: 0.6589\n",
      "Epoch 99/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6121 - acc: 0.6626\n",
      "auc: 76.2850% - val_auc: 72.4643% \n",
      "\n",
      "Epoch 00099: val_auc improved from 0.72434 to 0.72464, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6121 - acc: 0.6625 - val_loss: 0.6127 - val_acc: 0.6598\n",
      "Epoch 100/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6126 - acc: 0.6615\n",
      "auc: 76.4406% - val_auc: 72.4349% \n",
      "\n",
      "Epoch 00100: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6127 - acc: 0.6615 - val_loss: 0.6132 - val_acc: 0.6569\n",
      "Epoch 101/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6125 - acc: 0.6633\n",
      "auc: 76.3005% - val_auc: 72.3823% \n",
      "\n",
      "Epoch 00101: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6124 - acc: 0.6635 - val_loss: 0.6146 - val_acc: 0.6573\n",
      "Epoch 102/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6131 - acc: 0.6630\n",
      "auc: 76.4322% - val_auc: 72.4993% \n",
      "\n",
      "Epoch 00102: val_auc improved from 0.72464 to 0.72499, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6131 - acc: 0.6630 - val_loss: 0.6123 - val_acc: 0.6592\n",
      "Epoch 103/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6130 - acc: 0.6607\n",
      "auc: 76.4334% - val_auc: 72.4651% \n",
      "\n",
      "Epoch 00103: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6129 - acc: 0.6607 - val_loss: 0.6141 - val_acc: 0.6577\n",
      "Epoch 104/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6117 - acc: 0.6634\n",
      "auc: 76.5289% - val_auc: 72.5075% \n",
      "\n",
      "Epoch 00104: val_auc improved from 0.72499 to 0.72507, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6116 - acc: 0.6635 - val_loss: 0.6129 - val_acc: 0.6591\n",
      "Epoch 105/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6118 - acc: 0.6629\n",
      "auc: 76.7250% - val_auc: 72.4443% \n",
      "\n",
      "Epoch 00105: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6117 - acc: 0.6629 - val_loss: 0.6126 - val_acc: 0.6567\n",
      "Epoch 106/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6115 - acc: 0.6640\n",
      "auc: 76.6275% - val_auc: 72.5270% \n",
      "\n",
      "Epoch 00106: val_auc improved from 0.72507 to 0.72527, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 152s 881us/step - loss: 0.6116 - acc: 0.6639 - val_loss: 0.6137 - val_acc: 0.6571\n",
      "Epoch 107/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6115 - acc: 0.6638\n",
      "auc: 76.6415% - val_auc: 72.5541% \n",
      "\n",
      "Epoch 00107: val_auc improved from 0.72527 to 0.72554, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6114 - acc: 0.6639 - val_loss: 0.6125 - val_acc: 0.6604\n",
      "Epoch 108/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6110 - acc: 0.6647\n",
      "auc: 76.8555% - val_auc: 72.5560% \n",
      "\n",
      "Epoch 00108: val_auc improved from 0.72554 to 0.72556, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6108 - acc: 0.6650 - val_loss: 0.6128 - val_acc: 0.6578\n",
      "Epoch 109/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6112 - acc: 0.6639\n",
      "auc: 76.7969% - val_auc: 72.5169% \n",
      "\n",
      "Epoch 00109: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6112 - acc: 0.6640 - val_loss: 0.6118 - val_acc: 0.6608\n",
      "Epoch 110/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6106 - acc: 0.6645\n",
      "auc: 76.8170% - val_auc: 72.6195% \n",
      "\n",
      "Epoch 00110: val_auc improved from 0.72556 to 0.72619, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6107 - acc: 0.6644 - val_loss: 0.6108 - val_acc: 0.6614\n",
      "Epoch 111/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6113 - acc: 0.6635\n",
      "auc: 76.9633% - val_auc: 72.5614% \n",
      "\n",
      "Epoch 00111: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6113 - acc: 0.6635 - val_loss: 0.6110 - val_acc: 0.6595\n",
      "Epoch 112/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6115 - acc: 0.6646\n",
      "auc: 76.9061% - val_auc: 72.5596% \n",
      "\n",
      "Epoch 00112: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.6114 - acc: 0.6645 - val_loss: 0.6115 - val_acc: 0.6602\n",
      "Epoch 113/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6104 - acc: 0.6648\n",
      "auc: 77.0343% - val_auc: 72.5140% \n",
      "\n",
      "Epoch 00113: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6102 - acc: 0.6649 - val_loss: 0.6133 - val_acc: 0.6561\n",
      "Epoch 114/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6105 - acc: 0.6644\n",
      "auc: 76.9661% - val_auc: 72.5863% \n",
      "\n",
      "Epoch 00114: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6105 - acc: 0.6644 - val_loss: 0.6119 - val_acc: 0.6599\n",
      "Epoch 115/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6104 - acc: 0.6639\n",
      "auc: 77.0280% - val_auc: 72.6085% \n",
      "\n",
      "Epoch 00115: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6103 - acc: 0.6641 - val_loss: 0.6117 - val_acc: 0.6595\n",
      "Epoch 116/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6098 - acc: 0.6659\n",
      "auc: 77.1019% - val_auc: 72.5765% \n",
      "\n",
      "Epoch 00116: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6097 - acc: 0.6661 - val_loss: 0.6113 - val_acc: 0.6615\n",
      "Epoch 117/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6105 - acc: 0.6650\n",
      "auc: 77.1646% - val_auc: 72.6090% \n",
      "\n",
      "Epoch 00117: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6105 - acc: 0.6650 - val_loss: 0.6129 - val_acc: 0.6583\n",
      "Epoch 118/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6097 - acc: 0.6663\n",
      "auc: 77.2411% - val_auc: 72.5661% \n",
      "\n",
      "Epoch 00118: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6098 - acc: 0.6663 - val_loss: 0.6119 - val_acc: 0.6602\n",
      "Epoch 119/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6089 - acc: 0.6665\n",
      "auc: 77.3180% - val_auc: 72.6221% \n",
      "\n",
      "Epoch 00119: val_auc improved from 0.72619 to 0.72622, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.6090 - acc: 0.6663 - val_loss: 0.6107 - val_acc: 0.6606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6096 - acc: 0.6655\n",
      "auc: 77.3082% - val_auc: 72.5978% \n",
      "\n",
      "Epoch 00120: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6098 - acc: 0.6652 - val_loss: 0.6125 - val_acc: 0.6593\n",
      "Epoch 121/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6089 - acc: 0.6675\n",
      "auc: 77.4617% - val_auc: 72.6077% \n",
      "\n",
      "Epoch 00121: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6088 - acc: 0.6676 - val_loss: 0.6108 - val_acc: 0.6607\n",
      "Epoch 122/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6100 - acc: 0.6663\n",
      "auc: 77.4117% - val_auc: 72.6692% \n",
      "\n",
      "Epoch 00122: val_auc improved from 0.72622 to 0.72669, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.6098 - acc: 0.6665 - val_loss: 0.6102 - val_acc: 0.6624\n",
      "Epoch 123/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6086 - acc: 0.6675\n",
      "auc: 77.4613% - val_auc: 72.7026% \n",
      "\n",
      "Epoch 00123: val_auc improved from 0.72669 to 0.72703, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6087 - acc: 0.6674 - val_loss: 0.6107 - val_acc: 0.6615\n",
      "Epoch 124/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6083 - acc: 0.6672\n",
      "auc: 77.5092% - val_auc: 72.5694% \n",
      "\n",
      "Epoch 00124: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.6083 - acc: 0.6672 - val_loss: 0.6109 - val_acc: 0.6620\n",
      "Epoch 125/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6084 - acc: 0.6669\n",
      "auc: 77.5127% - val_auc: 72.6432% \n",
      "\n",
      "Epoch 00125: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6085 - acc: 0.6669 - val_loss: 0.6117 - val_acc: 0.6599\n",
      "Epoch 126/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6083 - acc: 0.6674\n",
      "auc: 77.4664% - val_auc: 72.6060% \n",
      "\n",
      "Epoch 00126: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6084 - acc: 0.6672 - val_loss: 0.6115 - val_acc: 0.6615\n",
      "Epoch 127/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6076 - acc: 0.6689\n",
      "auc: 77.4608% - val_auc: 72.7388% \n",
      "\n",
      "Epoch 00127: val_auc improved from 0.72703 to 0.72739, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6077 - acc: 0.6688 - val_loss: 0.6128 - val_acc: 0.6610\n",
      "Epoch 128/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6086 - acc: 0.6666\n",
      "auc: 77.5712% - val_auc: 72.6740% \n",
      "\n",
      "Epoch 00128: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.6086 - acc: 0.6667 - val_loss: 0.6139 - val_acc: 0.6579\n",
      "Epoch 129/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6079 - acc: 0.6679\n",
      "auc: 77.6870% - val_auc: 72.6595% \n",
      "\n",
      "Epoch 00129: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6077 - acc: 0.6681 - val_loss: 0.6131 - val_acc: 0.6581\n",
      "Epoch 130/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6075 - acc: 0.6676\n",
      "auc: 77.6897% - val_auc: 72.6962% \n",
      "\n",
      "Epoch 00130: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.6075 - acc: 0.6676 - val_loss: 0.6118 - val_acc: 0.6601\n",
      "Epoch 131/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6075 - acc: 0.6685\n",
      "auc: 77.7253% - val_auc: 72.4873% \n",
      "\n",
      "Epoch 00131: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6075 - acc: 0.6685 - val_loss: 0.6129 - val_acc: 0.6578\n",
      "Epoch 132/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6071 - acc: 0.6684\n",
      "auc: 77.7091% - val_auc: 72.6314% \n",
      "\n",
      "Epoch 00132: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6072 - acc: 0.6684 - val_loss: 0.6125 - val_acc: 0.6585\n",
      "Epoch 133/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6081 - acc: 0.6673\n",
      "auc: 77.8667% - val_auc: 72.7478% \n",
      "\n",
      "Epoch 00133: val_auc improved from 0.72739 to 0.72748, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6081 - acc: 0.6673 - val_loss: 0.6103 - val_acc: 0.6615\n",
      "Epoch 134/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6067 - acc: 0.6701\n",
      "auc: 77.9923% - val_auc: 72.7546% \n",
      "\n",
      "Epoch 00134: val_auc improved from 0.72748 to 0.72755, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6067 - acc: 0.6702 - val_loss: 0.6102 - val_acc: 0.6608\n",
      "Epoch 135/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6073 - acc: 0.6686\n",
      "auc: 77.9195% - val_auc: 72.7272% \n",
      "\n",
      "Epoch 00135: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6072 - acc: 0.6687 - val_loss: 0.6116 - val_acc: 0.6586\n",
      "Epoch 136/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6069 - acc: 0.6690\n",
      "auc: 77.9194% - val_auc: 72.6689% \n",
      "\n",
      "Epoch 00136: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6070 - acc: 0.6688 - val_loss: 0.6117 - val_acc: 0.6604\n",
      "Epoch 137/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6062 - acc: 0.6706\n",
      "auc: 77.9223% - val_auc: 72.7047% \n",
      "\n",
      "Epoch 00137: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6062 - acc: 0.6704 - val_loss: 0.6120 - val_acc: 0.6593\n",
      "Epoch 138/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6069 - acc: 0.6685\n",
      "auc: 78.0506% - val_auc: 72.7032% \n",
      "\n",
      "Epoch 00138: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6069 - acc: 0.6685 - val_loss: 0.6105 - val_acc: 0.6602\n",
      "Epoch 139/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6061 - acc: 0.6696\n",
      "auc: 78.0697% - val_auc: 72.7351% \n",
      "\n",
      "Epoch 00139: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6060 - acc: 0.6695 - val_loss: 0.6123 - val_acc: 0.6591\n",
      "Epoch 140/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6059 - acc: 0.6692\n",
      "auc: 78.0358% - val_auc: 72.7767% \n",
      "\n",
      "Epoch 00140: val_auc improved from 0.72755 to 0.72777, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.6059 - acc: 0.6692 - val_loss: 0.6121 - val_acc: 0.6614\n",
      "Epoch 141/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6060 - acc: 0.6694\n",
      "auc: 78.1091% - val_auc: 72.7254% \n",
      "\n",
      "Epoch 00141: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6060 - acc: 0.6694 - val_loss: 0.6109 - val_acc: 0.6613\n",
      "Epoch 142/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6069 - acc: 0.6690\n",
      "auc: 78.0861% - val_auc: 72.8906% \n",
      "\n",
      "Epoch 00142: val_auc improved from 0.72777 to 0.72891, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6071 - acc: 0.6688 - val_loss: 0.6107 - val_acc: 0.6623\n",
      "Epoch 143/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6062 - acc: 0.6694\n",
      "auc: 78.1847% - val_auc: 72.7402% \n",
      "\n",
      "Epoch 00143: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6063 - acc: 0.6695 - val_loss: 0.6120 - val_acc: 0.6610\n",
      "Epoch 144/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6063 - acc: 0.6694\n",
      "auc: 78.1095% - val_auc: 72.6946% \n",
      "\n",
      "Epoch 00144: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6065 - acc: 0.6693 - val_loss: 0.6133 - val_acc: 0.6578\n",
      "Epoch 145/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6053 - acc: 0.6717\n",
      "auc: 78.2490% - val_auc: 72.8499% \n",
      "\n",
      "Epoch 00145: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6054 - acc: 0.6715 - val_loss: 0.6101 - val_acc: 0.6630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6063 - acc: 0.6705\n",
      "auc: 78.2495% - val_auc: 72.8523% \n",
      "\n",
      "Epoch 00146: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6064 - acc: 0.6703 - val_loss: 0.6094 - val_acc: 0.6629\n",
      "Epoch 147/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6067 - acc: 0.6689\n",
      "auc: 78.2188% - val_auc: 72.8394% \n",
      "\n",
      "Epoch 00147: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.6066 - acc: 0.6692 - val_loss: 0.6106 - val_acc: 0.6616\n",
      "Epoch 148/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6048 - acc: 0.6706\n",
      "auc: 78.2541% - val_auc: 72.7842% \n",
      "\n",
      "Epoch 00148: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6049 - acc: 0.6705 - val_loss: 0.6117 - val_acc: 0.6615\n",
      "Epoch 149/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6054 - acc: 0.6701\n",
      "auc: 78.2847% - val_auc: 72.7528% \n",
      "\n",
      "Epoch 00149: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6052 - acc: 0.6702 - val_loss: 0.6113 - val_acc: 0.6599\n",
      "Epoch 150/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6060 - acc: 0.6696\n",
      "auc: 78.3255% - val_auc: 72.7807% \n",
      "\n",
      "Epoch 00150: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6060 - acc: 0.6697 - val_loss: 0.6110 - val_acc: 0.6627\n",
      "Epoch 151/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6049 - acc: 0.6711\n",
      "auc: 78.4532% - val_auc: 72.7230% \n",
      "\n",
      "Epoch 00151: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6050 - acc: 0.6710 - val_loss: 0.6131 - val_acc: 0.6592\n",
      "Epoch 152/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6048 - acc: 0.6703\n",
      "auc: 78.4934% - val_auc: 72.8225% \n",
      "\n",
      "Epoch 00152: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6048 - acc: 0.6703 - val_loss: 0.6097 - val_acc: 0.6627\n",
      "Epoch 153/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6047 - acc: 0.6710\n",
      "auc: 78.4353% - val_auc: 72.7032% \n",
      "\n",
      "Epoch 00153: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6048 - acc: 0.6710 - val_loss: 0.6106 - val_acc: 0.6619\n",
      "Epoch 154/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6054 - acc: 0.6700\n",
      "auc: 78.4153% - val_auc: 72.8071% \n",
      "\n",
      "Epoch 00154: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6055 - acc: 0.6699 - val_loss: 0.6124 - val_acc: 0.6589\n",
      "Epoch 155/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6046 - acc: 0.6715\n",
      "auc: 78.4506% - val_auc: 72.7730% \n",
      "\n",
      "Epoch 00155: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6046 - acc: 0.6715 - val_loss: 0.6124 - val_acc: 0.6602\n",
      "Epoch 156/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6052 - acc: 0.6707\n",
      "auc: 78.4978% - val_auc: 72.7955% \n",
      "\n",
      "Epoch 00156: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6049 - acc: 0.6711 - val_loss: 0.6121 - val_acc: 0.6611\n",
      "Epoch 157/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6041 - acc: 0.6722\n",
      "auc: 78.5586% - val_auc: 72.8269% \n",
      "\n",
      "Epoch 00157: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6040 - acc: 0.6722 - val_loss: 0.6120 - val_acc: 0.6626\n",
      "Epoch 158/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6054 - acc: 0.6692\n",
      "auc: 78.6084% - val_auc: 72.8926% \n",
      "\n",
      "Epoch 00158: val_auc improved from 0.72891 to 0.72893, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6054 - acc: 0.6693 - val_loss: 0.6090 - val_acc: 0.6644\n",
      "Epoch 159/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6042 - acc: 0.6713\n",
      "auc: 78.5954% - val_auc: 72.7902% \n",
      "\n",
      "Epoch 00159: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6042 - acc: 0.6713 - val_loss: 0.6130 - val_acc: 0.6605\n",
      "Epoch 160/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6039 - acc: 0.6725\n",
      "auc: 78.6392% - val_auc: 72.7951% \n",
      "\n",
      "Epoch 00160: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6039 - acc: 0.6724 - val_loss: 0.6099 - val_acc: 0.6623\n",
      "Epoch 161/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6046 - acc: 0.6712\n",
      "auc: 78.6732% - val_auc: 72.8273% \n",
      "\n",
      "Epoch 00161: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6046 - acc: 0.6711 - val_loss: 0.6121 - val_acc: 0.6600\n",
      "Epoch 162/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6045 - acc: 0.6713\n",
      "auc: 78.6724% - val_auc: 72.7978% \n",
      "\n",
      "Epoch 00162: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6046 - acc: 0.6711 - val_loss: 0.6139 - val_acc: 0.6611\n",
      "Epoch 163/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6026 - acc: 0.6732\n",
      "auc: 78.8000% - val_auc: 72.7956% \n",
      "\n",
      "Epoch 00163: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6025 - acc: 0.6731 - val_loss: 0.6107 - val_acc: 0.6630\n",
      "Epoch 164/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6038 - acc: 0.6713\n",
      "auc: 78.8232% - val_auc: 72.7403% \n",
      "\n",
      "Epoch 00164: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6036 - acc: 0.6715 - val_loss: 0.6111 - val_acc: 0.6622\n",
      "Epoch 165/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6036 - acc: 0.6724\n",
      "auc: 78.7616% - val_auc: 72.7755% \n",
      "\n",
      "Epoch 00165: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6037 - acc: 0.6722 - val_loss: 0.6131 - val_acc: 0.6608\n",
      "Epoch 166/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6026 - acc: 0.6719\n",
      "auc: 78.8318% - val_auc: 72.8133% \n",
      "\n",
      "Epoch 00166: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6028 - acc: 0.6718 - val_loss: 0.6112 - val_acc: 0.6619\n",
      "Epoch 167/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6032 - acc: 0.6733\n",
      "auc: 78.8875% - val_auc: 72.8182% \n",
      "\n",
      "Epoch 00167: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6032 - acc: 0.6733 - val_loss: 0.6108 - val_acc: 0.6624\n",
      "Epoch 168/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6042 - acc: 0.6717\n",
      "auc: 78.8568% - val_auc: 72.8165% \n",
      "\n",
      "Epoch 00168: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6042 - acc: 0.6718 - val_loss: 0.6131 - val_acc: 0.6611\n",
      "Epoch 169/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6036 - acc: 0.6712\n",
      "auc: 78.7697% - val_auc: 72.7403% \n",
      "\n",
      "Epoch 00169: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6037 - acc: 0.6711 - val_loss: 0.6123 - val_acc: 0.6604\n",
      "Epoch 170/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6033 - acc: 0.6732\n",
      "auc: 78.9358% - val_auc: 72.8016% \n",
      "\n",
      "Epoch 00170: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6032 - acc: 0.6732 - val_loss: 0.6120 - val_acc: 0.6610\n",
      "Epoch 171/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6028 - acc: 0.6736\n",
      "auc: 78.9739% - val_auc: 72.8313% \n",
      "\n",
      "Epoch 00171: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6027 - acc: 0.6736 - val_loss: 0.6119 - val_acc: 0.6612\n",
      "Epoch 172/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6035 - acc: 0.6722\n",
      "auc: 78.9148% - val_auc: 72.7578% \n",
      "\n",
      "Epoch 00172: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6035 - acc: 0.6723 - val_loss: 0.6111 - val_acc: 0.6613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6027 - acc: 0.6744\n",
      "auc: 78.9370% - val_auc: 72.8418% \n",
      "\n",
      "Epoch 00173: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6026 - acc: 0.6744 - val_loss: 0.6118 - val_acc: 0.6620\n",
      "Epoch 174/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6036 - acc: 0.6731\n",
      "auc: 79.0096% - val_auc: 72.8533% \n",
      "\n",
      "Epoch 00174: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6036 - acc: 0.6731 - val_loss: 0.6106 - val_acc: 0.6624\n",
      "Epoch 175/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.6732\n",
      "auc: 79.0807% - val_auc: 72.8713% \n",
      "\n",
      "Epoch 00175: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.6031 - acc: 0.6732 - val_loss: 0.6100 - val_acc: 0.6618\n",
      "Epoch 176/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6032 - acc: 0.6722\n",
      "auc: 78.9436% - val_auc: 72.9123% \n",
      "\n",
      "Epoch 00176: val_auc improved from 0.72893 to 0.72912, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6034 - acc: 0.6720 - val_loss: 0.6107 - val_acc: 0.6621\n",
      "Epoch 177/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6032 - acc: 0.6729\n",
      "auc: 79.1164% - val_auc: 72.8079% \n",
      "\n",
      "Epoch 00177: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6030 - acc: 0.6731 - val_loss: 0.6107 - val_acc: 0.6619\n",
      "Epoch 178/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6028 - acc: 0.6727\n",
      "auc: 79.1471% - val_auc: 72.8294% \n",
      "\n",
      "Epoch 00178: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6028 - acc: 0.6728 - val_loss: 0.6111 - val_acc: 0.6599\n",
      "Epoch 179/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6025 - acc: 0.6739\n",
      "auc: 79.1304% - val_auc: 72.7812% \n",
      "\n",
      "Epoch 00179: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6025 - acc: 0.6738 - val_loss: 0.6147 - val_acc: 0.6578\n",
      "Epoch 180/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6029 - acc: 0.6726\n",
      "auc: 79.1457% - val_auc: 72.8727% \n",
      "\n",
      "Epoch 00180: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.6028 - acc: 0.6728 - val_loss: 0.6122 - val_acc: 0.6607\n",
      "Epoch 181/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.6732\n",
      "auc: 79.1879% - val_auc: 72.8778% \n",
      "\n",
      "Epoch 00181: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6030 - acc: 0.6732 - val_loss: 0.6133 - val_acc: 0.6609\n",
      "Epoch 182/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6029 - acc: 0.6724\n",
      "auc: 79.2188% - val_auc: 72.7946% \n",
      "\n",
      "Epoch 00182: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6029 - acc: 0.6726 - val_loss: 0.6113 - val_acc: 0.6599\n",
      "Epoch 183/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.6732\n",
      "auc: 79.1713% - val_auc: 72.8688% \n",
      "\n",
      "Epoch 00183: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6023 - acc: 0.6735 - val_loss: 0.6113 - val_acc: 0.6605\n",
      "Epoch 184/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.6733\n",
      "auc: 79.1912% - val_auc: 72.9134% \n",
      "\n",
      "Epoch 00184: val_auc improved from 0.72912 to 0.72913, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6022 - acc: 0.6733 - val_loss: 0.6115 - val_acc: 0.6619\n",
      "Epoch 185/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.6734\n",
      "auc: 79.3210% - val_auc: 72.8598% \n",
      "\n",
      "Epoch 00185: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6020 - acc: 0.6737 - val_loss: 0.6118 - val_acc: 0.6604\n",
      "Epoch 186/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.6741\n",
      "auc: 79.3396% - val_auc: 72.9332% \n",
      "\n",
      "Epoch 00186: val_auc improved from 0.72913 to 0.72933, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 150s 870us/step - loss: 0.6015 - acc: 0.6742 - val_loss: 0.6102 - val_acc: 0.6622\n",
      "Epoch 187/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.6747\n",
      "auc: 79.3709% - val_auc: 72.8354% \n",
      "\n",
      "Epoch 00187: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6016 - acc: 0.6745 - val_loss: 0.6121 - val_acc: 0.6603\n",
      "Epoch 188/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.6735\n",
      "auc: 79.4444% - val_auc: 72.7813% \n",
      "\n",
      "Epoch 00188: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6019 - acc: 0.6736 - val_loss: 0.6103 - val_acc: 0.6610\n",
      "Epoch 189/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.6734\n",
      "auc: 79.4039% - val_auc: 72.9290% \n",
      "\n",
      "Epoch 00189: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6016 - acc: 0.6735 - val_loss: 0.6107 - val_acc: 0.6619\n",
      "Epoch 190/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6013 - acc: 0.6749\n",
      "auc: 79.3335% - val_auc: 72.9051% \n",
      "\n",
      "Epoch 00190: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6012 - acc: 0.6749 - val_loss: 0.6113 - val_acc: 0.6614\n",
      "Epoch 191/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6008 - acc: 0.6756\n",
      "auc: 79.5150% - val_auc: 72.9434% \n",
      "\n",
      "Epoch 00191: val_auc improved from 0.72933 to 0.72943, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6007 - acc: 0.6756 - val_loss: 0.6111 - val_acc: 0.6624\n",
      "Epoch 192/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6003 - acc: 0.6760\n",
      "auc: 79.4260% - val_auc: 72.7829% \n",
      "\n",
      "Epoch 00192: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6002 - acc: 0.6761 - val_loss: 0.6130 - val_acc: 0.6584\n",
      "Epoch 193/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6007 - acc: 0.6742\n",
      "auc: 79.4734% - val_auc: 72.9150% \n",
      "\n",
      "Epoch 00193: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6007 - acc: 0.6742 - val_loss: 0.6115 - val_acc: 0.6608\n",
      "Epoch 194/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6002 - acc: 0.6761\n",
      "auc: 79.4702% - val_auc: 72.8780% \n",
      "\n",
      "Epoch 00194: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6002 - acc: 0.6760 - val_loss: 0.6139 - val_acc: 0.6600\n",
      "Epoch 195/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6010 - acc: 0.6752\n",
      "auc: 79.5661% - val_auc: 72.9179% \n",
      "\n",
      "Epoch 00195: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6010 - acc: 0.6751 - val_loss: 0.6114 - val_acc: 0.6618\n",
      "Epoch 196/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6007 - acc: 0.6756\n",
      "auc: 79.4950% - val_auc: 72.9051% \n",
      "\n",
      "Epoch 00196: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6008 - acc: 0.6756 - val_loss: 0.6120 - val_acc: 0.6615\n",
      "Epoch 197/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.6740\n",
      "auc: 79.5353% - val_auc: 72.9574% \n",
      "\n",
      "Epoch 00197: val_auc improved from 0.72943 to 0.72957, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6018 - acc: 0.6739 - val_loss: 0.6106 - val_acc: 0.6629\n",
      "Epoch 198/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6011 - acc: 0.6736\n",
      "auc: 79.5671% - val_auc: 72.9487% \n",
      "\n",
      "Epoch 00198: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6013 - acc: 0.6736 - val_loss: 0.6111 - val_acc: 0.6635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6010 - acc: 0.6748\n",
      "auc: 79.5986% - val_auc: 72.9090% \n",
      "\n",
      "Epoch 00199: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6010 - acc: 0.6747 - val_loss: 0.6126 - val_acc: 0.6619\n",
      "Epoch 200/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6011 - acc: 0.6747\n",
      "auc: 79.6429% - val_auc: 72.9597% \n",
      "\n",
      "Epoch 00200: val_auc improved from 0.72957 to 0.72960, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6010 - acc: 0.6747 - val_loss: 0.6105 - val_acc: 0.6624\n",
      "Epoch 201/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6008 - acc: 0.6742\n",
      "auc: 79.5771% - val_auc: 72.8218% \n",
      "\n",
      "Epoch 00201: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6008 - acc: 0.6742 - val_loss: 0.6131 - val_acc: 0.6597\n",
      "Epoch 202/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6007 - acc: 0.6753\n",
      "auc: 79.5112% - val_auc: 72.9313% \n",
      "\n",
      "Epoch 00202: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.6007 - acc: 0.6754 - val_loss: 0.6113 - val_acc: 0.6630\n",
      "Epoch 203/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6002 - acc: 0.6763\n",
      "auc: 79.6575% - val_auc: 72.8465% \n",
      "\n",
      "Epoch 00203: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6001 - acc: 0.6764 - val_loss: 0.6109 - val_acc: 0.6624\n",
      "Epoch 204/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6004 - acc: 0.6742\n",
      "auc: 79.6824% - val_auc: 72.9533% \n",
      "\n",
      "Epoch 00204: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6004 - acc: 0.6743 - val_loss: 0.6115 - val_acc: 0.6612\n",
      "Epoch 205/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6008 - acc: 0.6752\n",
      "auc: 79.7675% - val_auc: 73.0254% \n",
      "\n",
      "Epoch 00205: val_auc improved from 0.72960 to 0.73025, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6007 - acc: 0.6752 - val_loss: 0.6105 - val_acc: 0.6627\n",
      "Epoch 206/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6008 - acc: 0.6756\n",
      "auc: 79.7300% - val_auc: 72.9813% \n",
      "\n",
      "Epoch 00206: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.6007 - acc: 0.6756 - val_loss: 0.6113 - val_acc: 0.6616\n",
      "Epoch 207/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5995 - acc: 0.6757\n",
      "auc: 79.7520% - val_auc: 72.9076% \n",
      "\n",
      "Epoch 00207: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.5995 - acc: 0.6757 - val_loss: 0.6116 - val_acc: 0.6621\n",
      "Epoch 208/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6002 - acc: 0.6753\n",
      "auc: 79.8003% - val_auc: 72.9380% \n",
      "\n",
      "Epoch 00208: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6003 - acc: 0.6752 - val_loss: 0.6111 - val_acc: 0.6616\n",
      "Epoch 209/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6004 - acc: 0.6751\n",
      "auc: 79.7942% - val_auc: 72.9713% \n",
      "\n",
      "Epoch 00209: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6005 - acc: 0.6749 - val_loss: 0.6119 - val_acc: 0.6609\n",
      "Epoch 210/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6011 - acc: 0.6745\n",
      "auc: 79.8489% - val_auc: 72.9650% \n",
      "\n",
      "Epoch 00210: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6012 - acc: 0.6743 - val_loss: 0.6106 - val_acc: 0.6618\n",
      "Epoch 211/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6003 - acc: 0.6759\n",
      "auc: 79.8455% - val_auc: 72.9741% \n",
      "\n",
      "Epoch 00211: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.6003 - acc: 0.6759 - val_loss: 0.6109 - val_acc: 0.6624\n",
      "Epoch 212/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6000 - acc: 0.6767\n",
      "auc: 79.7729% - val_auc: 72.9538% \n",
      "\n",
      "Epoch 00212: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.5999 - acc: 0.6767 - val_loss: 0.6108 - val_acc: 0.6630\n",
      "Epoch 213/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6004 - acc: 0.6753\n",
      "auc: 79.8301% - val_auc: 72.9472% \n",
      "\n",
      "Epoch 00213: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6004 - acc: 0.6754 - val_loss: 0.6098 - val_acc: 0.6638\n",
      "Epoch 214/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5999 - acc: 0.6757\n",
      "auc: 79.8983% - val_auc: 73.0084% \n",
      "\n",
      "Epoch 00214: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.5998 - acc: 0.6758 - val_loss: 0.6108 - val_acc: 0.6628\n",
      "Epoch 215/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5998 - acc: 0.6765\n",
      "auc: 79.8310% - val_auc: 72.9049% \n",
      "\n",
      "Epoch 00215: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.5999 - acc: 0.6763 - val_loss: 0.6109 - val_acc: 0.6617\n",
      "Epoch 216/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5998 - acc: 0.6761\n",
      "auc: 79.9407% - val_auc: 73.0321% \n",
      "\n",
      "Epoch 00216: val_auc improved from 0.73025 to 0.73032, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.5999 - acc: 0.6759 - val_loss: 0.6097 - val_acc: 0.6628\n",
      "Epoch 217/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5996 - acc: 0.6751\n",
      "auc: 79.9251% - val_auc: 72.9346% \n",
      "\n",
      "Epoch 00217: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.5996 - acc: 0.6751 - val_loss: 0.6112 - val_acc: 0.6613\n",
      "Epoch 218/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6001 - acc: 0.6773\n",
      "auc: 80.0682% - val_auc: 72.9070% \n",
      "\n",
      "Epoch 00218: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.6001 - acc: 0.6775 - val_loss: 0.6121 - val_acc: 0.6604\n",
      "Epoch 219/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5989 - acc: 0.6772\n",
      "auc: 79.9750% - val_auc: 72.9147% \n",
      "\n",
      "Epoch 00219: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.5990 - acc: 0.6771 - val_loss: 0.6108 - val_acc: 0.6622\n",
      "Epoch 220/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5994 - acc: 0.6765\n",
      "auc: 79.9742% - val_auc: 72.9904% \n",
      "\n",
      "Epoch 00220: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.5993 - acc: 0.6765 - val_loss: 0.6107 - val_acc: 0.6625\n",
      "Epoch 221/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5997 - acc: 0.6775\n",
      "auc: 79.9798% - val_auc: 72.9452% \n",
      "\n",
      "Epoch 00221: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.5998 - acc: 0.6774 - val_loss: 0.6109 - val_acc: 0.6608\n",
      "Epoch 222/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5981 - acc: 0.6781\n",
      "auc: 79.9551% - val_auc: 72.8632% \n",
      "\n",
      "Epoch 00222: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.5982 - acc: 0.6779 - val_loss: 0.6134 - val_acc: 0.6614\n",
      "Epoch 223/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5996 - acc: 0.6760\n",
      "auc: 79.9945% - val_auc: 72.8480% \n",
      "\n",
      "Epoch 00223: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.5995 - acc: 0.6762 - val_loss: 0.6117 - val_acc: 0.6598\n",
      "Epoch 224/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5982 - acc: 0.6773\n",
      "auc: 80.1353% - val_auc: 72.9485% \n",
      "\n",
      "Epoch 00224: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.5982 - acc: 0.6774 - val_loss: 0.6094 - val_acc: 0.6638\n",
      "Epoch 225/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5988 - acc: 0.6767\n",
      "auc: 80.1114% - val_auc: 72.8339% \n",
      "\n",
      "Epoch 00225: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.5988 - acc: 0.6768 - val_loss: 0.6119 - val_acc: 0.6583\n",
      "Epoch 226/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5992 - acc: 0.6769\n",
      "auc: 80.1040% - val_auc: 73.1231% \n",
      "\n",
      "Epoch 00226: val_auc improved from 0.73032 to 0.73123, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.5991 - acc: 0.6769 - val_loss: 0.6085 - val_acc: 0.6642\n",
      "Epoch 227/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5992 - acc: 0.6756\n",
      "auc: 80.2055% - val_auc: 73.0204% \n",
      "\n",
      "Epoch 00227: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.5992 - acc: 0.6757 - val_loss: 0.6104 - val_acc: 0.6630\n",
      "Epoch 228/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5976 - acc: 0.6787\n",
      "auc: 80.1793% - val_auc: 73.0376% \n",
      "\n",
      "Epoch 00228: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.5978 - acc: 0.6784 - val_loss: 0.6127 - val_acc: 0.6621\n",
      "Epoch 229/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5983 - acc: 0.6766\n",
      "auc: 80.1447% - val_auc: 72.9796% \n",
      "\n",
      "Epoch 00229: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.5983 - acc: 0.6766 - val_loss: 0.6116 - val_acc: 0.6596\n",
      "Epoch 230/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5981 - acc: 0.6771\n",
      "auc: 80.2279% - val_auc: 73.1260% \n",
      "\n",
      "Epoch 00230: val_auc improved from 0.73123 to 0.73126, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.5983 - acc: 0.6770 - val_loss: 0.6097 - val_acc: 0.6629\n",
      "Epoch 231/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5984 - acc: 0.6767\n",
      "auc: 80.1186% - val_auc: 73.0534% \n",
      "\n",
      "Epoch 00231: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.5985 - acc: 0.6766 - val_loss: 0.6138 - val_acc: 0.6603\n",
      "Epoch 232/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5988 - acc: 0.6763\n",
      "auc: 80.2727% - val_auc: 73.0179% \n",
      "\n",
      "Epoch 00232: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 867us/step - loss: 0.5991 - acc: 0.6760 - val_loss: 0.6110 - val_acc: 0.6611\n",
      "Epoch 233/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5981 - acc: 0.6779\n",
      "auc: 80.2382% - val_auc: 73.0010% \n",
      "\n",
      "Epoch 00233: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.5982 - acc: 0.6778 - val_loss: 0.6122 - val_acc: 0.6605\n",
      "Epoch 234/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5986 - acc: 0.6774\n",
      "auc: 80.2533% - val_auc: 73.0094% \n",
      "\n",
      "Epoch 00234: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 865us/step - loss: 0.5986 - acc: 0.6773 - val_loss: 0.6103 - val_acc: 0.6615\n",
      "Epoch 235/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5994 - acc: 0.6756\n",
      "auc: 80.3737% - val_auc: 73.0257% \n",
      "\n",
      "Epoch 00235: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.5993 - acc: 0.6756 - val_loss: 0.6121 - val_acc: 0.6601\n",
      "Epoch 236/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5978 - acc: 0.6776\n",
      "auc: 80.3519% - val_auc: 73.0111% \n",
      "\n",
      "Epoch 00236: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 868us/step - loss: 0.5979 - acc: 0.6775 - val_loss: 0.6099 - val_acc: 0.6618\n",
      "Epoch 237/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5993 - acc: 0.6768\n",
      "auc: 80.3215% - val_auc: 73.0680% \n",
      "\n",
      "Epoch 00237: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.5992 - acc: 0.6768 - val_loss: 0.6090 - val_acc: 0.6644\n",
      "Epoch 238/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5989 - acc: 0.6755\n",
      "auc: 80.3320% - val_auc: 72.9643% \n",
      "\n",
      "Epoch 00238: val_auc did not improve\n",
      "171945/171945 [==============================] - 149s 866us/step - loss: 0.5990 - acc: 0.6753 - val_loss: 0.6107 - val_acc: 0.6616\n",
      "Epoch 239/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5985 - acc: 0.6771\n",
      "auc: 80.3012% - val_auc: 72.9901% \n",
      "\n",
      "Epoch 00239: val_auc did not improve\n",
      "171945/171945 [==============================] - 155s 900us/step - loss: 0.5987 - acc: 0.6769 - val_loss: 0.6109 - val_acc: 0.6605\n",
      "Epoch 240/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5985 - acc: 0.6778\n",
      "auc: 80.2968% - val_auc: 73.0626% \n",
      "\n",
      "Epoch 00240: val_auc did not improve\n",
      "171945/171945 [==============================] - 152s 884us/step - loss: 0.5985 - acc: 0.6779 - val_loss: 0.6100 - val_acc: 0.6633\n",
      "Epoch 241/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5967 - acc: 0.6783\n",
      "auc: 80.3085% - val_auc: 73.0723% \n",
      "\n",
      "Epoch 00241: val_auc did not improve\n",
      "171945/171945 [==============================] - 152s 882us/step - loss: 0.5968 - acc: 0.6781 - val_loss: 0.6115 - val_acc: 0.6608\n",
      "Epoch 242/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5988 - acc: 0.6768\n",
      "auc: 80.4375% - val_auc: 73.0287% \n",
      "\n",
      "Epoch 00242: val_auc did not improve\n",
      "171945/171945 [==============================] - 151s 877us/step - loss: 0.5988 - acc: 0.6768 - val_loss: 0.6107 - val_acc: 0.6605\n",
      "Epoch 243/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5970 - acc: 0.6790\n",
      "auc: 80.3388% - val_auc: 72.9529% \n",
      "\n",
      "Epoch 00243: val_auc did not improve\n",
      "171945/171945 [==============================] - 152s 883us/step - loss: 0.5971 - acc: 0.6789 - val_loss: 0.6106 - val_acc: 0.6619\n",
      "Epoch 244/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5980 - acc: 0.6781\n",
      "auc: 80.3037% - val_auc: 72.8891% \n",
      "\n",
      "Epoch 00244: val_auc did not improve\n",
      "171945/171945 [==============================] - 154s 894us/step - loss: 0.5979 - acc: 0.6781 - val_loss: 0.6108 - val_acc: 0.6616\n",
      "Epoch 245/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5974 - acc: 0.6779\n",
      "auc: 80.3223% - val_auc: 73.0578% \n",
      "\n",
      "Epoch 00245: val_auc did not improve\n",
      "171945/171945 [==============================] - 152s 883us/step - loss: 0.5974 - acc: 0.6781 - val_loss: 0.6103 - val_acc: 0.6630\n",
      "Epoch 246/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5985 - acc: 0.6773\n",
      "auc: 80.3781% - val_auc: 72.9838% \n",
      "\n",
      "Epoch 00246: val_auc did not improve\n",
      "171945/171945 [==============================] - 151s 877us/step - loss: 0.5986 - acc: 0.6772 - val_loss: 0.6109 - val_acc: 0.6618\n",
      "Epoch 247/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5969 - acc: 0.6794\n",
      "auc: 80.3911% - val_auc: 73.0479% \n",
      "\n",
      "Epoch 00247: val_auc did not improve\n",
      "171945/171945 [==============================] - 151s 877us/step - loss: 0.5968 - acc: 0.6793 - val_loss: 0.6116 - val_acc: 0.6616\n",
      "Epoch 248/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5980 - acc: 0.6778\n",
      "auc: 80.3475% - val_auc: 73.0279% \n",
      "\n",
      "Epoch 00248: val_auc did not improve\n",
      "171945/171945 [==============================] - 151s 876us/step - loss: 0.5979 - acc: 0.6778 - val_loss: 0.6144 - val_acc: 0.6609\n",
      "Epoch 249/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5972 - acc: 0.6793\n",
      "auc: 80.5599% - val_auc: 73.0242% \n",
      "\n",
      "Epoch 00249: val_auc did not improve\n",
      "171945/171945 [==============================] - 152s 886us/step - loss: 0.5972 - acc: 0.6792 - val_loss: 0.6110 - val_acc: 0.6617\n",
      "Epoch 250/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5974 - acc: 0.6776\n",
      "auc: 80.5145% - val_auc: 73.0421% \n",
      "\n",
      "Epoch 00250: val_auc did not improve\n",
      "171945/171945 [==============================] - 150s 874us/step - loss: 0.5974 - acc: 0.6777 - val_loss: 0.6105 - val_acc: 0.6614\n",
      "Epoch 251/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5977 - acc: 0.6784\n",
      "auc: 80.4778% - val_auc: 73.0081% \n",
      "\n",
      "Epoch 00251: val_auc did not improve\n",
      "171945/171945 [==============================] - 151s 876us/step - loss: 0.5976 - acc: 0.6784 - val_loss: 0.6108 - val_acc: 0.6616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5972 - acc: 0.6796\n",
      "auc: 80.4466% - val_auc: 72.9831% \n",
      "\n",
      "Epoch 00252: val_auc did not improve\n",
      "171945/171945 [==============================] - 152s 885us/step - loss: 0.5971 - acc: 0.6796 - val_loss: 0.6133 - val_acc: 0.6619\n",
      "Epoch 253/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5971 - acc: 0.6794\n",
      "auc: 80.4385% - val_auc: 73.1233% \n",
      "\n",
      "Epoch 00253: val_auc did not improve\n",
      "171945/171945 [==============================] - 152s 882us/step - loss: 0.5970 - acc: 0.6793 - val_loss: 0.6103 - val_acc: 0.6640\n",
      "Epoch 254/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5981 - acc: 0.6783\n",
      "auc: 80.4669% - val_auc: 73.0705% \n",
      "\n",
      "Epoch 00254: val_auc did not improve\n",
      "171945/171945 [==============================] - 151s 879us/step - loss: 0.5980 - acc: 0.6784 - val_loss: 0.6110 - val_acc: 0.6621\n",
      "Epoch 255/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5969 - acc: 0.6790\n",
      "auc: 80.5629% - val_auc: 72.9684% \n",
      "\n",
      "Epoch 00255: val_auc did not improve\n",
      "171945/171945 [==============================] - 151s 878us/step - loss: 0.5970 - acc: 0.6789 - val_loss: 0.6128 - val_acc: 0.6610\n",
      "Epoch 00255: early stopping\n",
      "Wall time: 10h 36min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#now train\n",
    "history50_fixed = nn.run_model(model=model50_fixed, out_path=\"models/nn_50d_fixed.hdf5\", **run_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/interim/nn50_fixed_history.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save history\n",
    "joblib.dump(model50_fixed.history.history, \"data/interim/nn50_fixed_history.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Train 300d model with fixed embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second model 300 dimensionhal word embeddings. However the number of hidden units is decreases in order mtianta  aprocaml the same number of trainable paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "joke_seq (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 300)          8218800   \n",
      "_________________________________________________________________\n",
      "mask_paddings (Masking)      (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "drop_words (SpatialDropout1D (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "mask_dropped_words (Masking) (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "reccurrent_layer (LSTM)      (None, 150)               270600    \n",
      "_________________________________________________________________\n",
      "drop_dense (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_sigmoid (Dense)        (None, 75)                11325     \n",
      "_________________________________________________________________\n",
      "avg_pred (GlobalAverage)     (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,500,725\n",
      "Trainable params: 281,925\n",
      "Non-trainable params: 8,218,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM, average final\n",
    "model300_fixed = nn.create_model(embedding_matrix=embedding_matrix300, n_hidden=150)\n",
    "model300_fixed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171945 samples, validate on 24564 samples\n",
      "Epoch 1/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6650 - acc: 0.5908\n",
      "auc: 66.1044% - val_auc: 65.8528% \n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.65853, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 218s 1ms/step - loss: 0.6649 - acc: 0.5910 - val_loss: 0.6533 - val_acc: 0.6070\n",
      "Epoch 2/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6544 - acc: 0.6077\n",
      "auc: 67.5849% - val_auc: 67.5304% \n",
      "\n",
      "Epoch 00002: val_auc improved from 0.65853 to 0.67530, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 165s 962us/step - loss: 0.6545 - acc: 0.6077 - val_loss: 0.6420 - val_acc: 0.6247\n",
      "Epoch 3/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6463 - acc: 0.6189\n",
      "auc: 68.6341% - val_auc: 68.5563% \n",
      "\n",
      "Epoch 00003: val_auc improved from 0.67530 to 0.68556, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 966us/step - loss: 0.6463 - acc: 0.6190 - val_loss: 0.6382 - val_acc: 0.6301\n",
      "Epoch 4/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6421 - acc: 0.6257\n",
      "auc: 69.5155% - val_auc: 69.2070% \n",
      "\n",
      "Epoch 00004: val_auc improved from 0.68556 to 0.69207, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 964us/step - loss: 0.6421 - acc: 0.6257 - val_loss: 0.6335 - val_acc: 0.6371\n",
      "Epoch 5/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6394 - acc: 0.6301\n",
      "auc: 69.9569% - val_auc: 69.5781% \n",
      "\n",
      "Epoch 00005: val_auc improved from 0.69207 to 0.69578, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 963us/step - loss: 0.6395 - acc: 0.6298 - val_loss: 0.6308 - val_acc: 0.6416\n",
      "Epoch 6/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6364 - acc: 0.6325\n",
      "auc: 70.3868% - val_auc: 69.8760% \n",
      "\n",
      "Epoch 00006: val_auc improved from 0.69578 to 0.69876, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 165s 961us/step - loss: 0.6365 - acc: 0.6325 - val_loss: 0.6294 - val_acc: 0.6455\n",
      "Epoch 7/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6351 - acc: 0.6360\n",
      "auc: 70.7879% - val_auc: 70.1560% \n",
      "\n",
      "Epoch 00007: val_auc improved from 0.69876 to 0.70156, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 165s 961us/step - loss: 0.6351 - acc: 0.6360 - val_loss: 0.6272 - val_acc: 0.6481\n",
      "Epoch 8/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6331 - acc: 0.6386\n",
      "auc: 71.2621% - val_auc: 70.4578% \n",
      "\n",
      "Epoch 00008: val_auc improved from 0.70156 to 0.70458, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 966us/step - loss: 0.6330 - acc: 0.6387 - val_loss: 0.6256 - val_acc: 0.6464\n",
      "Epoch 9/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6312 - acc: 0.6424\n",
      "auc: 71.6284% - val_auc: 70.6467% \n",
      "\n",
      "Epoch 00009: val_auc improved from 0.70458 to 0.70647, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 965us/step - loss: 0.6312 - acc: 0.6423 - val_loss: 0.6255 - val_acc: 0.6465\n",
      "Epoch 10/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6296 - acc: 0.6437\n",
      "auc: 72.0111% - val_auc: 70.8878% \n",
      "\n",
      "Epoch 00010: val_auc improved from 0.70647 to 0.70888, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 965us/step - loss: 0.6297 - acc: 0.6437 - val_loss: 0.6225 - val_acc: 0.6534\n",
      "Epoch 11/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6283 - acc: 0.6460\n",
      "auc: 72.3704% - val_auc: 71.1269% \n",
      "\n",
      "Epoch 00011: val_auc improved from 0.70888 to 0.71127, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 168s 975us/step - loss: 0.6282 - acc: 0.6462 - val_loss: 0.6213 - val_acc: 0.6551\n",
      "Epoch 12/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6268 - acc: 0.6471\n",
      "auc: 72.7582% - val_auc: 71.3496% \n",
      "\n",
      "Epoch 00012: val_auc improved from 0.71127 to 0.71350, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 167s 971us/step - loss: 0.6268 - acc: 0.6470 - val_loss: 0.6198 - val_acc: 0.6575\n",
      "Epoch 13/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6250 - acc: 0.6498\n",
      "auc: 72.9770% - val_auc: 71.4483% \n",
      "\n",
      "Epoch 00013: val_auc improved from 0.71350 to 0.71448, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 965us/step - loss: 0.6250 - acc: 0.6501 - val_loss: 0.6192 - val_acc: 0.6561\n",
      "Epoch 14/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6232 - acc: 0.6512\n",
      "auc: 73.3769% - val_auc: 71.6693% \n",
      "\n",
      "Epoch 00014: val_auc improved from 0.71448 to 0.71669, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 966us/step - loss: 0.6230 - acc: 0.6512 - val_loss: 0.6182 - val_acc: 0.6591\n",
      "Epoch 15/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6222 - acc: 0.6532\n",
      "auc: 73.7055% - val_auc: 71.7904% \n",
      "\n",
      "Epoch 00015: val_auc improved from 0.71669 to 0.71790, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 169s 981us/step - loss: 0.6222 - acc: 0.6531 - val_loss: 0.6165 - val_acc: 0.6585\n",
      "Epoch 16/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6205 - acc: 0.6543\n",
      "auc: 73.9804% - val_auc: 71.9738% \n",
      "\n",
      "Epoch 00016: val_auc improved from 0.71790 to 0.71974, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 168s 978us/step - loss: 0.6204 - acc: 0.6545 - val_loss: 0.6155 - val_acc: 0.6596\n",
      "Epoch 17/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6189 - acc: 0.6567\n",
      "auc: 74.1996% - val_auc: 72.1171% \n",
      "\n",
      "Epoch 00017: val_auc improved from 0.71974 to 0.72117, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 968us/step - loss: 0.6188 - acc: 0.6568 - val_loss: 0.6156 - val_acc: 0.6598\n",
      "Epoch 18/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6182 - acc: 0.6574\n",
      "auc: 74.4347% - val_auc: 72.2677% \n",
      "\n",
      "Epoch 00018: val_auc improved from 0.72117 to 0.72268, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 168s 974us/step - loss: 0.6183 - acc: 0.6572 - val_loss: 0.6139 - val_acc: 0.6644\n",
      "Epoch 19/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6168 - acc: 0.6585\n",
      "auc: 74.7709% - val_auc: 72.3379% \n",
      "\n",
      "Epoch 00019: val_auc improved from 0.72268 to 0.72338, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 168s 974us/step - loss: 0.6169 - acc: 0.6585 - val_loss: 0.6142 - val_acc: 0.6584\n",
      "Epoch 20/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6152 - acc: 0.6610\n",
      "auc: 74.9777% - val_auc: 72.5205% \n",
      "\n",
      "Epoch 00020: val_auc improved from 0.72338 to 0.72520, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 167s 973us/step - loss: 0.6152 - acc: 0.6610 - val_loss: 0.6123 - val_acc: 0.6649\n",
      "Epoch 21/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6140 - acc: 0.6617\n",
      "auc: 75.2730% - val_auc: 72.5079% \n",
      "\n",
      "Epoch 00021: val_auc did not improve\n",
      "171945/171945 [==============================] - 166s 965us/step - loss: 0.6140 - acc: 0.6617 - val_loss: 0.6130 - val_acc: 0.6613\n",
      "Epoch 22/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6130 - acc: 0.6627\n",
      "auc: 75.4282% - val_auc: 72.6198% \n",
      "\n",
      "Epoch 00022: val_auc improved from 0.72520 to 0.72620, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 965us/step - loss: 0.6130 - acc: 0.6626 - val_loss: 0.6128 - val_acc: 0.6625\n",
      "Epoch 23/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6118 - acc: 0.6652\n",
      "auc: 75.7800% - val_auc: 72.7266% \n",
      "\n",
      "Epoch 00023: val_auc improved from 0.72620 to 0.72727, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 967us/step - loss: 0.6120 - acc: 0.6649 - val_loss: 0.6121 - val_acc: 0.6633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6118 - acc: 0.6647\n",
      "auc: 75.8764% - val_auc: 72.8139% \n",
      "\n",
      "Epoch 00024: val_auc improved from 0.72727 to 0.72814, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 965us/step - loss: 0.6117 - acc: 0.6648 - val_loss: 0.6113 - val_acc: 0.6647\n",
      "Epoch 25/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6098 - acc: 0.6672\n",
      "auc: 76.1991% - val_auc: 72.9515% \n",
      "\n",
      "Epoch 00025: val_auc improved from 0.72814 to 0.72952, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 963us/step - loss: 0.6099 - acc: 0.6671 - val_loss: 0.6082 - val_acc: 0.6687\n",
      "Epoch 26/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6087 - acc: 0.6680\n",
      "auc: 76.4081% - val_auc: 73.0610% \n",
      "\n",
      "Epoch 00026: val_auc improved from 0.72952 to 0.73061, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 964us/step - loss: 0.6085 - acc: 0.6683 - val_loss: 0.6084 - val_acc: 0.6667\n",
      "Epoch 27/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6083 - acc: 0.6679\n",
      "auc: 76.6277% - val_auc: 73.1170% \n",
      "\n",
      "Epoch 00027: val_auc improved from 0.73061 to 0.73117, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 167s 971us/step - loss: 0.6084 - acc: 0.6678 - val_loss: 0.6081 - val_acc: 0.6665\n",
      "Epoch 28/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6070 - acc: 0.6702\n",
      "auc: 76.8754% - val_auc: 73.2206% \n",
      "\n",
      "Epoch 00028: val_auc improved from 0.73117 to 0.73221, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 964us/step - loss: 0.6069 - acc: 0.6703 - val_loss: 0.6080 - val_acc: 0.6647\n",
      "Epoch 29/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6055 - acc: 0.6711\n",
      "auc: 77.0672% - val_auc: 73.2460% \n",
      "\n",
      "Epoch 00029: val_auc improved from 0.73221 to 0.73246, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 963us/step - loss: 0.6055 - acc: 0.6711 - val_loss: 0.6065 - val_acc: 0.6666\n",
      "Epoch 30/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6048 - acc: 0.6709\n",
      "auc: 77.1802% - val_auc: 73.2534% \n",
      "\n",
      "Epoch 00030: val_auc improved from 0.73246 to 0.73253, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 965us/step - loss: 0.6049 - acc: 0.6708 - val_loss: 0.6064 - val_acc: 0.6680\n",
      "Epoch 31/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6043 - acc: 0.6734\n",
      "auc: 77.3694% - val_auc: 73.3424% \n",
      "\n",
      "Epoch 00031: val_auc improved from 0.73253 to 0.73342, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 963us/step - loss: 0.6040 - acc: 0.6736 - val_loss: 0.6097 - val_acc: 0.6647\n",
      "Epoch 32/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.6737\n",
      "auc: 77.6025% - val_auc: 73.3926% \n",
      "\n",
      "Epoch 00032: val_auc improved from 0.73342 to 0.73393, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 168s 979us/step - loss: 0.6025 - acc: 0.6737 - val_loss: 0.6060 - val_acc: 0.6690\n",
      "Epoch 33/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.6758\n",
      "auc: 77.8169% - val_auc: 73.4416% \n",
      "\n",
      "Epoch 00033: val_auc improved from 0.73393 to 0.73442, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 168s 974us/step - loss: 0.6019 - acc: 0.6760 - val_loss: 0.6041 - val_acc: 0.6717\n",
      "Epoch 34/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6011 - acc: 0.6758\n",
      "auc: 77.9584% - val_auc: 73.4982% \n",
      "\n",
      "Epoch 00034: val_auc improved from 0.73442 to 0.73498, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 965us/step - loss: 0.6012 - acc: 0.6757 - val_loss: 0.6051 - val_acc: 0.6684\n",
      "Epoch 35/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6006 - acc: 0.6774\n",
      "auc: 78.1331% - val_auc: 73.5321% \n",
      "\n",
      "Epoch 00035: val_auc improved from 0.73498 to 0.73532, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 167s 973us/step - loss: 0.6006 - acc: 0.6774 - val_loss: 0.6053 - val_acc: 0.6691\n",
      "Epoch 36/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6000 - acc: 0.6759\n",
      "auc: 78.2421% - val_auc: 73.5534% \n",
      "\n",
      "Epoch 00036: val_auc improved from 0.73532 to 0.73553, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 966us/step - loss: 0.6002 - acc: 0.6757 - val_loss: 0.6046 - val_acc: 0.6688\n",
      "Epoch 37/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5999 - acc: 0.6776\n",
      "auc: 78.3527% - val_auc: 73.5792% \n",
      "\n",
      "Epoch 00037: val_auc improved from 0.73553 to 0.73579, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 964us/step - loss: 0.6000 - acc: 0.6775 - val_loss: 0.6055 - val_acc: 0.6678\n",
      "Epoch 38/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5983 - acc: 0.6788\n",
      "auc: 78.3396% - val_auc: 73.6109% \n",
      "\n",
      "Epoch 00038: val_auc improved from 0.73579 to 0.73611, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 165s 961us/step - loss: 0.5981 - acc: 0.6790 - val_loss: 0.6061 - val_acc: 0.6676\n",
      "Epoch 39/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5976 - acc: 0.6783\n",
      "auc: 78.7186% - val_auc: 73.7209% \n",
      "\n",
      "Epoch 00039: val_auc improved from 0.73611 to 0.73721, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 165s 962us/step - loss: 0.5976 - acc: 0.6783 - val_loss: 0.6026 - val_acc: 0.6742\n",
      "Epoch 40/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5961 - acc: 0.6815\n",
      "auc: 78.8307% - val_auc: 73.7602% \n",
      "\n",
      "Epoch 00040: val_auc improved from 0.73721 to 0.73760, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 963us/step - loss: 0.5962 - acc: 0.6815 - val_loss: 0.6028 - val_acc: 0.6721\n",
      "Epoch 41/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5962 - acc: 0.6815\n",
      "auc: 78.9704% - val_auc: 73.7705% \n",
      "\n",
      "Epoch 00041: val_auc improved from 0.73760 to 0.73770, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 165s 962us/step - loss: 0.5963 - acc: 0.6812 - val_loss: 0.6040 - val_acc: 0.6703\n",
      "Epoch 42/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5952 - acc: 0.6814\n",
      "auc: 79.0709% - val_auc: 73.8648% \n",
      "\n",
      "Epoch 00042: val_auc improved from 0.73770 to 0.73865, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 963us/step - loss: 0.5953 - acc: 0.6814 - val_loss: 0.6039 - val_acc: 0.6709\n",
      "Epoch 43/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5948 - acc: 0.6818\n",
      "auc: 79.1603% - val_auc: 73.8490% \n",
      "\n",
      "Epoch 00043: val_auc did not improve\n",
      "171945/171945 [==============================] - 165s 962us/step - loss: 0.5949 - acc: 0.6818 - val_loss: 0.6039 - val_acc: 0.6718\n",
      "Epoch 44/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5954 - acc: 0.6812\n",
      "auc: 79.3406% - val_auc: 73.9000% \n",
      "\n",
      "Epoch 00044: val_auc improved from 0.73865 to 0.73900, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 165s 961us/step - loss: 0.5954 - acc: 0.6814 - val_loss: 0.6044 - val_acc: 0.6697\n",
      "Epoch 45/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5928 - acc: 0.6849\n",
      "auc: 79.5317% - val_auc: 73.8954% \n",
      "\n",
      "Epoch 00045: val_auc did not improve\n",
      "171945/171945 [==============================] - 165s 961us/step - loss: 0.5928 - acc: 0.6848 - val_loss: 0.6040 - val_acc: 0.6706\n",
      "Epoch 46/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5935 - acc: 0.6824\n",
      "auc: 79.6082% - val_auc: 73.9537% \n",
      "\n",
      "Epoch 00046: val_auc improved from 0.73900 to 0.73954, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 966us/step - loss: 0.5933 - acc: 0.6827 - val_loss: 0.6023 - val_acc: 0.6727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5920 - acc: 0.6854\n",
      "auc: 79.8025% - val_auc: 73.9297% \n",
      "\n",
      "Epoch 00047: val_auc did not improve\n",
      "171945/171945 [==============================] - 166s 964us/step - loss: 0.5920 - acc: 0.6852 - val_loss: 0.6009 - val_acc: 0.6753\n",
      "Epoch 48/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5910 - acc: 0.6858\n",
      "auc: 79.8932% - val_auc: 74.1709% \n",
      "\n",
      "Epoch 00048: val_auc improved from 0.73954 to 0.74171, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 963us/step - loss: 0.5912 - acc: 0.6856 - val_loss: 0.6006 - val_acc: 0.6756\n",
      "Epoch 49/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5905 - acc: 0.6860\n",
      "auc: 80.0298% - val_auc: 74.0405% \n",
      "\n",
      "Epoch 00049: val_auc did not improve\n",
      "171945/171945 [==============================] - 166s 964us/step - loss: 0.5904 - acc: 0.6859 - val_loss: 0.6032 - val_acc: 0.6715\n",
      "Epoch 50/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5904 - acc: 0.6861\n",
      "auc: 80.1043% - val_auc: 74.1184% \n",
      "\n",
      "Epoch 00050: val_auc did not improve\n",
      "171945/171945 [==============================] - 167s 971us/step - loss: 0.5904 - acc: 0.6861 - val_loss: 0.6002 - val_acc: 0.6768\n",
      "Epoch 51/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5898 - acc: 0.6872\n",
      "auc: 80.2905% - val_auc: 74.1531% \n",
      "\n",
      "Epoch 00051: val_auc did not improve\n",
      "171945/171945 [==============================] - 166s 963us/step - loss: 0.5898 - acc: 0.6871 - val_loss: 0.6010 - val_acc: 0.6766\n",
      "Epoch 52/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5898 - acc: 0.6875\n",
      "auc: 80.3069% - val_auc: 74.0846% \n",
      "\n",
      "Epoch 00052: val_auc did not improve\n",
      "171945/171945 [==============================] - 165s 962us/step - loss: 0.5899 - acc: 0.6874 - val_loss: 0.6026 - val_acc: 0.6740\n",
      "Epoch 53/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5884 - acc: 0.6877\n",
      "auc: 80.4948% - val_auc: 74.0368% \n",
      "\n",
      "Epoch 00053: val_auc did not improve\n",
      "171945/171945 [==============================] - 166s 963us/step - loss: 0.5885 - acc: 0.6877 - val_loss: 0.6030 - val_acc: 0.6727\n",
      "Epoch 54/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5879 - acc: 0.6887\n",
      "auc: 80.5865% - val_auc: 74.1591% \n",
      "\n",
      "Epoch 00054: val_auc did not improve\n",
      "171945/171945 [==============================] - 166s 964us/step - loss: 0.5880 - acc: 0.6886 - val_loss: 0.6025 - val_acc: 0.6731\n",
      "Epoch 55/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5883 - acc: 0.6891\n",
      "auc: 80.6905% - val_auc: 74.1879% \n",
      "\n",
      "Epoch 00055: val_auc improved from 0.74171 to 0.74188, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 165s 962us/step - loss: 0.5882 - acc: 0.6891 - val_loss: 0.6037 - val_acc: 0.6729\n",
      "Epoch 56/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5877 - acc: 0.6881\n",
      "auc: 80.7119% - val_auc: 74.3025% \n",
      "\n",
      "Epoch 00056: val_auc improved from 0.74188 to 0.74302, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 165s 962us/step - loss: 0.5878 - acc: 0.6879 - val_loss: 0.6004 - val_acc: 0.6780\n",
      "Epoch 57/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5873 - acc: 0.6890\n",
      "auc: 80.8064% - val_auc: 74.2101% \n",
      "\n",
      "Epoch 00057: val_auc did not improve\n",
      "171945/171945 [==============================] - 165s 962us/step - loss: 0.5873 - acc: 0.6889 - val_loss: 0.6032 - val_acc: 0.6733\n",
      "Epoch 58/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5860 - acc: 0.6908\n",
      "auc: 80.9723% - val_auc: 74.2225% \n",
      "\n",
      "Epoch 00058: val_auc did not improve\n",
      "171945/171945 [==============================] - 165s 960us/step - loss: 0.5860 - acc: 0.6910 - val_loss: 0.6006 - val_acc: 0.6759\n",
      "Epoch 59/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5863 - acc: 0.6901\n",
      "auc: 81.0777% - val_auc: 74.2858% \n",
      "\n",
      "Epoch 00059: val_auc did not improve\n",
      "171945/171945 [==============================] - 165s 962us/step - loss: 0.5863 - acc: 0.6901 - val_loss: 0.6005 - val_acc: 0.6772\n",
      "Epoch 60/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5851 - acc: 0.6919\n",
      "auc: 81.1915% - val_auc: 74.3009% \n",
      "\n",
      "Epoch 00060: val_auc did not improve\n",
      "171945/171945 [==============================] - 166s 963us/step - loss: 0.5852 - acc: 0.6918 - val_loss: 0.6005 - val_acc: 0.6752\n",
      "Epoch 61/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5851 - acc: 0.6910\n",
      "auc: 81.2533% - val_auc: 74.2970% \n",
      "\n",
      "Epoch 00061: val_auc did not improve\n",
      "171945/171945 [==============================] - 165s 961us/step - loss: 0.5852 - acc: 0.6910 - val_loss: 0.6025 - val_acc: 0.6736\n",
      "Epoch 62/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5841 - acc: 0.6939\n",
      "auc: 81.4120% - val_auc: 74.3468% \n",
      "\n",
      "Epoch 00062: val_auc improved from 0.74302 to 0.74347, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 166s 964us/step - loss: 0.5840 - acc: 0.6939 - val_loss: 0.6009 - val_acc: 0.6778\n",
      "Epoch 63/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5837 - acc: 0.6917\n",
      "auc: 81.4334% - val_auc: 74.3253% \n",
      "\n",
      "Epoch 00063: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 953us/step - loss: 0.5837 - acc: 0.6916 - val_loss: 0.6020 - val_acc: 0.6748\n",
      "Epoch 64/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5836 - acc: 0.6929\n",
      "auc: 81.4821% - val_auc: 74.2866% \n",
      "\n",
      "Epoch 00064: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 955us/step - loss: 0.5837 - acc: 0.6928 - val_loss: 0.6026 - val_acc: 0.6740\n",
      "Epoch 65/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5822 - acc: 0.6944\n",
      "auc: 81.6597% - val_auc: 74.3318% \n",
      "\n",
      "Epoch 00065: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 953us/step - loss: 0.5822 - acc: 0.6944 - val_loss: 0.6043 - val_acc: 0.6743\n",
      "Epoch 66/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5832 - acc: 0.6932\n",
      "auc: 81.7457% - val_auc: 74.2946% \n",
      "\n",
      "Epoch 00066: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 953us/step - loss: 0.5832 - acc: 0.6932 - val_loss: 0.6026 - val_acc: 0.6748\n",
      "Epoch 67/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5810 - acc: 0.6943\n",
      "auc: 81.8728% - val_auc: 74.3545% \n",
      "\n",
      "Epoch 00067: val_auc improved from 0.74347 to 0.74354, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 164s 953us/step - loss: 0.5810 - acc: 0.6943 - val_loss: 0.6027 - val_acc: 0.6749\n",
      "Epoch 68/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5811 - acc: 0.6953\n",
      "auc: 81.9630% - val_auc: 74.2940% \n",
      "\n",
      "Epoch 00068: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 955us/step - loss: 0.5810 - acc: 0.6954 - val_loss: 0.6040 - val_acc: 0.6735\n",
      "Epoch 69/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5811 - acc: 0.6958\n",
      "auc: 81.9903% - val_auc: 74.4463% \n",
      "\n",
      "Epoch 00069: val_auc improved from 0.74354 to 0.74446, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5810 - acc: 0.6957 - val_loss: 0.6003 - val_acc: 0.6775\n",
      "Epoch 70/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5797 - acc: 0.6960\n",
      "auc: 82.1581% - val_auc: 74.3376% \n",
      "\n",
      "Epoch 00070: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5798 - acc: 0.6957 - val_loss: 0.6010 - val_acc: 0.6757\n",
      "Epoch 71/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5818 - acc: 0.6928\n",
      "auc: 82.1721% - val_auc: 74.3886% \n",
      "\n",
      "Epoch 00071: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5816 - acc: 0.6929 - val_loss: 0.6018 - val_acc: 0.6751\n",
      "Epoch 72/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5794 - acc: 0.6962\n",
      "auc: 82.2991% - val_auc: 74.3828% \n",
      "\n",
      "Epoch 00072: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5794 - acc: 0.6960 - val_loss: 0.6040 - val_acc: 0.6733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5803 - acc: 0.6958\n",
      "auc: 82.3871% - val_auc: 74.4503% \n",
      "\n",
      "Epoch 00073: val_auc improved from 0.74446 to 0.74450, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 164s 953us/step - loss: 0.5803 - acc: 0.6958 - val_loss: 0.6010 - val_acc: 0.6752\n",
      "Epoch 74/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5793 - acc: 0.6966\n",
      "auc: 82.3944% - val_auc: 74.4341% \n",
      "\n",
      "Epoch 00074: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5789 - acc: 0.6970 - val_loss: 0.6038 - val_acc: 0.6731\n",
      "Epoch 75/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5792 - acc: 0.6977\n",
      "auc: 82.5400% - val_auc: 74.4861% \n",
      "\n",
      "Epoch 00075: val_auc improved from 0.74450 to 0.74486, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5790 - acc: 0.6979 - val_loss: 0.5999 - val_acc: 0.6787\n",
      "Epoch 76/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5784 - acc: 0.6966\n",
      "auc: 82.4811% - val_auc: 74.5048% \n",
      "\n",
      "Epoch 00076: val_auc improved from 0.74486 to 0.74505, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5785 - acc: 0.6965 - val_loss: 0.6035 - val_acc: 0.6736\n",
      "Epoch 77/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5774 - acc: 0.6975\n",
      "auc: 82.6023% - val_auc: 74.5244% \n",
      "\n",
      "Epoch 00077: val_auc improved from 0.74505 to 0.74524, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5776 - acc: 0.6973 - val_loss: 0.6016 - val_acc: 0.6770\n",
      "Epoch 78/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5777 - acc: 0.6974\n",
      "auc: 82.7491% - val_auc: 74.5616% \n",
      "\n",
      "Epoch 00078: val_auc improved from 0.74524 to 0.74562, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 164s 953us/step - loss: 0.5776 - acc: 0.6974 - val_loss: 0.6015 - val_acc: 0.6771\n",
      "Epoch 79/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5778 - acc: 0.6985\n",
      "auc: 82.8001% - val_auc: 74.5744% \n",
      "\n",
      "Epoch 00079: val_auc improved from 0.74562 to 0.74574, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 164s 952us/step - loss: 0.5778 - acc: 0.6984 - val_loss: 0.6027 - val_acc: 0.6755\n",
      "Epoch 80/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5770 - acc: 0.6993\n",
      "auc: 82.8056% - val_auc: 74.5823% \n",
      "\n",
      "Epoch 00080: val_auc improved from 0.74574 to 0.74582, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5771 - acc: 0.6994 - val_loss: 0.6003 - val_acc: 0.6775\n",
      "Epoch 81/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5764 - acc: 0.6984\n",
      "auc: 82.9083% - val_auc: 74.5805% \n",
      "\n",
      "Epoch 00081: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5764 - acc: 0.6985 - val_loss: 0.6015 - val_acc: 0.6768\n",
      "Epoch 82/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5761 - acc: 0.6997\n",
      "auc: 82.9366% - val_auc: 74.4955% \n",
      "\n",
      "Epoch 00082: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 953us/step - loss: 0.5764 - acc: 0.6996 - val_loss: 0.6010 - val_acc: 0.6775\n",
      "Epoch 83/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5759 - acc: 0.6994\n",
      "auc: 83.1503% - val_auc: 74.4989% \n",
      "\n",
      "Epoch 00083: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 953us/step - loss: 0.5761 - acc: 0.6993 - val_loss: 0.5992 - val_acc: 0.6781\n",
      "Epoch 84/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5751 - acc: 0.7001\n",
      "auc: 83.1728% - val_auc: 74.5948% \n",
      "\n",
      "Epoch 00084: val_auc improved from 0.74582 to 0.74595, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 164s 955us/step - loss: 0.5752 - acc: 0.7000 - val_loss: 0.6009 - val_acc: 0.6773\n",
      "Epoch 85/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5754 - acc: 0.6996\n",
      "auc: 83.1366% - val_auc: 74.6338% \n",
      "\n",
      "Epoch 00085: val_auc improved from 0.74595 to 0.74634, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 164s 955us/step - loss: 0.5754 - acc: 0.6996 - val_loss: 0.6006 - val_acc: 0.6790\n",
      "Epoch 86/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5747 - acc: 0.7008\n",
      "auc: 83.1879% - val_auc: 74.7080% \n",
      "\n",
      "Epoch 00086: val_auc improved from 0.74634 to 0.74708, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 164s 955us/step - loss: 0.5748 - acc: 0.7007 - val_loss: 0.6016 - val_acc: 0.6765\n",
      "Epoch 87/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5745 - acc: 0.7008\n",
      "auc: 83.3328% - val_auc: 74.5444% \n",
      "\n",
      "Epoch 00087: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5745 - acc: 0.7008 - val_loss: 0.6010 - val_acc: 0.6788\n",
      "Epoch 88/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5741 - acc: 0.7011\n",
      "auc: 83.3625% - val_auc: 74.6109% \n",
      "\n",
      "Epoch 00088: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 953us/step - loss: 0.5740 - acc: 0.7011 - val_loss: 0.6025 - val_acc: 0.6734\n",
      "Epoch 89/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5736 - acc: 0.7003\n",
      "auc: 83.3836% - val_auc: 74.5381% \n",
      "\n",
      "Epoch 00089: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 952us/step - loss: 0.5737 - acc: 0.7000 - val_loss: 0.6036 - val_acc: 0.6738\n",
      "Epoch 90/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5727 - acc: 0.7016\n",
      "auc: 83.5323% - val_auc: 74.6330% \n",
      "\n",
      "Epoch 00090: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 952us/step - loss: 0.5730 - acc: 0.7014 - val_loss: 0.6025 - val_acc: 0.6744\n",
      "Epoch 91/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5731 - acc: 0.7017\n",
      "auc: 83.4977% - val_auc: 74.5642% \n",
      "\n",
      "Epoch 00091: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5731 - acc: 0.7016 - val_loss: 0.6030 - val_acc: 0.6753\n",
      "Epoch 92/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5728 - acc: 0.7010\n",
      "auc: 83.5868% - val_auc: 74.6039% \n",
      "\n",
      "Epoch 00092: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 952us/step - loss: 0.5728 - acc: 0.7010 - val_loss: 0.6019 - val_acc: 0.6777\n",
      "Epoch 93/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5735 - acc: 0.7031\n",
      "auc: 83.6600% - val_auc: 74.5691% \n",
      "\n",
      "Epoch 00093: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 952us/step - loss: 0.5735 - acc: 0.7030 - val_loss: 0.6016 - val_acc: 0.6783\n",
      "Epoch 94/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5737 - acc: 0.7008\n",
      "auc: 83.6785% - val_auc: 74.6854% \n",
      "\n",
      "Epoch 00094: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 951us/step - loss: 0.5737 - acc: 0.7007 - val_loss: 0.5993 - val_acc: 0.6810\n",
      "Epoch 95/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5720 - acc: 0.7021\n",
      "auc: 83.8665% - val_auc: 74.5726% \n",
      "\n",
      "Epoch 00095: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 953us/step - loss: 0.5721 - acc: 0.7020 - val_loss: 0.6007 - val_acc: 0.6785\n",
      "Epoch 96/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5720 - acc: 0.7010\n",
      "auc: 83.9069% - val_auc: 74.6058% \n",
      "\n",
      "Epoch 00096: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 955us/step - loss: 0.5719 - acc: 0.7012 - val_loss: 0.6026 - val_acc: 0.6760\n",
      "Epoch 97/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5720 - acc: 0.7019\n",
      "auc: 83.9197% - val_auc: 74.6353% \n",
      "\n",
      "Epoch 00097: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5718 - acc: 0.7022 - val_loss: 0.6007 - val_acc: 0.6780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5708 - acc: 0.7039\n",
      "auc: 83.9855% - val_auc: 74.6375% \n",
      "\n",
      "Epoch 00098: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 955us/step - loss: 0.5710 - acc: 0.7038 - val_loss: 0.6000 - val_acc: 0.6810\n",
      "Epoch 99/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5702 - acc: 0.7044\n",
      "auc: 84.0394% - val_auc: 74.7326% \n",
      "\n",
      "Epoch 00099: val_auc improved from 0.74708 to 0.74733, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 164s 955us/step - loss: 0.5703 - acc: 0.7043 - val_loss: 0.6011 - val_acc: 0.6791\n",
      "Epoch 100/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5709 - acc: 0.7040\n",
      "auc: 83.9607% - val_auc: 74.6969% \n",
      "\n",
      "Epoch 00100: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 952us/step - loss: 0.5709 - acc: 0.7040 - val_loss: 0.6014 - val_acc: 0.6775\n",
      "Epoch 101/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5705 - acc: 0.7039\n",
      "auc: 84.1715% - val_auc: 74.6533% \n",
      "\n",
      "Epoch 00101: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 953us/step - loss: 0.5706 - acc: 0.7038 - val_loss: 0.6023 - val_acc: 0.6765\n",
      "Epoch 102/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5691 - acc: 0.7056\n",
      "auc: 84.1975% - val_auc: 74.6794% \n",
      "\n",
      "Epoch 00102: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 951us/step - loss: 0.5691 - acc: 0.7057 - val_loss: 0.6009 - val_acc: 0.6784\n",
      "Epoch 103/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5695 - acc: 0.7051\n",
      "auc: 84.2654% - val_auc: 74.7439% \n",
      "\n",
      "Epoch 00103: val_auc improved from 0.74733 to 0.74744, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5696 - acc: 0.7050 - val_loss: 0.6006 - val_acc: 0.6793\n",
      "Epoch 104/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5696 - acc: 0.7042\n",
      "auc: 84.2486% - val_auc: 74.6466% \n",
      "\n",
      "Epoch 00104: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 953us/step - loss: 0.5697 - acc: 0.7040 - val_loss: 0.6003 - val_acc: 0.6805\n",
      "Epoch 105/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5700 - acc: 0.7045\n",
      "auc: 84.3765% - val_auc: 74.7507% \n",
      "\n",
      "Epoch 00105: val_auc improved from 0.74744 to 0.74751, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5697 - acc: 0.7047 - val_loss: 0.6003 - val_acc: 0.6794\n",
      "Epoch 106/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5701 - acc: 0.7034\n",
      "auc: 84.4365% - val_auc: 74.6496% \n",
      "\n",
      "Epoch 00106: val_auc did not improve\n",
      "171945/171945 [==============================] - 168s 980us/step - loss: 0.5700 - acc: 0.7035 - val_loss: 0.6002 - val_acc: 0.6787\n",
      "Epoch 107/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5693 - acc: 0.7038\n",
      "auc: 84.3864% - val_auc: 74.6876% \n",
      "\n",
      "Epoch 00107: val_auc did not improve\n",
      "171945/171945 [==============================] - 166s 963us/step - loss: 0.5694 - acc: 0.7038 - val_loss: 0.6005 - val_acc: 0.6780\n",
      "Epoch 108/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5689 - acc: 0.7048\n",
      "auc: 84.4529% - val_auc: 74.6726% \n",
      "\n",
      "Epoch 00108: val_auc did not improve\n",
      "171945/171945 [==============================] - 166s 965us/step - loss: 0.5692 - acc: 0.7045 - val_loss: 0.6038 - val_acc: 0.6753\n",
      "Epoch 109/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5693 - acc: 0.7051\n",
      "auc: 84.5410% - val_auc: 74.7108% \n",
      "\n",
      "Epoch 00109: val_auc did not improve\n",
      "171945/171945 [==============================] - 166s 963us/step - loss: 0.5694 - acc: 0.7049 - val_loss: 0.6020 - val_acc: 0.6762\n",
      "Epoch 110/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5689 - acc: 0.7056\n",
      "auc: 84.5461% - val_auc: 74.7218% \n",
      "\n",
      "Epoch 00110: val_auc did not improve\n",
      "171945/171945 [==============================] - 165s 958us/step - loss: 0.5690 - acc: 0.7055 - val_loss: 0.6017 - val_acc: 0.6770\n",
      "Epoch 111/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5689 - acc: 0.7063\n",
      "auc: 84.5739% - val_auc: 74.7453% \n",
      "\n",
      "Epoch 00111: val_auc did not improve\n",
      "171945/171945 [==============================] - 165s 959us/step - loss: 0.5690 - acc: 0.7062 - val_loss: 0.6019 - val_acc: 0.6765\n",
      "Epoch 112/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5685 - acc: 0.7056\n",
      "auc: 84.6286% - val_auc: 74.6725% \n",
      "\n",
      "Epoch 00112: val_auc did not improve\n",
      "171945/171945 [==============================] - 165s 961us/step - loss: 0.5685 - acc: 0.7056 - val_loss: 0.6021 - val_acc: 0.6773\n",
      "Epoch 113/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5679 - acc: 0.7059\n",
      "auc: 84.6269% - val_auc: 74.7063% \n",
      "\n",
      "Epoch 00113: val_auc did not improve\n",
      "171945/171945 [==============================] - 165s 961us/step - loss: 0.5679 - acc: 0.7060 - val_loss: 0.6031 - val_acc: 0.6765\n",
      "Epoch 114/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5691 - acc: 0.7048\n",
      "auc: 84.6907% - val_auc: 74.8227% \n",
      "\n",
      "Epoch 00114: val_auc improved from 0.74751 to 0.74823, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 165s 961us/step - loss: 0.5691 - acc: 0.7050 - val_loss: 0.6010 - val_acc: 0.6792\n",
      "Epoch 115/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5676 - acc: 0.7060\n",
      "auc: 84.7955% - val_auc: 74.7127% \n",
      "\n",
      "Epoch 00115: val_auc did not improve\n",
      "171945/171945 [==============================] - 165s 961us/step - loss: 0.5676 - acc: 0.7060 - val_loss: 0.6015 - val_acc: 0.6775\n",
      "Epoch 116/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5673 - acc: 0.7069\n",
      "auc: 84.7591% - val_auc: 74.8367% \n",
      "\n",
      "Epoch 00116: val_auc improved from 0.74823 to 0.74837, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 165s 961us/step - loss: 0.5675 - acc: 0.7067 - val_loss: 0.6007 - val_acc: 0.6792\n",
      "Epoch 117/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5664 - acc: 0.7065\n",
      "auc: 84.8696% - val_auc: 74.7171% \n",
      "\n",
      "Epoch 00117: val_auc did not improve\n",
      "171945/171945 [==============================] - 165s 961us/step - loss: 0.5663 - acc: 0.7068 - val_loss: 0.6015 - val_acc: 0.6784\n",
      "Epoch 118/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5671 - acc: 0.7065\n",
      "auc: 84.9233% - val_auc: 74.7701% \n",
      "\n",
      "Epoch 00118: val_auc did not improve\n",
      "171945/171945 [==============================] - 165s 961us/step - loss: 0.5672 - acc: 0.7065 - val_loss: 0.6001 - val_acc: 0.6797\n",
      "Epoch 119/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5680 - acc: 0.7063\n",
      "auc: 84.8833% - val_auc: 74.8257% \n",
      "\n",
      "Epoch 00119: val_auc did not improve\n",
      "171945/171945 [==============================] - 165s 961us/step - loss: 0.5681 - acc: 0.7062 - val_loss: 0.6014 - val_acc: 0.6786\n",
      "Epoch 120/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5655 - acc: 0.7088\n",
      "auc: 84.9549% - val_auc: 74.8672% \n",
      "\n",
      "Epoch 00120: val_auc improved from 0.74837 to 0.74867, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 164s 956us/step - loss: 0.5655 - acc: 0.7089 - val_loss: 0.6011 - val_acc: 0.6787\n",
      "Epoch 121/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5668 - acc: 0.7064\n",
      "auc: 85.0453% - val_auc: 74.7917% \n",
      "\n",
      "Epoch 00121: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 955us/step - loss: 0.5668 - acc: 0.7065 - val_loss: 0.6010 - val_acc: 0.6796\n",
      "Epoch 122/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5676 - acc: 0.7062\n",
      "auc: 85.0404% - val_auc: 74.8613% \n",
      "\n",
      "Epoch 00122: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5675 - acc: 0.7063 - val_loss: 0.5996 - val_acc: 0.6825\n",
      "Epoch 123/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5664 - acc: 0.7059\n",
      "auc: 85.0559% - val_auc: 74.8027% \n",
      "\n",
      "Epoch 00123: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5664 - acc: 0.7060 - val_loss: 0.6056 - val_acc: 0.6762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5657 - acc: 0.7080\n",
      "auc: 85.0330% - val_auc: 74.7845% \n",
      "\n",
      "Epoch 00124: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5657 - acc: 0.7080 - val_loss: 0.6021 - val_acc: 0.6805\n",
      "Epoch 125/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5668 - acc: 0.7058\n",
      "auc: 85.1631% - val_auc: 74.7551% \n",
      "\n",
      "Epoch 00125: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 953us/step - loss: 0.5667 - acc: 0.7060 - val_loss: 0.6021 - val_acc: 0.6790\n",
      "Epoch 126/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5658 - acc: 0.7077\n",
      "auc: 85.1089% - val_auc: 74.7459% \n",
      "\n",
      "Epoch 00126: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 955us/step - loss: 0.5658 - acc: 0.7076 - val_loss: 0.6026 - val_acc: 0.6799\n",
      "Epoch 127/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5650 - acc: 0.7075\n",
      "auc: 85.2396% - val_auc: 74.8596% \n",
      "\n",
      "Epoch 00127: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 956us/step - loss: 0.5650 - acc: 0.7075 - val_loss: 0.6005 - val_acc: 0.6808\n",
      "Epoch 128/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5641 - acc: 0.7087\n",
      "auc: 85.2651% - val_auc: 74.8410% \n",
      "\n",
      "Epoch 00128: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 953us/step - loss: 0.5639 - acc: 0.7089 - val_loss: 0.6018 - val_acc: 0.6806\n",
      "Epoch 129/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5630 - acc: 0.7101\n",
      "auc: 85.2999% - val_auc: 74.7666% \n",
      "\n",
      "Epoch 00129: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 955us/step - loss: 0.5631 - acc: 0.7101 - val_loss: 0.6030 - val_acc: 0.6791\n",
      "Epoch 130/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5635 - acc: 0.7091\n",
      "auc: 85.2840% - val_auc: 74.7917% \n",
      "\n",
      "Epoch 00130: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 955us/step - loss: 0.5636 - acc: 0.7091 - val_loss: 0.6043 - val_acc: 0.6766\n",
      "Epoch 131/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5646 - acc: 0.7096\n",
      "auc: 85.3685% - val_auc: 74.8364% \n",
      "\n",
      "Epoch 00131: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 955us/step - loss: 0.5645 - acc: 0.7098 - val_loss: 0.6011 - val_acc: 0.6817\n",
      "Epoch 132/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5638 - acc: 0.7105\n",
      "auc: 85.4707% - val_auc: 74.8279% \n",
      "\n",
      "Epoch 00132: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5638 - acc: 0.7105 - val_loss: 0.6033 - val_acc: 0.6792\n",
      "Epoch 133/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5650 - acc: 0.7081\n",
      "auc: 85.4662% - val_auc: 74.7575% \n",
      "\n",
      "Epoch 00133: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5650 - acc: 0.7080 - val_loss: 0.6039 - val_acc: 0.6787\n",
      "Epoch 134/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5637 - acc: 0.7114\n",
      "auc: 85.4899% - val_auc: 74.7720% \n",
      "\n",
      "Epoch 00134: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 953us/step - loss: 0.5637 - acc: 0.7114 - val_loss: 0.6032 - val_acc: 0.6792\n",
      "Epoch 135/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5651 - acc: 0.7087\n",
      "auc: 85.4170% - val_auc: 74.8510% \n",
      "\n",
      "Epoch 00135: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 955us/step - loss: 0.5649 - acc: 0.7087 - val_loss: 0.6036 - val_acc: 0.6781\n",
      "Epoch 136/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5637 - acc: 0.7107\n",
      "auc: 85.5172% - val_auc: 74.7397% \n",
      "\n",
      "Epoch 00136: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 954us/step - loss: 0.5637 - acc: 0.7107 - val_loss: 0.6018 - val_acc: 0.6781\n",
      "Epoch 137/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5631 - acc: 0.7110\n",
      "auc: 85.5234% - val_auc: 74.7914% \n",
      "\n",
      "Epoch 00137: val_auc did not improve\n",
      "171945/171945 [==============================] - 164s 955us/step - loss: 0.5632 - acc: 0.7111 - val_loss: 0.6066 - val_acc: 0.6775\n",
      "Epoch 138/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5636 - acc: 0.7103\n",
      "auc: 85.5049% - val_auc: 74.7697% \n",
      "\n",
      "Epoch 00138: val_auc did not improve\n",
      "171945/171945 [==============================] - 169s 981us/step - loss: 0.5635 - acc: 0.7105 - val_loss: 0.6054 - val_acc: 0.6776\n",
      "Epoch 139/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5632 - acc: 0.7101\n",
      "auc: 85.5182% - val_auc: 74.8382% \n",
      "\n",
      "Epoch 00139: val_auc did not improve\n",
      "171945/171945 [==============================] - 168s 976us/step - loss: 0.5633 - acc: 0.7101 - val_loss: 0.6041 - val_acc: 0.6788\n",
      "Epoch 140/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5641 - acc: 0.7092\n",
      "auc: 85.6901% - val_auc: 74.6942% \n",
      "\n",
      "Epoch 00140: val_auc did not improve\n",
      "171945/171945 [==============================] - 166s 963us/step - loss: 0.5641 - acc: 0.7092 - val_loss: 0.6025 - val_acc: 0.6803\n",
      "Epoch 141/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5633 - acc: 0.7098\n",
      "auc: 85.6775% - val_auc: 74.7175% \n",
      "\n",
      "Epoch 00141: val_auc did not improve\n",
      "171945/171945 [==============================] - 165s 960us/step - loss: 0.5631 - acc: 0.7101 - val_loss: 0.6030 - val_acc: 0.6812\n",
      "Epoch 142/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5640 - acc: 0.7094\n",
      "auc: 85.6801% - val_auc: 74.7739% \n",
      "\n",
      "Epoch 00142: val_auc did not improve\n",
      "171945/171945 [==============================] - 167s 973us/step - loss: 0.5639 - acc: 0.7095 - val_loss: 0.6047 - val_acc: 0.6779\n",
      "Epoch 143/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5636 - acc: 0.7095\n",
      "auc: 85.6758% - val_auc: 74.8429% \n",
      "\n",
      "Epoch 00143: val_auc did not improve\n",
      "171945/171945 [==============================] - 166s 965us/step - loss: 0.5634 - acc: 0.7097 - val_loss: 0.6020 - val_acc: 0.6797\n",
      "Epoch 144/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5616 - acc: 0.7113\n",
      "auc: 85.7051% - val_auc: 74.8369% \n",
      "\n",
      "Epoch 00144: val_auc did not improve\n",
      "171945/171945 [==============================] - 166s 963us/step - loss: 0.5617 - acc: 0.7113 - val_loss: 0.6036 - val_acc: 0.6796\n",
      "Epoch 145/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5622 - acc: 0.7114\n",
      "auc: 85.8733% - val_auc: 74.7674% \n",
      "\n",
      "Epoch 00145: val_auc did not improve\n",
      "171945/171945 [==============================] - 165s 961us/step - loss: 0.5622 - acc: 0.7114 - val_loss: 0.6041 - val_acc: 0.6787\n",
      "Epoch 00145: early stopping\n",
      "Wall time: 6h 40min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#now train\n",
    "history300_fixed = nn.run_model(model=model300_fixed, out_path=\"models/nn_300d_fixed.hdf5\", **run_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save history\n",
    "joblib.dump(history300_fixed.history, \"data/interim/nn30_fixed_history.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Train 50d model with trainable embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will now make embedding layer of first model trainable. Dropout of inputs to recurrent layer is automatically increased when the embedding layer is trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model50_trained = nn.create_model(n_hidden=150, embedding_matrix=embedding_matrix50, train_embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "joke_seq (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 50)           1369800   \n",
      "_________________________________________________________________\n",
      "mask_paddings (Masking)      (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "drop_words (SpatialDropout1D (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "mask_dropped_words (Masking) (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "reccurrent_layer (LSTM)      (None, 150)               120600    \n",
      "_________________________________________________________________\n",
      "drop_dense (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_sigmoid (Dense)        (None, 75)                11325     \n",
      "_________________________________________________________________\n",
      "avg_pred (GlobalAverage)     (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,501,725\n",
      "Trainable params: 1,501,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Load weights\n",
    "model50_trained.load_weights('models/nn_50d_fixed.hdf5')\n",
    "model50_trained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171945 samples, validate on 24564 samples\n",
      "Epoch 1/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6274 - acc: 0.6472 val_auc: 73.1424%\n",
      "Epoch 00001: val_auc improved from -inf to 0.73142, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 177s 1ms/step - loss: 0.6273 - acc: 0.6474 - val_loss: 0.6097 - val_acc: 0.6604\n",
      "Epoch 2/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6253 - acc: 0.6479 val_auc: 73.0896%\n",
      "Epoch 00002: val_auc did not improve\n",
      "171945/171945 [==============================] - 106s 618us/step - loss: 0.6251 - acc: 0.6481 - val_loss: 0.6088 - val_acc: 0.6616\n",
      "Epoch 3/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6232 - acc: 0.6520 val_auc: 73.0396%\n",
      "Epoch 00003: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 603us/step - loss: 0.6231 - acc: 0.6520 - val_loss: 0.6091 - val_acc: 0.6604\n",
      "Epoch 4/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6229 - acc: 0.6512 val_auc: 73.0330%\n",
      "Epoch 00004: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 596us/step - loss: 0.6228 - acc: 0.6513 - val_loss: 0.6101 - val_acc: 0.6608\n",
      "Epoch 5/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6217 - acc: 0.6526 val_auc: 73.0178%\n",
      "Epoch 00005: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 595us/step - loss: 0.6217 - acc: 0.6525 - val_loss: 0.6100 - val_acc: 0.6606\n",
      "Epoch 6/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6221 - acc: 0.6518 val_auc: 72.9887%\n",
      "Epoch 00006: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 597us/step - loss: 0.6221 - acc: 0.6518 - val_loss: 0.6100 - val_acc: 0.6600\n",
      "Epoch 7/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6209 - acc: 0.6528 val_auc: 72.9632%\n",
      "Epoch 00007: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 595us/step - loss: 0.6209 - acc: 0.6527 - val_loss: 0.6105 - val_acc: 0.6599\n",
      "Epoch 8/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6206 - acc: 0.6534 val_auc: 72.9758%\n",
      "Epoch 00008: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 596us/step - loss: 0.6207 - acc: 0.6533 - val_loss: 0.6097 - val_acc: 0.6596\n",
      "Epoch 9/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6198 - acc: 0.6540 val_auc: 72.9666%\n",
      "Epoch 00009: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 597us/step - loss: 0.6199 - acc: 0.6540 - val_loss: 0.6106 - val_acc: 0.6589\n",
      "Epoch 10/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6197 - acc: 0.6543 val_auc: 72.9726%\n",
      "Epoch 00010: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 607us/step - loss: 0.6197 - acc: 0.6543 - val_loss: 0.6101 - val_acc: 0.6593\n",
      "Epoch 11/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6190 - acc: 0.6548 val_auc: 72.9487%\n",
      "Epoch 00011: val_auc did not improve\n",
      "171945/171945 [==============================] - 105s 608us/step - loss: 0.6192 - acc: 0.6546 - val_loss: 0.6107 - val_acc: 0.6600\n",
      "Epoch 12/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6197 - acc: 0.6549 val_auc: 72.9499%\n",
      "Epoch 00012: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 605us/step - loss: 0.6196 - acc: 0.6550 - val_loss: 0.6101 - val_acc: 0.6593\n",
      "Epoch 13/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6194 - acc: 0.6549 val_auc: 72.9756%\n",
      "Epoch 00013: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 599us/step - loss: 0.6193 - acc: 0.6551 - val_loss: 0.6096 - val_acc: 0.6597\n",
      "Epoch 14/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6194 - acc: 0.6537 val_auc: 72.9859%\n",
      "Epoch 00014: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 600us/step - loss: 0.6194 - acc: 0.6537 - val_loss: 0.6101 - val_acc: 0.6594\n",
      "Epoch 15/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6184 - acc: 0.6564 val_auc: 72.9682%\n",
      "Epoch 00015: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 600us/step - loss: 0.6184 - acc: 0.6563 - val_loss: 0.6108 - val_acc: 0.6595\n",
      "Epoch 16/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6179 - acc: 0.6557 val_auc: 72.9828%\n",
      "Epoch 00016: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 593us/step - loss: 0.6178 - acc: 0.6556 - val_loss: 0.6110 - val_acc: 0.6596\n",
      "Epoch 17/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6177 - acc: 0.6571 val_auc: 72.9800%\n",
      "Epoch 00017: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 593us/step - loss: 0.6177 - acc: 0.6569 - val_loss: 0.6100 - val_acc: 0.6608\n",
      "Epoch 18/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6171 - acc: 0.6572 val_auc: 73.0193%\n",
      "Epoch 00018: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 591us/step - loss: 0.6172 - acc: 0.6571 - val_loss: 0.6112 - val_acc: 0.6596\n",
      "Epoch 19/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6172 - acc: 0.6577 val_auc: 73.0376%\n",
      "Epoch 00019: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 590us/step - loss: 0.6173 - acc: 0.6576 - val_loss: 0.6109 - val_acc: 0.6596\n",
      "Epoch 20/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6170 - acc: 0.6576 val_auc: 73.0539%\n",
      "Epoch 00020: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.6169 - acc: 0.6578 - val_loss: 0.6104 - val_acc: 0.6602\n",
      "Epoch 21/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6162 - acc: 0.6572 val_auc: 73.0249%\n",
      "Epoch 00021: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.6161 - acc: 0.6574 - val_loss: 0.6104 - val_acc: 0.6603\n",
      "Epoch 22/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6161 - acc: 0.6596 val_auc: 73.0489%\n",
      "Epoch 00022: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 591us/step - loss: 0.6161 - acc: 0.6595 - val_loss: 0.6107 - val_acc: 0.6606\n",
      "Epoch 23/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6158 - acc: 0.6588 val_auc: 73.0710%\n",
      "Epoch 00023: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.6160 - acc: 0.6586 - val_loss: 0.6098 - val_acc: 0.6611\n",
      "Epoch 24/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6165 - acc: 0.6575 val_auc: 73.0755%\n",
      "Epoch 00024: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 591us/step - loss: 0.6164 - acc: 0.6576 - val_loss: 0.6095 - val_acc: 0.6612\n",
      "Epoch 25/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6154 - acc: 0.6595 val_auc: 73.0796%\n",
      "Epoch 00025: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 590us/step - loss: 0.6153 - acc: 0.6595 - val_loss: 0.6101 - val_acc: 0.6611\n",
      "Epoch 26/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6155 - acc: 0.6601 val_auc: 73.0974%\n",
      "Epoch 00026: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.6154 - acc: 0.6600 - val_loss: 0.6098 - val_acc: 0.6615\n",
      "Epoch 27/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6143 - acc: 0.6609 val_auc: 73.1246%\n",
      "Epoch 00027: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.6143 - acc: 0.6610 - val_loss: 0.6114 - val_acc: 0.6603\n",
      "Epoch 28/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6156 - acc: 0.6604 val_auc: 73.1356%\n",
      "Epoch 00028: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.6155 - acc: 0.6605 - val_loss: 0.6099 - val_acc: 0.6618\n",
      "Epoch 29/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6147 - acc: 0.6605 val_auc: 73.1370%\n",
      "Epoch 00029: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 590us/step - loss: 0.6146 - acc: 0.6606 - val_loss: 0.6098 - val_acc: 0.6624\n",
      "Epoch 30/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6142 - acc: 0.6615 val_auc: 73.1436%\n",
      "Epoch 00030: val_auc improved from 0.73142 to 0.73144, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 590us/step - loss: 0.6142 - acc: 0.6616 - val_loss: 0.6104 - val_acc: 0.6602\n",
      "Epoch 31/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6136 - acc: 0.6607 val_auc: 73.1533%\n",
      "Epoch 00031: val_auc improved from 0.73144 to 0.73153, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 102s 590us/step - loss: 0.6136 - acc: 0.6607 - val_loss: 0.6099 - val_acc: 0.6613\n",
      "Epoch 32/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6139 - acc: 0.6614 val_auc: 73.1697%\n",
      "Epoch 00032: val_auc improved from 0.73153 to 0.73170, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.6141 - acc: 0.6610 - val_loss: 0.6099 - val_acc: 0.6618\n",
      "Epoch 33/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6137 - acc: 0.6613 val_auc: 73.1877%\n",
      "Epoch 00033: val_auc improved from 0.73170 to 0.73188, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 590us/step - loss: 0.6138 - acc: 0.6612 - val_loss: 0.6096 - val_acc: 0.6620\n",
      "Epoch 34/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6133 - acc: 0.6628 val_auc: 73.2079%\n",
      "Epoch 00034: val_auc improved from 0.73188 to 0.73208, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 590us/step - loss: 0.6133 - acc: 0.6628 - val_loss: 0.6096 - val_acc: 0.6618\n",
      "Epoch 35/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6131 - acc: 0.6634 val_auc: 73.2172%\n",
      "Epoch 00035: val_auc improved from 0.73208 to 0.73217, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.6131 - acc: 0.6634 - val_loss: 0.6104 - val_acc: 0.6615\n",
      "Epoch 36/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6125 - acc: 0.6637 val_auc: 73.2415%\n",
      "Epoch 00036: val_auc improved from 0.73217 to 0.73242, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 590us/step - loss: 0.6126 - acc: 0.6635 - val_loss: 0.6095 - val_acc: 0.6629\n",
      "Epoch 37/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6132 - acc: 0.6637 val_auc: 73.2289%\n",
      "Epoch 00037: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.6133 - acc: 0.6636 - val_loss: 0.6095 - val_acc: 0.6619\n",
      "Epoch 38/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6119 - acc: 0.6648 val_auc: 73.2463%\n",
      "Epoch 00038: val_auc improved from 0.73242 to 0.73246, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.6118 - acc: 0.6649 - val_loss: 0.6099 - val_acc: 0.6616\n",
      "Epoch 39/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6119 - acc: 0.6624 val_auc: 73.2617%\n",
      "Epoch 00039: val_auc improved from 0.73246 to 0.73262, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.6120 - acc: 0.6623 - val_loss: 0.6097 - val_acc: 0.6610\n",
      "Epoch 40/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6109 - acc: 0.6654 val_auc: 73.2167%\n",
      "Epoch 00040: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.6108 - acc: 0.6657 - val_loss: 0.6100 - val_acc: 0.6611\n",
      "Epoch 41/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6116 - acc: 0.6653 val_auc: 73.2636%\n",
      "Epoch 00041: val_auc improved from 0.73262 to 0.73264, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.6117 - acc: 0.6652 - val_loss: 0.6102 - val_acc: 0.6613\n",
      "Epoch 42/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6111 - acc: 0.6645 val_auc: 73.3058%\n",
      "Epoch 00042: val_auc improved from 0.73264 to 0.73306, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.6112 - acc: 0.6644 - val_loss: 0.6097 - val_acc: 0.6612\n",
      "Epoch 43/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6115 - acc: 0.6643 val_auc: 73.2741%\n",
      "Epoch 00043: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.6115 - acc: 0.6645 - val_loss: 0.6099 - val_acc: 0.6617\n",
      "Epoch 44/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6107 - acc: 0.6651 val_auc: 73.3135%\n",
      "Epoch 00044: val_auc improved from 0.73306 to 0.73314, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.6107 - acc: 0.6651 - val_loss: 0.6087 - val_acc: 0.6632\n",
      "Epoch 45/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6105 - acc: 0.6636 val_auc: 73.3190%\n",
      "Epoch 00045: val_auc improved from 0.73314 to 0.73319, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.6106 - acc: 0.6635 - val_loss: 0.6097 - val_acc: 0.6623\n",
      "Epoch 46/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6101 - acc: 0.6648 val_auc: 73.3627%\n",
      "Epoch 00046: val_auc improved from 0.73319 to 0.73363, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.6101 - acc: 0.6648 - val_loss: 0.6092 - val_acc: 0.6629\n",
      "Epoch 47/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6091 - acc: 0.6670 val_auc: 73.3689%\n",
      "Epoch 00047: val_auc improved from 0.73363 to 0.73369, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.6091 - acc: 0.6671 - val_loss: 0.6091 - val_acc: 0.6628\n",
      "Epoch 48/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6106 - acc: 0.6655 val_auc: 73.3714%\n",
      "Epoch 00048: val_auc improved from 0.73369 to 0.73371, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.6107 - acc: 0.6654 - val_loss: 0.6090 - val_acc: 0.6632\n",
      "Epoch 49/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6101 - acc: 0.6652 val_auc: 73.4062%\n",
      "Epoch 00049: val_auc improved from 0.73371 to 0.73406, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.6101 - acc: 0.6653 - val_loss: 0.6091 - val_acc: 0.6624\n",
      "Epoch 50/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6095 - acc: 0.6662 val_auc: 73.3925%\n",
      "Epoch 00050: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.6093 - acc: 0.6663 - val_loss: 0.6088 - val_acc: 0.6627\n",
      "Epoch 51/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6084 - acc: 0.6666 val_auc: 73.4162%\n",
      "Epoch 00051: val_auc improved from 0.73406 to 0.73416, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.6084 - acc: 0.6666 - val_loss: 0.6096 - val_acc: 0.6627\n",
      "Epoch 52/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6085 - acc: 0.6668 val_auc: 73.4333%\n",
      "Epoch 00052: val_auc improved from 0.73416 to 0.73433, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.6085 - acc: 0.6668 - val_loss: 0.6092 - val_acc: 0.6627\n",
      "Epoch 53/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6086 - acc: 0.6672 val_auc: 73.4609%\n",
      "Epoch 00053: val_auc improved from 0.73433 to 0.73461, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.6087 - acc: 0.6670 - val_loss: 0.6091 - val_acc: 0.6635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6086 - acc: 0.6669 val_auc: 73.4592%\n",
      "Epoch 00054: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.6086 - acc: 0.6669 - val_loss: 0.6097 - val_acc: 0.6630\n",
      "Epoch 55/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6072 - acc: 0.6690 val_auc: 73.4497%\n",
      "Epoch 00055: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 599us/step - loss: 0.6074 - acc: 0.6688 - val_loss: 0.6095 - val_acc: 0.6635\n",
      "Epoch 56/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6085 - acc: 0.6665 val_auc: 73.4720%\n",
      "Epoch 00056: val_auc improved from 0.73461 to 0.73472, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 104s 605us/step - loss: 0.6083 - acc: 0.6667 - val_loss: 0.6082 - val_acc: 0.6652\n",
      "Epoch 57/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6069 - acc: 0.6692 val_auc: 73.5014%\n",
      "Epoch 00057: val_auc improved from 0.73472 to 0.73501, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 104s 604us/step - loss: 0.6069 - acc: 0.6693 - val_loss: 0.6083 - val_acc: 0.6646\n",
      "Epoch 58/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6059 - acc: 0.6696 val_auc: 73.4689%\n",
      "Epoch 00058: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 602us/step - loss: 0.6059 - acc: 0.6696 - val_loss: 0.6095 - val_acc: 0.6644\n",
      "Epoch 59/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6062 - acc: 0.6707 val_auc: 73.5166%\n",
      "Epoch 00059: val_auc improved from 0.73501 to 0.73517, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 104s 607us/step - loss: 0.6062 - acc: 0.6707 - val_loss: 0.6091 - val_acc: 0.6639\n",
      "Epoch 60/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6073 - acc: 0.6684 val_auc: 73.5505%\n",
      "Epoch 00060: val_auc improved from 0.73517 to 0.73551, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 104s 607us/step - loss: 0.6074 - acc: 0.6684 - val_loss: 0.6085 - val_acc: 0.6648\n",
      "Epoch 61/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6053 - acc: 0.6714 val_auc: 73.5361%\n",
      "Epoch 00061: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 603us/step - loss: 0.6053 - acc: 0.6713 - val_loss: 0.6085 - val_acc: 0.6648\n",
      "Epoch 62/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6064 - acc: 0.6702 val_auc: 73.5871%\n",
      "Epoch 00062: val_auc improved from 0.73551 to 0.73587, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 103s 599us/step - loss: 0.6063 - acc: 0.6703 - val_loss: 0.6077 - val_acc: 0.6656\n",
      "Epoch 63/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6057 - acc: 0.6701 val_auc: 73.5744%\n",
      "Epoch 00063: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 596us/step - loss: 0.6059 - acc: 0.6699 - val_loss: 0.6084 - val_acc: 0.6652\n",
      "Epoch 64/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6055 - acc: 0.6710 val_auc: 73.5839%\n",
      "Epoch 00064: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 594us/step - loss: 0.6054 - acc: 0.6710 - val_loss: 0.6079 - val_acc: 0.6652\n",
      "Epoch 65/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6050 - acc: 0.6701 val_auc: 73.6549%\n",
      "Epoch 00065: val_auc improved from 0.73587 to 0.73655, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 103s 597us/step - loss: 0.6049 - acc: 0.6703 - val_loss: 0.6071 - val_acc: 0.6660\n",
      "Epoch 66/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6046 - acc: 0.6720 val_auc: 73.6390%\n",
      "Epoch 00066: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 595us/step - loss: 0.6046 - acc: 0.6718 - val_loss: 0.6075 - val_acc: 0.6661\n",
      "Epoch 67/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6037 - acc: 0.6735 val_auc: 73.6720%\n",
      "Epoch 00067: val_auc improved from 0.73655 to 0.73672, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 103s 598us/step - loss: 0.6036 - acc: 0.6736 - val_loss: 0.6070 - val_acc: 0.6663\n",
      "Epoch 68/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6043 - acc: 0.6726 val_auc: 73.6525%\n",
      "Epoch 00068: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 596us/step - loss: 0.6043 - acc: 0.6725 - val_loss: 0.6087 - val_acc: 0.6657\n",
      "Epoch 69/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6032 - acc: 0.6722 val_auc: 73.7029%\n",
      "Epoch 00069: val_auc improved from 0.73672 to 0.73703, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 104s 603us/step - loss: 0.6034 - acc: 0.6721 - val_loss: 0.6080 - val_acc: 0.6659\n",
      "Epoch 70/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6026 - acc: 0.6742 val_auc: 73.6965%\n",
      "Epoch 00070: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 607us/step - loss: 0.6027 - acc: 0.6741 - val_loss: 0.6076 - val_acc: 0.6658\n",
      "Epoch 71/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6029 - acc: 0.6736 val_auc: 73.7105%\n",
      "Epoch 00071: val_auc improved from 0.73703 to 0.73711, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 104s 606us/step - loss: 0.6029 - acc: 0.6736 - val_loss: 0.6075 - val_acc: 0.6660\n",
      "Epoch 72/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6028 - acc: 0.6738 val_auc: 73.7451%\n",
      "Epoch 00072: val_auc improved from 0.73711 to 0.73745, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 105s 610us/step - loss: 0.6027 - acc: 0.6737 - val_loss: 0.6070 - val_acc: 0.6665\n",
      "Epoch 73/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.6746 val_auc: 73.7476%\n",
      "Epoch 00073: val_auc improved from 0.73745 to 0.73748, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 105s 610us/step - loss: 0.6025 - acc: 0.6745 - val_loss: 0.6070 - val_acc: 0.6662\n",
      "Epoch 74/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6027 - acc: 0.6739 val_auc: 73.7463%\n",
      "Epoch 00074: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 607us/step - loss: 0.6027 - acc: 0.6739 - val_loss: 0.6074 - val_acc: 0.6676\n",
      "Epoch 75/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.6747 val_auc: 73.8082%\n",
      "Epoch 00075: val_auc improved from 0.73748 to 0.73808, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 104s 607us/step - loss: 0.6018 - acc: 0.6748 - val_loss: 0.6070 - val_acc: 0.6674\n",
      "Epoch 76/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.6739 val_auc: 73.8130%\n",
      "Epoch 00076: val_auc improved from 0.73808 to 0.73813, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 104s 606us/step - loss: 0.6020 - acc: 0.6740 - val_loss: 0.6064 - val_acc: 0.6685\n",
      "Epoch 77/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.6735 val_auc: 73.7948%\n",
      "Epoch 00077: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 607us/step - loss: 0.6016 - acc: 0.6736 - val_loss: 0.6075 - val_acc: 0.6681\n",
      "Epoch 78/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6005 - acc: 0.6760 val_auc: 73.8384%\n",
      "Epoch 00078: val_auc improved from 0.73813 to 0.73838, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 104s 603us/step - loss: 0.6004 - acc: 0.6762 - val_loss: 0.6071 - val_acc: 0.6681\n",
      "Epoch 79/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6003 - acc: 0.6749 val_auc: 73.7898%\n",
      "Epoch 00079: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 607us/step - loss: 0.6003 - acc: 0.6749 - val_loss: 0.6073 - val_acc: 0.6673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6008 - acc: 0.6754 val_auc: 73.8341%\n",
      "Epoch 00080: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 598us/step - loss: 0.6009 - acc: 0.6754 - val_loss: 0.6078 - val_acc: 0.6670\n",
      "Epoch 81/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5998 - acc: 0.6772 val_auc: 73.8630%\n",
      "Epoch 00081: val_auc improved from 0.73838 to 0.73863, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 103s 598us/step - loss: 0.5999 - acc: 0.6771 - val_loss: 0.6065 - val_acc: 0.6680\n",
      "Epoch 82/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6001 - acc: 0.6777 val_auc: 73.9052%\n",
      "Epoch 00082: val_auc improved from 0.73863 to 0.73905, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 103s 601us/step - loss: 0.6002 - acc: 0.6777 - val_loss: 0.6056 - val_acc: 0.6683\n",
      "Epoch 83/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5999 - acc: 0.6769 val_auc: 73.8701%\n",
      "Epoch 00083: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 598us/step - loss: 0.5999 - acc: 0.6772 - val_loss: 0.6072 - val_acc: 0.6676\n",
      "Epoch 84/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5995 - acc: 0.6767 val_auc: 73.8936%\n",
      "Epoch 00084: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 599us/step - loss: 0.5995 - acc: 0.6768 - val_loss: 0.6058 - val_acc: 0.6684\n",
      "Epoch 85/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5997 - acc: 0.6768 val_auc: 73.9208%\n",
      "Epoch 00085: val_auc improved from 0.73905 to 0.73921, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 103s 600us/step - loss: 0.5997 - acc: 0.6769 - val_loss: 0.6073 - val_acc: 0.6676\n",
      "Epoch 86/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5986 - acc: 0.6767 val_auc: 73.9457%\n",
      "Epoch 00086: val_auc improved from 0.73921 to 0.73946, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 103s 599us/step - loss: 0.5988 - acc: 0.6766 - val_loss: 0.6069 - val_acc: 0.6679\n",
      "Epoch 87/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5985 - acc: 0.6788 val_auc: 73.9429%\n",
      "Epoch 00087: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 601us/step - loss: 0.5985 - acc: 0.6787 - val_loss: 0.6061 - val_acc: 0.6679\n",
      "Epoch 88/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5983 - acc: 0.6784 val_auc: 73.9495%\n",
      "Epoch 00088: val_auc improved from 0.73946 to 0.73950, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 104s 603us/step - loss: 0.5984 - acc: 0.6783 - val_loss: 0.6065 - val_acc: 0.6680\n",
      "Epoch 89/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5982 - acc: 0.6772 val_auc: 73.9848%\n",
      "Epoch 00089: val_auc improved from 0.73950 to 0.73985, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 103s 602us/step - loss: 0.5983 - acc: 0.6771 - val_loss: 0.6066 - val_acc: 0.6679\n",
      "Epoch 90/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5982 - acc: 0.6781 val_auc: 73.9886%\n",
      "Epoch 00090: val_auc improved from 0.73985 to 0.73989, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 105s 609us/step - loss: 0.5984 - acc: 0.6780 - val_loss: 0.6069 - val_acc: 0.6680\n",
      "Epoch 91/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5958 - acc: 0.6812 val_auc: 74.0442%\n",
      "Epoch 00091: val_auc improved from 0.73989 to 0.74044, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 102s 595us/step - loss: 0.5957 - acc: 0.6814 - val_loss: 0.6063 - val_acc: 0.6690\n",
      "Epoch 92/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5977 - acc: 0.6792 val_auc: 74.0354%\n",
      "Epoch 00092: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 597us/step - loss: 0.5977 - acc: 0.6793 - val_loss: 0.6065 - val_acc: 0.6689\n",
      "Epoch 93/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5975 - acc: 0.6792 val_auc: 74.0713%\n",
      "Epoch 00093: val_auc improved from 0.74044 to 0.74071, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 590us/step - loss: 0.5976 - acc: 0.6791 - val_loss: 0.6052 - val_acc: 0.6695\n",
      "Epoch 94/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5981 - acc: 0.6786 val_auc: 74.0452%\n",
      "Epoch 00094: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.5980 - acc: 0.6786 - val_loss: 0.6054 - val_acc: 0.6697\n",
      "Epoch 95/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5958 - acc: 0.6804 val_auc: 74.1093%\n",
      "Epoch 00095: val_auc improved from 0.74071 to 0.74109, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.5958 - acc: 0.6804 - val_loss: 0.6060 - val_acc: 0.6687\n",
      "Epoch 96/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5954 - acc: 0.6815 val_auc: 74.0908%\n",
      "Epoch 00096: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.5954 - acc: 0.6814 - val_loss: 0.6055 - val_acc: 0.6697\n",
      "Epoch 97/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5954 - acc: 0.6802 val_auc: 74.1041%\n",
      "Epoch 00097: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.5954 - acc: 0.6802 - val_loss: 0.6059 - val_acc: 0.6689\n",
      "Epoch 98/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5950 - acc: 0.6825 val_auc: 74.1299%\n",
      "Epoch 00098: val_auc improved from 0.74109 to 0.74130, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.5951 - acc: 0.6823 - val_loss: 0.6060 - val_acc: 0.6695\n",
      "Epoch 99/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5959 - acc: 0.6809 val_auc: 74.1195%\n",
      "Epoch 00099: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.5957 - acc: 0.6810 - val_loss: 0.6059 - val_acc: 0.6688\n",
      "Epoch 100/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5948 - acc: 0.6832 val_auc: 74.1450%\n",
      "Epoch 00100: val_auc improved from 0.74130 to 0.74145, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.5948 - acc: 0.6831 - val_loss: 0.6056 - val_acc: 0.6701\n",
      "Epoch 101/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5951 - acc: 0.6808 val_auc: 74.1589%\n",
      "Epoch 00101: val_auc improved from 0.74145 to 0.74159, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.5950 - acc: 0.6808 - val_loss: 0.6054 - val_acc: 0.6704\n",
      "Epoch 102/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5946 - acc: 0.6810 val_auc: 74.2059%\n",
      "Epoch 00102: val_auc improved from 0.74159 to 0.74206, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.5948 - acc: 0.6809 - val_loss: 0.6043 - val_acc: 0.6706\n",
      "Epoch 103/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5939 - acc: 0.6819 val_auc: 74.2003%\n",
      "Epoch 00103: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.5939 - acc: 0.6818 - val_loss: 0.6056 - val_acc: 0.6696\n",
      "Epoch 104/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5940 - acc: 0.6832 val_auc: 74.2229%\n",
      "Epoch 00104: val_auc improved from 0.74206 to 0.74223, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.5941 - acc: 0.6830 - val_loss: 0.6049 - val_acc: 0.6702\n",
      "Epoch 105/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5931 - acc: 0.6837 val_auc: 74.1677%\n",
      "Epoch 00105: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5931 - acc: 0.6838 - val_loss: 0.6058 - val_acc: 0.6694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5934 - acc: 0.6831 val_auc: 74.2135%\n",
      "Epoch 00106: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5933 - acc: 0.6833 - val_loss: 0.6068 - val_acc: 0.6687\n",
      "Epoch 107/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5933 - acc: 0.6826 val_auc: 74.2290%\n",
      "Epoch 00107: val_auc improved from 0.74223 to 0.74229, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.5933 - acc: 0.6826 - val_loss: 0.6058 - val_acc: 0.6696\n",
      "Epoch 108/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5922 - acc: 0.6847 val_auc: 74.2218%\n",
      "Epoch 00108: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5921 - acc: 0.6847 - val_loss: 0.6049 - val_acc: 0.6711\n",
      "Epoch 109/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5926 - acc: 0.6839 val_auc: 74.2191%\n",
      "Epoch 00109: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.5925 - acc: 0.6840 - val_loss: 0.6063 - val_acc: 0.6688\n",
      "Epoch 110/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5923 - acc: 0.6848 val_auc: 74.2378%\n",
      "Epoch 00110: val_auc improved from 0.74229 to 0.74238, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.5923 - acc: 0.6849 - val_loss: 0.6055 - val_acc: 0.6699\n",
      "Epoch 111/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5916 - acc: 0.6846 val_auc: 74.2872%\n",
      "Epoch 00111: val_auc improved from 0.74238 to 0.74287, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.5916 - acc: 0.6846 - val_loss: 0.6049 - val_acc: 0.6707\n",
      "Epoch 112/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5914 - acc: 0.6849 val_auc: 74.2309%\n",
      "Epoch 00112: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5915 - acc: 0.6848 - val_loss: 0.6062 - val_acc: 0.6691\n",
      "Epoch 113/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5931 - acc: 0.6823 val_auc: 74.2888%\n",
      "Epoch 00113: val_auc improved from 0.74287 to 0.74289, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5930 - acc: 0.6824 - val_loss: 0.6048 - val_acc: 0.6704\n",
      "Epoch 114/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5910 - acc: 0.6857 val_auc: 74.2985%\n",
      "Epoch 00114: val_auc improved from 0.74289 to 0.74299, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5911 - acc: 0.6855 - val_loss: 0.6050 - val_acc: 0.6707\n",
      "Epoch 115/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5908 - acc: 0.6857 val_auc: 74.2934%\n",
      "Epoch 00115: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5909 - acc: 0.6856 - val_loss: 0.6049 - val_acc: 0.6704\n",
      "Epoch 116/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5900 - acc: 0.6859 val_auc: 74.3537%\n",
      "Epoch 00116: val_auc improved from 0.74299 to 0.74354, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5902 - acc: 0.6857 - val_loss: 0.6044 - val_acc: 0.6709\n",
      "Epoch 117/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5898 - acc: 0.6863 val_auc: 74.3351%\n",
      "Epoch 00117: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5899 - acc: 0.6862 - val_loss: 0.6048 - val_acc: 0.6704\n",
      "Epoch 118/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5896 - acc: 0.6872 val_auc: 74.3189%\n",
      "Epoch 00118: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5895 - acc: 0.6872 - val_loss: 0.6054 - val_acc: 0.6706\n",
      "Epoch 119/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5891 - acc: 0.6871 val_auc: 74.3212%\n",
      "Epoch 00119: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5890 - acc: 0.6871 - val_loss: 0.6066 - val_acc: 0.6700\n",
      "Epoch 120/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5901 - acc: 0.6861 val_auc: 74.3732%\n",
      "Epoch 00120: val_auc improved from 0.74354 to 0.74373, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5901 - acc: 0.6861 - val_loss: 0.6058 - val_acc: 0.6701\n",
      "Epoch 121/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5885 - acc: 0.6884 val_auc: 74.4554%\n",
      "Epoch 00121: val_auc improved from 0.74373 to 0.74455, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5883 - acc: 0.6885 - val_loss: 0.6039 - val_acc: 0.6734\n",
      "Epoch 122/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5892 - acc: 0.6873 val_auc: 74.4403%\n",
      "Epoch 00122: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5892 - acc: 0.6872 - val_loss: 0.6046 - val_acc: 0.6715\n",
      "Epoch 123/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5882 - acc: 0.6882 val_auc: 74.4027%\n",
      "Epoch 00123: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5882 - acc: 0.6881 - val_loss: 0.6046 - val_acc: 0.6722\n",
      "Epoch 124/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5866 - acc: 0.6894 val_auc: 74.4637%\n",
      "Epoch 00124: val_auc improved from 0.74455 to 0.74464, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5868 - acc: 0.6891 - val_loss: 0.6043 - val_acc: 0.6729\n",
      "Epoch 125/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5879 - acc: 0.6893 val_auc: 74.4958%\n",
      "Epoch 00125: val_auc improved from 0.74464 to 0.74496, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5879 - acc: 0.6893 - val_loss: 0.6044 - val_acc: 0.6735\n",
      "Epoch 126/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5875 - acc: 0.6885 val_auc: 74.4641%\n",
      "Epoch 00126: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5873 - acc: 0.6887 - val_loss: 0.6046 - val_acc: 0.6730\n",
      "Epoch 127/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5879 - acc: 0.6879 val_auc: 74.4761%\n",
      "Epoch 00127: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5878 - acc: 0.6880 - val_loss: 0.6045 - val_acc: 0.6731\n",
      "Epoch 128/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5872 - acc: 0.6884 val_auc: 74.5164%\n",
      "Epoch 00128: val_auc improved from 0.74496 to 0.74516, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5871 - acc: 0.6884 - val_loss: 0.6033 - val_acc: 0.6740\n",
      "Epoch 129/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5863 - acc: 0.6905 val_auc: 74.5172%\n",
      "Epoch 00129: val_auc improved from 0.74516 to 0.74517, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5863 - acc: 0.6906 - val_loss: 0.6056 - val_acc: 0.6731\n",
      "Epoch 130/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5865 - acc: 0.6903 val_auc: 74.5136%\n",
      "Epoch 00130: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5865 - acc: 0.6902 - val_loss: 0.6047 - val_acc: 0.6733\n",
      "Epoch 131/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5855 - acc: 0.6906 val_auc: 74.5630%\n",
      "Epoch 00131: val_auc improved from 0.74517 to 0.74563, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5855 - acc: 0.6905 - val_loss: 0.6041 - val_acc: 0.6743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5849 - acc: 0.6909 val_auc: 74.5640%\n",
      "Epoch 00132: val_auc improved from 0.74563 to 0.74564, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5850 - acc: 0.6908 - val_loss: 0.6036 - val_acc: 0.6746\n",
      "Epoch 133/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5850 - acc: 0.6919 val_auc: 74.5504%\n",
      "Epoch 00133: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5850 - acc: 0.6920 - val_loss: 0.6057 - val_acc: 0.6729\n",
      "Epoch 134/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5844 - acc: 0.6918 val_auc: 74.5857%\n",
      "Epoch 00134: val_auc improved from 0.74564 to 0.74586, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5845 - acc: 0.6918 - val_loss: 0.6042 - val_acc: 0.6747\n",
      "Epoch 135/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5836 - acc: 0.6930 val_auc: 74.6266%\n",
      "Epoch 00135: val_auc improved from 0.74586 to 0.74627, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5838 - acc: 0.6929 - val_loss: 0.6043 - val_acc: 0.6746\n",
      "Epoch 136/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5837 - acc: 0.6927 val_auc: 74.6303%\n",
      "Epoch 00136: val_auc improved from 0.74627 to 0.74630, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5837 - acc: 0.6927 - val_loss: 0.6037 - val_acc: 0.6746\n",
      "Epoch 137/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5840 - acc: 0.6922 val_auc: 74.6695%\n",
      "Epoch 00137: val_auc improved from 0.74630 to 0.74670, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5841 - acc: 0.6921 - val_loss: 0.6041 - val_acc: 0.6755\n",
      "Epoch 138/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5844 - acc: 0.6924 val_auc: 74.6544%\n",
      "Epoch 00138: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5845 - acc: 0.6923 - val_loss: 0.6053 - val_acc: 0.6748\n",
      "Epoch 139/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5834 - acc: 0.6919 val_auc: 74.6555%\n",
      "Epoch 00139: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.5833 - acc: 0.6921 - val_loss: 0.6054 - val_acc: 0.6742\n",
      "Epoch 140/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5838 - acc: 0.6917 val_auc: 74.6901%\n",
      "Epoch 00140: val_auc improved from 0.74670 to 0.74690, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5837 - acc: 0.6918 - val_loss: 0.6043 - val_acc: 0.6756\n",
      "Epoch 141/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5826 - acc: 0.6928 val_auc: 74.6287%\n",
      "Epoch 00141: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5825 - acc: 0.6929 - val_loss: 0.6035 - val_acc: 0.6753\n",
      "Epoch 142/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5822 - acc: 0.6945 val_auc: 74.6687%\n",
      "Epoch 00142: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5823 - acc: 0.6944 - val_loss: 0.6042 - val_acc: 0.6750\n",
      "Epoch 143/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5813 - acc: 0.6941 val_auc: 74.6089%\n",
      "Epoch 00143: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5812 - acc: 0.6942 - val_loss: 0.6054 - val_acc: 0.6735\n",
      "Epoch 144/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5812 - acc: 0.6950 val_auc: 74.7405%\n",
      "Epoch 00144: val_auc improved from 0.74690 to 0.74741, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5811 - acc: 0.6950 - val_loss: 0.6047 - val_acc: 0.6758\n",
      "Epoch 145/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5814 - acc: 0.6948 val_auc: 74.7361%\n",
      "Epoch 00145: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5813 - acc: 0.6948 - val_loss: 0.6036 - val_acc: 0.6759\n",
      "Epoch 146/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5802 - acc: 0.6958 val_auc: 74.7729%\n",
      "Epoch 00146: val_auc improved from 0.74741 to 0.74773, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5804 - acc: 0.6957 - val_loss: 0.6044 - val_acc: 0.6750\n",
      "Epoch 147/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5808 - acc: 0.6953 val_auc: 74.7945%\n",
      "Epoch 00147: val_auc improved from 0.74773 to 0.74795, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5807 - acc: 0.6953 - val_loss: 0.6035 - val_acc: 0.6764\n",
      "Epoch 148/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5799 - acc: 0.6972 val_auc: 74.7439%\n",
      "Epoch 00148: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5800 - acc: 0.6972 - val_loss: 0.6041 - val_acc: 0.6764\n",
      "Epoch 149/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5797 - acc: 0.6961 val_auc: 74.7849%\n",
      "Epoch 00149: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5798 - acc: 0.6960 - val_loss: 0.6044 - val_acc: 0.6759\n",
      "Epoch 150/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5802 - acc: 0.6957 val_auc: 74.7827%\n",
      "Epoch 00150: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5803 - acc: 0.6955 - val_loss: 0.6031 - val_acc: 0.6778\n",
      "Epoch 151/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5788 - acc: 0.6973 val_auc: 74.7403%\n",
      "Epoch 00151: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5790 - acc: 0.6970 - val_loss: 0.6035 - val_acc: 0.6766\n",
      "Epoch 152/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5793 - acc: 0.6958 val_auc: 74.7988%\n",
      "Epoch 00152: val_auc improved from 0.74795 to 0.74799, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5794 - acc: 0.6958 - val_loss: 0.6024 - val_acc: 0.6782\n",
      "Epoch 153/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5778 - acc: 0.6978 val_auc: 74.7664%\n",
      "Epoch 00153: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5779 - acc: 0.6977 - val_loss: 0.6045 - val_acc: 0.6762\n",
      "Epoch 154/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5787 - acc: 0.6974 val_auc: 74.7867%\n",
      "Epoch 00154: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5787 - acc: 0.6972 - val_loss: 0.6059 - val_acc: 0.6757\n",
      "Epoch 155/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5784 - acc: 0.6974 val_auc: 74.8266%\n",
      "Epoch 00155: val_auc improved from 0.74799 to 0.74827, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5785 - acc: 0.6974 - val_loss: 0.6053 - val_acc: 0.6760\n",
      "Epoch 156/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5783 - acc: 0.6971 val_auc: 74.8085%\n",
      "Epoch 00156: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5783 - acc: 0.6970 - val_loss: 0.6044 - val_acc: 0.6767\n",
      "Epoch 157/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5776 - acc: 0.6975 val_auc: 74.8922%\n",
      "Epoch 00157: val_auc improved from 0.74827 to 0.74892, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5776 - acc: 0.6976 - val_loss: 0.6052 - val_acc: 0.6767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5778 - acc: 0.6978 val_auc: 74.8911%\n",
      "Epoch 00158: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5777 - acc: 0.6979 - val_loss: 0.6040 - val_acc: 0.6777\n",
      "Epoch 159/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5767 - acc: 0.6999 val_auc: 74.9271%\n",
      "Epoch 00159: val_auc improved from 0.74892 to 0.74927, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5769 - acc: 0.6999 - val_loss: 0.6031 - val_acc: 0.6792\n",
      "Epoch 160/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5767 - acc: 0.6996 val_auc: 74.9006%\n",
      "Epoch 00160: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5767 - acc: 0.6997 - val_loss: 0.6042 - val_acc: 0.6775\n",
      "Epoch 161/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5768 - acc: 0.6985 val_auc: 74.8974%\n",
      "Epoch 00161: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5768 - acc: 0.6985 - val_loss: 0.6030 - val_acc: 0.6781\n",
      "Epoch 162/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5752 - acc: 0.7000 val_auc: 74.9192%\n",
      "Epoch 00162: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5754 - acc: 0.6999 - val_loss: 0.6038 - val_acc: 0.6782\n",
      "Epoch 163/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5757 - acc: 0.7000 val_auc: 74.9296%\n",
      "Epoch 00163: val_auc improved from 0.74927 to 0.74930, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5757 - acc: 0.6999 - val_loss: 0.6032 - val_acc: 0.6788\n",
      "Epoch 164/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5745 - acc: 0.7011 val_auc: 74.9632%\n",
      "Epoch 00164: val_auc improved from 0.74930 to 0.74963, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5746 - acc: 0.7012 - val_loss: 0.6033 - val_acc: 0.6787\n",
      "Epoch 165/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5744 - acc: 0.7012 val_auc: 74.9396%\n",
      "Epoch 00165: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5745 - acc: 0.7010 - val_loss: 0.6050 - val_acc: 0.6776\n",
      "Epoch 166/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5756 - acc: 0.6993 val_auc: 74.9579%\n",
      "Epoch 00166: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5757 - acc: 0.6992 - val_loss: 0.6043 - val_acc: 0.6781\n",
      "Epoch 167/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5745 - acc: 0.7018 val_auc: 74.9510%\n",
      "Epoch 00167: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5746 - acc: 0.7017 - val_loss: 0.6033 - val_acc: 0.6781\n",
      "Epoch 168/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5741 - acc: 0.7023 val_auc: 74.9882%\n",
      "Epoch 00168: val_auc improved from 0.74963 to 0.74988, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5741 - acc: 0.7021 - val_loss: 0.6033 - val_acc: 0.6785\n",
      "Epoch 169/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5740 - acc: 0.7013 val_auc: 75.0019%\n",
      "Epoch 00169: val_auc improved from 0.74988 to 0.75002, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5740 - acc: 0.7012 - val_loss: 0.6030 - val_acc: 0.6789\n",
      "Epoch 170/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5749 - acc: 0.7005 val_auc: 74.9901%\n",
      "Epoch 00170: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5747 - acc: 0.7005 - val_loss: 0.6025 - val_acc: 0.6796\n",
      "Epoch 171/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5727 - acc: 0.7021 val_auc: 75.0010%\n",
      "Epoch 00171: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5728 - acc: 0.7021 - val_loss: 0.6036 - val_acc: 0.6801\n",
      "Epoch 172/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5727 - acc: 0.7023 val_auc: 75.0347%\n",
      "Epoch 00172: val_auc improved from 0.75002 to 0.75035, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5723 - acc: 0.7025 - val_loss: 0.6026 - val_acc: 0.6805\n",
      "Epoch 173/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5729 - acc: 0.7027 val_auc: 75.0658%\n",
      "Epoch 00173: val_auc improved from 0.75035 to 0.75066, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5730 - acc: 0.7026 - val_loss: 0.6042 - val_acc: 0.6792\n",
      "Epoch 174/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5719 - acc: 0.7020 val_auc: 75.0610%\n",
      "Epoch 00174: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5720 - acc: 0.7020 - val_loss: 0.6039 - val_acc: 0.6794\n",
      "Epoch 175/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5724 - acc: 0.7018 val_auc: 75.1147%\n",
      "Epoch 00175: val_auc improved from 0.75066 to 0.75115, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5724 - acc: 0.7019 - val_loss: 0.6026 - val_acc: 0.6811\n",
      "Epoch 176/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5707 - acc: 0.7042 val_auc: 75.0490%\n",
      "Epoch 00176: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5707 - acc: 0.7042 - val_loss: 0.6038 - val_acc: 0.6801\n",
      "Epoch 177/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5714 - acc: 0.7023 val_auc: 75.0426%\n",
      "Epoch 00177: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5715 - acc: 0.7023 - val_loss: 0.6036 - val_acc: 0.6800\n",
      "Epoch 178/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5712 - acc: 0.7026 val_auc: 75.0900%\n",
      "Epoch 00178: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5712 - acc: 0.7026 - val_loss: 0.6033 - val_acc: 0.6802\n",
      "Epoch 179/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5699 - acc: 0.7060 val_auc: 75.1091%\n",
      "Epoch 00179: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5699 - acc: 0.7059 - val_loss: 0.6039 - val_acc: 0.6799\n",
      "Epoch 180/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5702 - acc: 0.7035 val_auc: 75.1275%\n",
      "Epoch 00180: val_auc improved from 0.75115 to 0.75127, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.5704 - acc: 0.7034 - val_loss: 0.6033 - val_acc: 0.6807\n",
      "Epoch 181/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5708 - acc: 0.7038 val_auc: 75.1294%\n",
      "Epoch 00181: val_auc improved from 0.75127 to 0.75129, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5707 - acc: 0.7040 - val_loss: 0.6027 - val_acc: 0.6810\n",
      "Epoch 182/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5701 - acc: 0.7050 val_auc: 75.1749%\n",
      "Epoch 00182: val_auc improved from 0.75129 to 0.75175, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5701 - acc: 0.7048 - val_loss: 0.6023 - val_acc: 0.6819\n",
      "Epoch 183/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5691 - acc: 0.7048 val_auc: 75.1481%\n",
      "Epoch 00183: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5691 - acc: 0.7050 - val_loss: 0.6033 - val_acc: 0.6811\n",
      "Epoch 184/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5685 - acc: 0.7074 val_auc: 75.1543%\n",
      "Epoch 00184: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5685 - acc: 0.7073 - val_loss: 0.6050 - val_acc: 0.6801\n",
      "Epoch 185/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5681 - acc: 0.7053 val_auc: 75.1880%\n",
      "Epoch 00185: val_auc improved from 0.75175 to 0.75188, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5680 - acc: 0.7053 - val_loss: 0.6048 - val_acc: 0.6797\n",
      "Epoch 186/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5675 - acc: 0.7069 val_auc: 75.1434%\n",
      "Epoch 00186: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.5675 - acc: 0.7069 - val_loss: 0.6057 - val_acc: 0.6792\n",
      "Epoch 187/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5670 - acc: 0.7070 val_auc: 75.1447%\n",
      "Epoch 00187: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5669 - acc: 0.7071 - val_loss: 0.6025 - val_acc: 0.6836\n",
      "Epoch 188/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5684 - acc: 0.7058 val_auc: 75.1648%\n",
      "Epoch 00188: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5684 - acc: 0.7056 - val_loss: 0.6031 - val_acc: 0.6825\n",
      "Epoch 189/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5677 - acc: 0.7070 val_auc: 75.2315%\n",
      "Epoch 00189: val_auc improved from 0.75188 to 0.75232, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5677 - acc: 0.7071 - val_loss: 0.6024 - val_acc: 0.6828\n",
      "Epoch 190/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5665 - acc: 0.7080 val_auc: 75.1777%\n",
      "Epoch 00190: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5663 - acc: 0.7081 - val_loss: 0.6044 - val_acc: 0.6808\n",
      "Epoch 191/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5670 - acc: 0.7061 val_auc: 75.2166%\n",
      "Epoch 00191: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5670 - acc: 0.7061 - val_loss: 0.6034 - val_acc: 0.6821\n",
      "Epoch 192/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5655 - acc: 0.7081 val_auc: 75.2345%\n",
      "Epoch 00192: val_auc improved from 0.75232 to 0.75234, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5656 - acc: 0.7078 - val_loss: 0.6028 - val_acc: 0.6832\n",
      "Epoch 193/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5661 - acc: 0.7083 val_auc: 75.2422%\n",
      "Epoch 00193: val_auc improved from 0.75234 to 0.75242, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5662 - acc: 0.7082 - val_loss: 0.6034 - val_acc: 0.6821\n",
      "Epoch 194/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5656 - acc: 0.7082 val_auc: 75.2777%\n",
      "Epoch 00194: val_auc improved from 0.75242 to 0.75278, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5657 - acc: 0.7082 - val_loss: 0.6026 - val_acc: 0.6833\n",
      "Epoch 195/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5662 - acc: 0.7067 val_auc: 75.2684%\n",
      "Epoch 00195: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5662 - acc: 0.7067 - val_loss: 0.6026 - val_acc: 0.6830\n",
      "Epoch 196/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5660 - acc: 0.7078 val_auc: 75.1963%\n",
      "Epoch 00196: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5659 - acc: 0.7079 - val_loss: 0.6025 - val_acc: 0.6832\n",
      "Epoch 197/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5644 - acc: 0.7094 val_auc: 75.2780%\n",
      "Epoch 00197: val_auc improved from 0.75278 to 0.75278, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5644 - acc: 0.7094 - val_loss: 0.6030 - val_acc: 0.6839\n",
      "Epoch 198/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5637 - acc: 0.7095 val_auc: 75.2418%\n",
      "Epoch 00198: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5639 - acc: 0.7094 - val_loss: 0.6039 - val_acc: 0.6831\n",
      "Epoch 199/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5636 - acc: 0.7093 val_auc: 75.2784%\n",
      "Epoch 00199: val_auc improved from 0.75278 to 0.75278, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5638 - acc: 0.7092 - val_loss: 0.6041 - val_acc: 0.6821\n",
      "Epoch 200/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5639 - acc: 0.7099 val_auc: 75.2799%\n",
      "Epoch 00200: val_auc improved from 0.75278 to 0.75280, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5639 - acc: 0.7099 - val_loss: 0.6029 - val_acc: 0.6838\n",
      "Epoch 201/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5627 - acc: 0.7113 val_auc: 75.2803%\n",
      "Epoch 00201: val_auc improved from 0.75280 to 0.75280, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5629 - acc: 0.7111 - val_loss: 0.6044 - val_acc: 0.6824\n",
      "Epoch 202/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5617 - acc: 0.7119 val_auc: 75.3350%\n",
      "Epoch 00202: val_auc improved from 0.75280 to 0.75335, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5617 - acc: 0.7121 - val_loss: 0.6034 - val_acc: 0.6836\n",
      "Epoch 203/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5635 - acc: 0.7105 val_auc: 75.3121%\n",
      "Epoch 00203: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5636 - acc: 0.7104 - val_loss: 0.6040 - val_acc: 0.6833\n",
      "Epoch 204/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5628 - acc: 0.7106 val_auc: 75.2998%\n",
      "Epoch 00204: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5628 - acc: 0.7107 - val_loss: 0.6038 - val_acc: 0.6837\n",
      "Epoch 205/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5628 - acc: 0.7108 val_auc: 75.3398%\n",
      "Epoch 00205: val_auc improved from 0.75335 to 0.75340, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5629 - acc: 0.7108 - val_loss: 0.6043 - val_acc: 0.6833\n",
      "Epoch 206/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5621 - acc: 0.7119 val_auc: 75.2993%\n",
      "Epoch 00206: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5621 - acc: 0.7118 - val_loss: 0.6025 - val_acc: 0.6843\n",
      "Epoch 207/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5623 - acc: 0.7114 val_auc: 75.2963%\n",
      "Epoch 00207: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5623 - acc: 0.7116 - val_loss: 0.6034 - val_acc: 0.6838\n",
      "Epoch 208/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5601 - acc: 0.7119 val_auc: 75.2615%\n",
      "Epoch 00208: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5601 - acc: 0.7121 - val_loss: 0.6046 - val_acc: 0.6844\n",
      "Epoch 209/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5603 - acc: 0.7129 val_auc: 75.2997%\n",
      "Epoch 00209: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5604 - acc: 0.7128 - val_loss: 0.6040 - val_acc: 0.6848\n",
      "Epoch 210/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5587 - acc: 0.7141 val_auc: 75.3198%\n",
      "Epoch 00210: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5588 - acc: 0.7141 - val_loss: 0.6056 - val_acc: 0.6840\n",
      "Epoch 211/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5594 - acc: 0.7129 val_auc: 75.3542%\n",
      "Epoch 00211: val_auc improved from 0.75340 to 0.75354, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5594 - acc: 0.7130 - val_loss: 0.6052 - val_acc: 0.6850\n",
      "Epoch 212/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5597 - acc: 0.7146 val_auc: 75.3430%\n",
      "Epoch 00212: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5598 - acc: 0.7145 - val_loss: 0.6046 - val_acc: 0.6855\n",
      "Epoch 213/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5597 - acc: 0.7127 val_auc: 75.3585%\n",
      "Epoch 00213: val_auc improved from 0.75354 to 0.75359, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5598 - acc: 0.7127 - val_loss: 0.6033 - val_acc: 0.6860\n",
      "Epoch 214/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5597 - acc: 0.7136 val_auc: 75.3831%\n",
      "Epoch 00214: val_auc improved from 0.75359 to 0.75383, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5599 - acc: 0.7135 - val_loss: 0.6044 - val_acc: 0.6848\n",
      "Epoch 215/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5594 - acc: 0.7147 val_auc: 75.3757%\n",
      "Epoch 00215: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5594 - acc: 0.7146 - val_loss: 0.6036 - val_acc: 0.6855\n",
      "Epoch 216/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5581 - acc: 0.7136 val_auc: 75.3501%\n",
      "Epoch 00216: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.5582 - acc: 0.7134 - val_loss: 0.6051 - val_acc: 0.6845\n",
      "Epoch 217/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5584 - acc: 0.7144 val_auc: 75.3787%\n",
      "Epoch 00217: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.5584 - acc: 0.7144 - val_loss: 0.6038 - val_acc: 0.6856\n",
      "Epoch 218/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5586 - acc: 0.7149 val_auc: 75.3600%\n",
      "Epoch 00218: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5587 - acc: 0.7148 - val_loss: 0.6051 - val_acc: 0.6851\n",
      "Epoch 219/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5570 - acc: 0.7154 val_auc: 75.4039%\n",
      "Epoch 00219: val_auc improved from 0.75383 to 0.75404, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5572 - acc: 0.7153 - val_loss: 0.6044 - val_acc: 0.6862\n",
      "Epoch 220/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5562 - acc: 0.7163 val_auc: 75.3810%\n",
      "Epoch 00220: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5560 - acc: 0.7164 - val_loss: 0.6045 - val_acc: 0.6865\n",
      "Epoch 221/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5561 - acc: 0.7165 val_auc: 75.4082%\n",
      "Epoch 00221: val_auc improved from 0.75404 to 0.75408, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5564 - acc: 0.7162 - val_loss: 0.6044 - val_acc: 0.6858\n",
      "Epoch 222/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5564 - acc: 0.7157 val_auc: 75.3408%\n",
      "Epoch 00222: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 606us/step - loss: 0.5565 - acc: 0.7156 - val_loss: 0.6043 - val_acc: 0.6867\n",
      "Epoch 223/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5564 - acc: 0.7155 val_auc: 75.5043%\n",
      "Epoch 00223: val_auc improved from 0.75408 to 0.75504, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 103s 598us/step - loss: 0.5562 - acc: 0.7157 - val_loss: 0.6045 - val_acc: 0.6865\n",
      "Epoch 224/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5542 - acc: 0.7177 val_auc: 75.4447%\n",
      "Epoch 00224: val_auc did not improve\n",
      "171945/171945 [==============================] - 105s 609us/step - loss: 0.5544 - acc: 0.7177 - val_loss: 0.6043 - val_acc: 0.6871\n",
      "Epoch 225/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5557 - acc: 0.7159 val_auc: 75.4606%\n",
      "Epoch 00225: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 598us/step - loss: 0.5557 - acc: 0.7159 - val_loss: 0.6051 - val_acc: 0.6862\n",
      "Epoch 226/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5558 - acc: 0.7161 val_auc: 75.4290%\n",
      "Epoch 00226: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 605us/step - loss: 0.5559 - acc: 0.7160 - val_loss: 0.6040 - val_acc: 0.6870\n",
      "Epoch 227/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5551 - acc: 0.7173 val_auc: 75.4707%\n",
      "Epoch 00227: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 603us/step - loss: 0.5551 - acc: 0.7174 - val_loss: 0.6049 - val_acc: 0.6867\n",
      "Epoch 228/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5553 - acc: 0.7174 val_auc: 75.4818%\n",
      "Epoch 00228: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 602us/step - loss: 0.5555 - acc: 0.7173 - val_loss: 0.6046 - val_acc: 0.6870\n",
      "Epoch 229/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5538 - acc: 0.7182 val_auc: 75.5148%\n",
      "Epoch 00229: val_auc improved from 0.75504 to 0.75515, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 103s 598us/step - loss: 0.5542 - acc: 0.7180 - val_loss: 0.6041 - val_acc: 0.6870\n",
      "Epoch 230/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5527 - acc: 0.7198 val_auc: 75.4820%\n",
      "Epoch 00230: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 600us/step - loss: 0.5528 - acc: 0.7198 - val_loss: 0.6049 - val_acc: 0.6870\n",
      "Epoch 231/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5532 - acc: 0.7189 val_auc: 75.5502%\n",
      "Epoch 00231: val_auc improved from 0.75515 to 0.75550, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 104s 602us/step - loss: 0.5532 - acc: 0.7190 - val_loss: 0.6032 - val_acc: 0.6881\n",
      "Epoch 232/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5544 - acc: 0.7176 val_auc: 75.5238%\n",
      "Epoch 00232: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 607us/step - loss: 0.5543 - acc: 0.7178 - val_loss: 0.6040 - val_acc: 0.6875\n",
      "Epoch 233/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5527 - acc: 0.7201 val_auc: 75.4868%\n",
      "Epoch 00233: val_auc did not improve\n",
      "171945/171945 [==============================] - 105s 609us/step - loss: 0.5526 - acc: 0.7200 - val_loss: 0.6035 - val_acc: 0.6879\n",
      "Epoch 234/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5531 - acc: 0.7188 val_auc: 75.4957%\n",
      "Epoch 00234: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 607us/step - loss: 0.5532 - acc: 0.7186 - val_loss: 0.6043 - val_acc: 0.6882\n",
      "Epoch 235/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5528 - acc: 0.7181 val_auc: 75.5095%\n",
      "Epoch 00235: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 607us/step - loss: 0.5527 - acc: 0.7182 - val_loss: 0.6045 - val_acc: 0.6886\n",
      "Epoch 236/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5515 - acc: 0.7192 val_auc: 75.4994%\n",
      "Epoch 00236: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 602us/step - loss: 0.5515 - acc: 0.7193 - val_loss: 0.6053 - val_acc: 0.6879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5509 - acc: 0.7203 val_auc: 75.5245%\n",
      "Epoch 00237: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 601us/step - loss: 0.5508 - acc: 0.7203 - val_loss: 0.6044 - val_acc: 0.6885\n",
      "Epoch 238/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5522 - acc: 0.7193 val_auc: 75.5341%\n",
      "Epoch 00238: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 600us/step - loss: 0.5520 - acc: 0.7195 - val_loss: 0.6038 - val_acc: 0.6890\n",
      "Epoch 239/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5512 - acc: 0.7206 val_auc: 75.5472%\n",
      "Epoch 00239: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 599us/step - loss: 0.5512 - acc: 0.7205 - val_loss: 0.6054 - val_acc: 0.6882\n",
      "Epoch 240/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5505 - acc: 0.7205 val_auc: 75.5370%\n",
      "Epoch 00240: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 608us/step - loss: 0.5506 - acc: 0.7204 - val_loss: 0.6037 - val_acc: 0.6879\n",
      "Epoch 241/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5506 - acc: 0.7201 val_auc: 75.5541%\n",
      "Epoch 00241: val_auc improved from 0.75550 to 0.75554, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 104s 604us/step - loss: 0.5506 - acc: 0.7201 - val_loss: 0.6047 - val_acc: 0.6877\n",
      "Epoch 242/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5490 - acc: 0.7217 val_auc: 75.5755%\n",
      "Epoch 00242: val_auc improved from 0.75554 to 0.75576, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 103s 598us/step - loss: 0.5490 - acc: 0.7216 - val_loss: 0.6056 - val_acc: 0.6879\n",
      "Epoch 243/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5506 - acc: 0.7208 val_auc: 75.6107%\n",
      "Epoch 00243: val_auc improved from 0.75576 to 0.75611, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 590us/step - loss: 0.5505 - acc: 0.7208 - val_loss: 0.6039 - val_acc: 0.6891\n",
      "Epoch 244/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5491 - acc: 0.7224 val_auc: 75.5596%\n",
      "Epoch 00244: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 591us/step - loss: 0.5493 - acc: 0.7222 - val_loss: 0.6061 - val_acc: 0.6867\n",
      "Epoch 245/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5491 - acc: 0.7212 val_auc: 75.6059%\n",
      "Epoch 00245: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 598us/step - loss: 0.5492 - acc: 0.7210 - val_loss: 0.6067 - val_acc: 0.6872\n",
      "Epoch 246/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5489 - acc: 0.7217 val_auc: 75.5596%\n",
      "Epoch 00246: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 598us/step - loss: 0.5489 - acc: 0.7218 - val_loss: 0.6063 - val_acc: 0.6874\n",
      "Epoch 247/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5494 - acc: 0.7210 val_auc: 75.6236%\n",
      "Epoch 00247: val_auc improved from 0.75611 to 0.75624, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 103s 597us/step - loss: 0.5493 - acc: 0.7210 - val_loss: 0.6048 - val_acc: 0.6885\n",
      "Epoch 248/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5486 - acc: 0.7219 val_auc: 75.5988%\n",
      "Epoch 00248: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 601us/step - loss: 0.5488 - acc: 0.7218 - val_loss: 0.6038 - val_acc: 0.6888\n",
      "Epoch 249/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5487 - acc: 0.7220 val_auc: 75.6175%\n",
      "Epoch 00249: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 604us/step - loss: 0.5487 - acc: 0.7221 - val_loss: 0.6037 - val_acc: 0.6887\n",
      "Epoch 250/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5473 - acc: 0.7233 val_auc: 75.5850%\n",
      "Epoch 00250: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 596us/step - loss: 0.5472 - acc: 0.7233 - val_loss: 0.6049 - val_acc: 0.6884\n",
      "Epoch 251/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5474 - acc: 0.7238 val_auc: 75.5706%\n",
      "Epoch 00251: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 594us/step - loss: 0.5474 - acc: 0.7239 - val_loss: 0.6056 - val_acc: 0.6880\n",
      "Epoch 252/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5468 - acc: 0.7231 val_auc: 75.6429%\n",
      "Epoch 00252: val_auc improved from 0.75624 to 0.75643, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 103s 597us/step - loss: 0.5467 - acc: 0.7231 - val_loss: 0.6058 - val_acc: 0.6883\n",
      "Epoch 253/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5465 - acc: 0.7236 val_auc: 75.5894%\n",
      "Epoch 00253: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 590us/step - loss: 0.5465 - acc: 0.7235 - val_loss: 0.6056 - val_acc: 0.6884\n",
      "Epoch 254/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5467 - acc: 0.7235 val_auc: 75.6205%\n",
      "Epoch 00254: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 597us/step - loss: 0.5467 - acc: 0.7234 - val_loss: 0.6061 - val_acc: 0.6878\n",
      "Epoch 255/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5461 - acc: 0.7244 val_auc: 75.6456%\n",
      "Epoch 00255: val_auc improved from 0.75643 to 0.75646, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 102s 595us/step - loss: 0.5461 - acc: 0.7245 - val_loss: 0.6064 - val_acc: 0.6878\n",
      "Epoch 256/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5450 - acc: 0.7247 val_auc: 75.6231%\n",
      "Epoch 00256: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 596us/step - loss: 0.5451 - acc: 0.7245 - val_loss: 0.6064 - val_acc: 0.6883\n",
      "Epoch 257/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5457 - acc: 0.7253 val_auc: 75.6520%\n",
      "Epoch 00257: val_auc improved from 0.75646 to 0.75652, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 103s 598us/step - loss: 0.5456 - acc: 0.7253 - val_loss: 0.6054 - val_acc: 0.6889\n",
      "Epoch 258/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5460 - acc: 0.7235 val_auc: 75.6759%\n",
      "Epoch 00258: val_auc improved from 0.75652 to 0.75676, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 103s 600us/step - loss: 0.5460 - acc: 0.7235 - val_loss: 0.6057 - val_acc: 0.6871\n",
      "Epoch 259/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5454 - acc: 0.7244 val_auc: 75.6545%\n",
      "Epoch 00259: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 602us/step - loss: 0.5454 - acc: 0.7244 - val_loss: 0.6056 - val_acc: 0.6885\n",
      "Epoch 260/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5452 - acc: 0.7243 val_auc: 75.7095%\n",
      "Epoch 00260: val_auc improved from 0.75676 to 0.75709, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 102s 596us/step - loss: 0.5451 - acc: 0.7244 - val_loss: 0.6058 - val_acc: 0.6880\n",
      "Epoch 261/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5456 - acc: 0.7233 val_auc: 75.6589%\n",
      "Epoch 00261: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 596us/step - loss: 0.5456 - acc: 0.7235 - val_loss: 0.6053 - val_acc: 0.6890\n",
      "Epoch 262/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5433 - acc: 0.7263 val_auc: 75.7089%\n",
      "Epoch 00262: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 598us/step - loss: 0.5435 - acc: 0.7261 - val_loss: 0.6056 - val_acc: 0.6893\n",
      "Epoch 263/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5439 - acc: 0.7258 val_auc: 75.7190%\n",
      "Epoch 00263: val_auc improved from 0.75709 to 0.75719, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 103s 597us/step - loss: 0.5439 - acc: 0.7258 - val_loss: 0.6057 - val_acc: 0.6891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 264/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5433 - acc: 0.7255 val_auc: 75.6890%\n",
      "Epoch 00264: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 601us/step - loss: 0.5432 - acc: 0.7256 - val_loss: 0.6052 - val_acc: 0.6893\n",
      "Epoch 265/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5430 - acc: 0.7257 val_auc: 75.7485%\n",
      "Epoch 00265: val_auc improved from 0.75719 to 0.75748, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 104s 602us/step - loss: 0.5431 - acc: 0.7257 - val_loss: 0.6056 - val_acc: 0.6890\n",
      "Epoch 266/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5428 - acc: 0.7267 val_auc: 75.7372%\n",
      "Epoch 00266: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 599us/step - loss: 0.5429 - acc: 0.7266 - val_loss: 0.6057 - val_acc: 0.6891\n",
      "Epoch 267/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5425 - acc: 0.7265 val_auc: 75.6900%\n",
      "Epoch 00267: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 595us/step - loss: 0.5425 - acc: 0.7265 - val_loss: 0.6056 - val_acc: 0.6887\n",
      "Epoch 268/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5429 - acc: 0.7266 val_auc: 75.7192%\n",
      "Epoch 00268: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 595us/step - loss: 0.5429 - acc: 0.7266 - val_loss: 0.6061 - val_acc: 0.6883\n",
      "Epoch 269/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5418 - acc: 0.7265 val_auc: 75.7463%\n",
      "Epoch 00269: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 603us/step - loss: 0.5417 - acc: 0.7265 - val_loss: 0.6063 - val_acc: 0.6892\n",
      "Epoch 270/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5412 - acc: 0.7280 val_auc: 75.7251%\n",
      "Epoch 00270: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 601us/step - loss: 0.5410 - acc: 0.7281 - val_loss: 0.6065 - val_acc: 0.6887\n",
      "Epoch 271/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5412 - acc: 0.7268 val_auc: 75.6853%\n",
      "Epoch 00271: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5412 - acc: 0.7268 - val_loss: 0.6067 - val_acc: 0.6887\n",
      "Epoch 272/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5400 - acc: 0.7287 val_auc: 75.7907%\n",
      "Epoch 00272: val_auc improved from 0.75748 to 0.75791, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 102s 594us/step - loss: 0.5401 - acc: 0.7286 - val_loss: 0.6064 - val_acc: 0.6889\n",
      "Epoch 273/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5407 - acc: 0.7270 val_auc: 75.7422%\n",
      "Epoch 00273: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.5409 - acc: 0.7269 - val_loss: 0.6052 - val_acc: 0.6894\n",
      "Epoch 274/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5398 - acc: 0.7290 val_auc: 75.8020%\n",
      "Epoch 00274: val_auc improved from 0.75791 to 0.75802, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.5399 - acc: 0.7291 - val_loss: 0.6059 - val_acc: 0.6891\n",
      "Epoch 275/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5397 - acc: 0.7288 val_auc: 75.6931%\n",
      "Epoch 00275: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 601us/step - loss: 0.5400 - acc: 0.7285 - val_loss: 0.6073 - val_acc: 0.6884\n",
      "Epoch 276/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5391 - acc: 0.7283 val_auc: 75.7188%\n",
      "Epoch 00276: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 590us/step - loss: 0.5393 - acc: 0.7282 - val_loss: 0.6069 - val_acc: 0.6882\n",
      "Epoch 277/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5387 - acc: 0.7303 val_auc: 75.8200%\n",
      "Epoch 00277: val_auc improved from 0.75802 to 0.75820, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5387 - acc: 0.7303 - val_loss: 0.6075 - val_acc: 0.6889\n",
      "Epoch 278/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5405 - acc: 0.7280 val_auc: 75.8022%\n",
      "Epoch 00278: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 593us/step - loss: 0.5405 - acc: 0.7280 - val_loss: 0.6060 - val_acc: 0.6899\n",
      "Epoch 279/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5377 - acc: 0.7297 val_auc: 75.8028%\n",
      "Epoch 00279: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.5378 - acc: 0.7297 - val_loss: 0.6063 - val_acc: 0.6890\n",
      "Epoch 280/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5384 - acc: 0.7295 val_auc: 75.8371%\n",
      "Epoch 00280: val_auc improved from 0.75820 to 0.75837, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.5383 - acc: 0.7296 - val_loss: 0.6057 - val_acc: 0.6896\n",
      "Epoch 281/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5379 - acc: 0.7301 val_auc: 75.7863%\n",
      "Epoch 00281: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.5378 - acc: 0.7302 - val_loss: 0.6062 - val_acc: 0.6897\n",
      "Epoch 282/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5381 - acc: 0.7293 val_auc: 75.7705%\n",
      "Epoch 00282: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5382 - acc: 0.7293 - val_loss: 0.6062 - val_acc: 0.6897\n",
      "Epoch 283/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5373 - acc: 0.7298 val_auc: 75.8102%\n",
      "Epoch 00283: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 590us/step - loss: 0.5373 - acc: 0.7297 - val_loss: 0.6064 - val_acc: 0.6896\n",
      "Epoch 284/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5357 - acc: 0.7322 val_auc: 75.7916%\n",
      "Epoch 00284: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 598us/step - loss: 0.5358 - acc: 0.7321 - val_loss: 0.6076 - val_acc: 0.6895\n",
      "Epoch 285/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5381 - acc: 0.7305 val_auc: 75.7638%\n",
      "Epoch 00285: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 593us/step - loss: 0.5381 - acc: 0.7305 - val_loss: 0.6062 - val_acc: 0.6895\n",
      "Epoch 286/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5367 - acc: 0.7311 val_auc: 75.8681%\n",
      "Epoch 00286: val_auc improved from 0.75837 to 0.75868, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 103s 599us/step - loss: 0.5368 - acc: 0.7310 - val_loss: 0.6067 - val_acc: 0.6904\n",
      "Epoch 287/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5356 - acc: 0.7313 val_auc: 75.8471%\n",
      "Epoch 00287: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 599us/step - loss: 0.5355 - acc: 0.7313 - val_loss: 0.6065 - val_acc: 0.6898\n",
      "Epoch 288/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5352 - acc: 0.7324 val_auc: 75.8467%\n",
      "Epoch 00288: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 590us/step - loss: 0.5355 - acc: 0.7321 - val_loss: 0.6078 - val_acc: 0.6897\n",
      "Epoch 289/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5358 - acc: 0.7304 val_auc: 75.8170%\n",
      "Epoch 00289: val_auc did not improve\n",
      "171945/171945 [==============================] - 105s 609us/step - loss: 0.5359 - acc: 0.7303 - val_loss: 0.6065 - val_acc: 0.6897\n",
      "Epoch 290/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5356 - acc: 0.7322 val_auc: 75.8526%\n",
      "Epoch 00290: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 594us/step - loss: 0.5358 - acc: 0.7321 - val_loss: 0.6070 - val_acc: 0.6899\n",
      "Epoch 291/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5339 - acc: 0.7326 val_auc: 75.8410%\n",
      "Epoch 00291: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 601us/step - loss: 0.5339 - acc: 0.7327 - val_loss: 0.6075 - val_acc: 0.6899\n",
      "Epoch 292/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5349 - acc: 0.7322 val_auc: 75.8444%\n",
      "Epoch 00292: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 592us/step - loss: 0.5348 - acc: 0.7322 - val_loss: 0.6075 - val_acc: 0.6904\n",
      "Epoch 293/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5338 - acc: 0.7330 val_auc: 75.8426%\n",
      "Epoch 00293: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 596us/step - loss: 0.5338 - acc: 0.7330 - val_loss: 0.6080 - val_acc: 0.6901\n",
      "Epoch 294/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5339 - acc: 0.7330 val_auc: 75.8415%\n",
      "Epoch 00294: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 595us/step - loss: 0.5340 - acc: 0.7328 - val_loss: 0.6082 - val_acc: 0.6897\n",
      "Epoch 295/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5322 - acc: 0.7342 val_auc: 75.8782%\n",
      "Epoch 00295: val_auc improved from 0.75868 to 0.75878, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 102s 594us/step - loss: 0.5321 - acc: 0.7342 - val_loss: 0.6068 - val_acc: 0.6903\n",
      "Epoch 296/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5340 - acc: 0.7319 val_auc: 75.8274%\n",
      "Epoch 00296: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 596us/step - loss: 0.5342 - acc: 0.7318 - val_loss: 0.6078 - val_acc: 0.6900\n",
      "Epoch 297/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5315 - acc: 0.7336 val_auc: 75.8043%\n",
      "Epoch 00297: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 599us/step - loss: 0.5317 - acc: 0.7335 - val_loss: 0.6082 - val_acc: 0.6896\n",
      "Epoch 298/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5334 - acc: 0.7337 val_auc: 75.9093%\n",
      "Epoch 00298: val_auc improved from 0.75878 to 0.75909, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 102s 593us/step - loss: 0.5335 - acc: 0.7337 - val_loss: 0.6091 - val_acc: 0.6897\n",
      "Epoch 299/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5316 - acc: 0.7352 val_auc: 75.7822%\n",
      "Epoch 00299: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 593us/step - loss: 0.5315 - acc: 0.7351 - val_loss: 0.6093 - val_acc: 0.6887\n",
      "Epoch 300/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5310 - acc: 0.7351 val_auc: 75.8997%\n",
      "Epoch 00300: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5310 - acc: 0.7351 - val_loss: 0.6075 - val_acc: 0.6914\n",
      "Epoch 301/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5319 - acc: 0.7342 val_auc: 75.8943%\n",
      "Epoch 00301: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5318 - acc: 0.7343 - val_loss: 0.6089 - val_acc: 0.6902\n",
      "Epoch 302/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5313 - acc: 0.7347 val_auc: 75.8581%\n",
      "Epoch 00302: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5314 - acc: 0.7346 - val_loss: 0.6101 - val_acc: 0.6893\n",
      "Epoch 303/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5308 - acc: 0.7346 val_auc: 75.8650%\n",
      "Epoch 00303: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5307 - acc: 0.7346 - val_loss: 0.6087 - val_acc: 0.6896\n",
      "Epoch 304/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5304 - acc: 0.7356 val_auc: 75.8881%\n",
      "Epoch 00304: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 591us/step - loss: 0.5304 - acc: 0.7356 - val_loss: 0.6092 - val_acc: 0.6902\n",
      "Epoch 305/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5307 - acc: 0.7362 val_auc: 75.7992%\n",
      "Epoch 00305: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.5308 - acc: 0.7360 - val_loss: 0.6088 - val_acc: 0.6894\n",
      "Epoch 306/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5310 - acc: 0.7344 val_auc: 75.8762%\n",
      "Epoch 00306: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 594us/step - loss: 0.5307 - acc: 0.7347 - val_loss: 0.6072 - val_acc: 0.6904\n",
      "Epoch 307/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5298 - acc: 0.7362 val_auc: 75.8556%\n",
      "Epoch 00307: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5296 - acc: 0.7365 - val_loss: 0.6107 - val_acc: 0.6889\n",
      "Epoch 308/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5299 - acc: 0.7369 val_auc: 75.8628%\n",
      "Epoch 00308: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5299 - acc: 0.7368 - val_loss: 0.6092 - val_acc: 0.6899\n",
      "Epoch 309/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5287 - acc: 0.7362 val_auc: 75.8979%\n",
      "Epoch 00309: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.5285 - acc: 0.7364 - val_loss: 0.6102 - val_acc: 0.6903\n",
      "Epoch 310/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5279 - acc: 0.7369 val_auc: 75.9765%\n",
      "Epoch 00310: val_auc improved from 0.75909 to 0.75977, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.5277 - acc: 0.7371 - val_loss: 0.6086 - val_acc: 0.6915\n",
      "Epoch 311/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5273 - acc: 0.7389 val_auc: 75.8545%\n",
      "Epoch 00311: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5276 - acc: 0.7387 - val_loss: 0.6087 - val_acc: 0.6900\n",
      "Epoch 312/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5285 - acc: 0.7381 val_auc: 75.8461%\n",
      "Epoch 00312: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5287 - acc: 0.7380 - val_loss: 0.6088 - val_acc: 0.6891\n",
      "Epoch 313/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5286 - acc: 0.7376 val_auc: 75.8684%\n",
      "Epoch 00313: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5286 - acc: 0.7375 - val_loss: 0.6089 - val_acc: 0.6896\n",
      "Epoch 314/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5268 - acc: 0.7390 val_auc: 75.9123%\n",
      "Epoch 00314: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5270 - acc: 0.7386 - val_loss: 0.6097 - val_acc: 0.6905\n",
      "Epoch 315/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5270 - acc: 0.7379 val_auc: 75.8806%\n",
      "Epoch 00315: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.5272 - acc: 0.7379 - val_loss: 0.6104 - val_acc: 0.6900\n",
      "Epoch 316/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5271 - acc: 0.7379 val_auc: 75.8742%\n",
      "Epoch 00316: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5272 - acc: 0.7378 - val_loss: 0.6092 - val_acc: 0.6899\n",
      "Epoch 317/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5262 - acc: 0.7389 val_auc: 75.8499%\n",
      "Epoch 00317: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5262 - acc: 0.7389 - val_loss: 0.6100 - val_acc: 0.6894\n",
      "Epoch 318/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5259 - acc: 0.7382 val_auc: 75.8803%\n",
      "Epoch 00318: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.5260 - acc: 0.7381 - val_loss: 0.6088 - val_acc: 0.6898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 319/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5263 - acc: 0.7392 val_auc: 75.8845%\n",
      "Epoch 00319: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5264 - acc: 0.7391 - val_loss: 0.6105 - val_acc: 0.6902\n",
      "Epoch 320/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5264 - acc: 0.7383 val_auc: 75.8387%\n",
      "Epoch 00320: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5264 - acc: 0.7383 - val_loss: 0.6103 - val_acc: 0.6900\n",
      "Epoch 321/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5245 - acc: 0.7394 val_auc: 75.8987%\n",
      "Epoch 00321: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5246 - acc: 0.7393 - val_loss: 0.6107 - val_acc: 0.6899\n",
      "Epoch 322/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5246 - acc: 0.7395 val_auc: 75.9056%\n",
      "Epoch 00322: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5247 - acc: 0.7395 - val_loss: 0.6116 - val_acc: 0.6895\n",
      "Epoch 323/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5245 - acc: 0.7398 val_auc: 75.9049%\n",
      "Epoch 00323: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5243 - acc: 0.7399 - val_loss: 0.6103 - val_acc: 0.6901\n",
      "Epoch 324/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5230 - acc: 0.7411 val_auc: 75.9086%\n",
      "Epoch 00324: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5232 - acc: 0.7410 - val_loss: 0.6113 - val_acc: 0.6901\n",
      "Epoch 325/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5246 - acc: 0.7399 val_auc: 75.8479%\n",
      "Epoch 00325: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 590us/step - loss: 0.5247 - acc: 0.7398 - val_loss: 0.6109 - val_acc: 0.6900\n",
      "Epoch 326/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5235 - acc: 0.7401 val_auc: 75.9096%\n",
      "Epoch 00326: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 602us/step - loss: 0.5234 - acc: 0.7402 - val_loss: 0.6110 - val_acc: 0.6899\n",
      "Epoch 327/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5233 - acc: 0.7403 val_auc: 75.9572%\n",
      "Epoch 00327: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 597us/step - loss: 0.5234 - acc: 0.7402 - val_loss: 0.6113 - val_acc: 0.6902\n",
      "Epoch 328/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5228 - acc: 0.7412 val_auc: 75.9377%\n",
      "Epoch 00328: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 593us/step - loss: 0.5227 - acc: 0.7413 - val_loss: 0.6109 - val_acc: 0.6899\n",
      "Epoch 329/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5228 - acc: 0.7410 val_auc: 75.9401%\n",
      "Epoch 00329: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5227 - acc: 0.7412 - val_loss: 0.6113 - val_acc: 0.6899\n",
      "Epoch 330/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5224 - acc: 0.7408 val_auc: 75.8775%\n",
      "Epoch 00330: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5225 - acc: 0.7408 - val_loss: 0.6109 - val_acc: 0.6903\n",
      "Epoch 331/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5210 - acc: 0.7418 val_auc: 75.9440%\n",
      "Epoch 00331: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5209 - acc: 0.7419 - val_loss: 0.6108 - val_acc: 0.6907\n",
      "Epoch 332/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5225 - acc: 0.7412 val_auc: 76.0001%\n",
      "Epoch 00332: val_auc improved from 0.75977 to 0.76000, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5223 - acc: 0.7414 - val_loss: 0.6093 - val_acc: 0.6911\n",
      "Epoch 333/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5214 - acc: 0.7416 val_auc: 75.9519%\n",
      "Epoch 00333: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 591us/step - loss: 0.5214 - acc: 0.7416 - val_loss: 0.6114 - val_acc: 0.6900\n",
      "Epoch 334/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5203 - acc: 0.7429 val_auc: 75.9713%\n",
      "Epoch 00334: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 587us/step - loss: 0.5202 - acc: 0.7429 - val_loss: 0.6121 - val_acc: 0.6895\n",
      "Epoch 335/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5205 - acc: 0.7426 val_auc: 75.9266%\n",
      "Epoch 00335: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5203 - acc: 0.7428 - val_loss: 0.6139 - val_acc: 0.6885\n",
      "Epoch 336/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5207 - acc: 0.7425 val_auc: 75.9838%\n",
      "Epoch 00336: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 589us/step - loss: 0.5208 - acc: 0.7425 - val_loss: 0.6113 - val_acc: 0.6902\n",
      "Epoch 337/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5193 - acc: 0.7441 val_auc: 75.9123%\n",
      "Epoch 00337: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5195 - acc: 0.7439 - val_loss: 0.6128 - val_acc: 0.6904\n",
      "Epoch 338/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5197 - acc: 0.7438 val_auc: 75.9899%\n",
      "Epoch 00338: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5198 - acc: 0.7438 - val_loss: 0.6134 - val_acc: 0.6900\n",
      "Epoch 339/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5204 - acc: 0.7415 val_auc: 75.9797%\n",
      "Epoch 00339: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5201 - acc: 0.7418 - val_loss: 0.6102 - val_acc: 0.6906\n",
      "Epoch 340/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5196 - acc: 0.7430 val_auc: 75.9270%\n",
      "Epoch 00340: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5196 - acc: 0.7430 - val_loss: 0.6130 - val_acc: 0.6905\n",
      "Epoch 341/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5196 - acc: 0.7444 val_auc: 75.9186%\n",
      "Epoch 00341: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5198 - acc: 0.7443 - val_loss: 0.6135 - val_acc: 0.6893\n",
      "Epoch 342/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5183 - acc: 0.7435 val_auc: 75.9950%\n",
      "Epoch 00342: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5183 - acc: 0.7434 - val_loss: 0.6139 - val_acc: 0.6898\n",
      "Epoch 343/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5175 - acc: 0.7452 val_auc: 75.9733%\n",
      "Epoch 00343: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5176 - acc: 0.7451 - val_loss: 0.6124 - val_acc: 0.6899\n",
      "Epoch 344/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5175 - acc: 0.7450 val_auc: 75.9342%\n",
      "Epoch 00344: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5174 - acc: 0.7450 - val_loss: 0.6129 - val_acc: 0.6906\n",
      "Epoch 345/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5182 - acc: 0.7445 val_auc: 75.9770%\n",
      "Epoch 00345: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.5183 - acc: 0.7445 - val_loss: 0.6133 - val_acc: 0.6895\n",
      "Epoch 346/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5168 - acc: 0.7451 val_auc: 75.9932%\n",
      "Epoch 00346: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 599us/step - loss: 0.5166 - acc: 0.7453 - val_loss: 0.6133 - val_acc: 0.6904\n",
      "Epoch 347/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5155 - acc: 0.7468 val_auc: 75.9572%\n",
      "Epoch 00347: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 598us/step - loss: 0.5157 - acc: 0.7466 - val_loss: 0.6128 - val_acc: 0.6904\n",
      "Epoch 348/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5165 - acc: 0.7455 val_auc: 75.9772%\n",
      "Epoch 00348: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 596us/step - loss: 0.5165 - acc: 0.7456 - val_loss: 0.6136 - val_acc: 0.6902\n",
      "Epoch 349/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5170 - acc: 0.7451 val_auc: 75.9722%\n",
      "Epoch 00349: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 599us/step - loss: 0.5170 - acc: 0.7451 - val_loss: 0.6149 - val_acc: 0.6900\n",
      "Epoch 350/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5159 - acc: 0.7462 val_auc: 75.9367%\n",
      "Epoch 00350: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 593us/step - loss: 0.5158 - acc: 0.7462 - val_loss: 0.6124 - val_acc: 0.6911\n",
      "Epoch 351/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5160 - acc: 0.7461 val_auc: 75.9246%\n",
      "Epoch 00351: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 597us/step - loss: 0.5161 - acc: 0.7461 - val_loss: 0.6143 - val_acc: 0.6896\n",
      "Epoch 352/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5161 - acc: 0.7453 val_auc: 75.9340%\n",
      "Epoch 00352: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 599us/step - loss: 0.5161 - acc: 0.7453 - val_loss: 0.6150 - val_acc: 0.6892\n",
      "Epoch 353/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5144 - acc: 0.7463 val_auc: 75.9555%\n",
      "Epoch 00353: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 598us/step - loss: 0.5143 - acc: 0.7464 - val_loss: 0.6131 - val_acc: 0.6902\n",
      "Epoch 354/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5149 - acc: 0.7452 val_auc: 75.9485%\n",
      "Epoch 00354: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 604us/step - loss: 0.5148 - acc: 0.7453 - val_loss: 0.6162 - val_acc: 0.6887\n",
      "Epoch 355/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5141 - acc: 0.7470 val_auc: 75.9529%\n",
      "Epoch 00355: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 601us/step - loss: 0.5139 - acc: 0.7471 - val_loss: 0.6157 - val_acc: 0.6893\n",
      "Epoch 356/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5129 - acc: 0.7474 val_auc: 75.9801%\n",
      "Epoch 00356: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 604us/step - loss: 0.5129 - acc: 0.7474 - val_loss: 0.6138 - val_acc: 0.6906\n",
      "Epoch 357/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5140 - acc: 0.7465 val_auc: 76.0812%\n",
      "Epoch 00357: val_auc improved from 0.76000 to 0.76081, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 104s 603us/step - loss: 0.5140 - acc: 0.7465 - val_loss: 0.6131 - val_acc: 0.6916\n",
      "Epoch 358/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5130 - acc: 0.7486 val_auc: 76.0229%\n",
      "Epoch 00358: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 605us/step - loss: 0.5131 - acc: 0.7485 - val_loss: 0.6149 - val_acc: 0.6904\n",
      "Epoch 359/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5122 - acc: 0.7477 val_auc: 75.9999%\n",
      "Epoch 00359: val_auc did not improve\n",
      "171945/171945 [==============================] - 103s 600us/step - loss: 0.5123 - acc: 0.7476 - val_loss: 0.6153 - val_acc: 0.6900\n",
      "Epoch 360/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5134 - acc: 0.7460 val_auc: 76.0075%\n",
      "Epoch 00360: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 596us/step - loss: 0.5134 - acc: 0.7461 - val_loss: 0.6161 - val_acc: 0.6904\n",
      "Epoch 361/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5122 - acc: 0.7485 val_auc: 75.9954%\n",
      "Epoch 00361: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 592us/step - loss: 0.5120 - acc: 0.7486 - val_loss: 0.6156 - val_acc: 0.6897\n",
      "Epoch 362/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5113 - acc: 0.7492 val_auc: 76.0540%\n",
      "Epoch 00362: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 595us/step - loss: 0.5115 - acc: 0.7491 - val_loss: 0.6162 - val_acc: 0.6914\n",
      "Epoch 363/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5111 - acc: 0.7496 val_auc: 76.0196%\n",
      "Epoch 00363: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 588us/step - loss: 0.5110 - acc: 0.7497 - val_loss: 0.6174 - val_acc: 0.6905\n",
      "Epoch 364/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5113 - acc: 0.7484 val_auc: 76.0329%\n",
      "Epoch 00364: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 596us/step - loss: 0.5113 - acc: 0.7484 - val_loss: 0.6170 - val_acc: 0.6903\n",
      "Epoch 365/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5115 - acc: 0.7484 val_auc: 75.9979%\n",
      "Epoch 00365: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 596us/step - loss: 0.5116 - acc: 0.7483 - val_loss: 0.6180 - val_acc: 0.6892\n",
      "Epoch 366/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5100 - acc: 0.7489 val_auc: 76.0162%\n",
      "Epoch 00366: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 595us/step - loss: 0.5100 - acc: 0.7489 - val_loss: 0.6148 - val_acc: 0.6917\n",
      "Epoch 367/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5116 - acc: 0.7477 val_auc: 76.0201%\n",
      "Epoch 00367: val_auc did not improve\n",
      "171945/171945 [==============================] - 104s 606us/step - loss: 0.5114 - acc: 0.7480 - val_loss: 0.6168 - val_acc: 0.6904\n",
      "Epoch 368/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5107 - acc: 0.7497 val_auc: 76.0043%\n",
      "Epoch 00368: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 593us/step - loss: 0.5106 - acc: 0.7498 - val_loss: 0.6176 - val_acc: 0.6904\n",
      "Epoch 369/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5106 - acc: 0.7499 val_auc: 75.9727%\n",
      "Epoch 00369: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 593us/step - loss: 0.5106 - acc: 0.7498 - val_loss: 0.6169 - val_acc: 0.6909\n",
      "Epoch 370/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5090 - acc: 0.7511 val_auc: 75.9753%\n",
      "Epoch 00370: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 593us/step - loss: 0.5094 - acc: 0.7508 - val_loss: 0.6164 - val_acc: 0.6899\n",
      "Epoch 371/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5093 - acc: 0.7503 val_auc: 76.0499%\n",
      "Epoch 00371: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 591us/step - loss: 0.5092 - acc: 0.7503 - val_loss: 0.6162 - val_acc: 0.6910\n",
      "Epoch 372/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5093 - acc: 0.7501 val_auc: 75.9826%\n",
      "Epoch 00372: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 592us/step - loss: 0.5094 - acc: 0.7500 - val_loss: 0.6183 - val_acc: 0.6906\n",
      "Epoch 373/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5078 - acc: 0.7519 val_auc: 75.9591%\n",
      "Epoch 00373: val_auc did not improve\n",
      "171945/171945 [==============================] - 102s 593us/step - loss: 0.5077 - acc: 0.7520 - val_loss: 0.6193 - val_acc: 0.6890\n",
      "Epoch 374/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5076 - acc: 0.7522 val_auc: 75.9549%\n",
      "Epoch 00374: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5075 - acc: 0.7522 - val_loss: 0.6178 - val_acc: 0.6892\n",
      "Epoch 375/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5080 - acc: 0.7505 val_auc: 76.0225%\n",
      "Epoch 00375: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5081 - acc: 0.7506 - val_loss: 0.6180 - val_acc: 0.6898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5080 - acc: 0.7508 val_auc: 76.0356%\n",
      "Epoch 00376: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5080 - acc: 0.7508 - val_loss: 0.6159 - val_acc: 0.6909\n",
      "Epoch 377/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5093 - acc: 0.7508 val_auc: 76.0851%\n",
      "Epoch 00377: val_auc improved from 0.76081 to 0.76085, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5093 - acc: 0.7508 - val_loss: 0.6156 - val_acc: 0.6913\n",
      "Epoch 378/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5069 - acc: 0.7513 val_auc: 75.9743%\n",
      "Epoch 00378: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5069 - acc: 0.7513 - val_loss: 0.6178 - val_acc: 0.6902\n",
      "Epoch 379/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5066 - acc: 0.7515 val_auc: 76.0054%\n",
      "Epoch 00379: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5067 - acc: 0.7514 - val_loss: 0.6179 - val_acc: 0.6906\n",
      "Epoch 380/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5066 - acc: 0.7523 val_auc: 75.9973%\n",
      "Epoch 00380: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5066 - acc: 0.7522 - val_loss: 0.6185 - val_acc: 0.6904\n",
      "Epoch 381/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5062 - acc: 0.7527 val_auc: 75.9941%\n",
      "Epoch 00381: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5064 - acc: 0.7525 - val_loss: 0.6184 - val_acc: 0.6906\n",
      "Epoch 382/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5053 - acc: 0.7524 val_auc: 76.0011%\n",
      "Epoch 00382: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5055 - acc: 0.7522 - val_loss: 0.6188 - val_acc: 0.6894\n",
      "Epoch 383/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5059 - acc: 0.7526 val_auc: 76.0501%\n",
      "Epoch 00383: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 586us/step - loss: 0.5056 - acc: 0.7529 - val_loss: 0.6181 - val_acc: 0.6896\n",
      "Epoch 384/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5048 - acc: 0.7533 val_auc: 75.9907%\n",
      "Epoch 00384: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5050 - acc: 0.7531 - val_loss: 0.6190 - val_acc: 0.6897\n",
      "Epoch 385/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5042 - acc: 0.7543 val_auc: 75.9544%\n",
      "Epoch 00385: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5043 - acc: 0.7542 - val_loss: 0.6199 - val_acc: 0.6897\n",
      "Epoch 386/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5053 - acc: 0.7529 val_auc: 75.9477%\n",
      "Epoch 00386: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5055 - acc: 0.7527 - val_loss: 0.6175 - val_acc: 0.6905\n",
      "Epoch 387/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5038 - acc: 0.7543 val_auc: 75.9507%\n",
      "Epoch 00387: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5038 - acc: 0.7543 - val_loss: 0.6183 - val_acc: 0.6907\n",
      "Epoch 388/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5049 - acc: 0.7520 val_auc: 76.0094%\n",
      "Epoch 00388: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5049 - acc: 0.7522 - val_loss: 0.6189 - val_acc: 0.6897\n",
      "Epoch 389/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5028 - acc: 0.7541 val_auc: 76.0078%\n",
      "Epoch 00389: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5026 - acc: 0.7543 - val_loss: 0.6197 - val_acc: 0.6905\n",
      "Epoch 390/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5027 - acc: 0.7537 val_auc: 76.0157%\n",
      "Epoch 00390: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5028 - acc: 0.7538 - val_loss: 0.6189 - val_acc: 0.6909\n",
      "Epoch 391/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5028 - acc: 0.7550 val_auc: 76.0470%\n",
      "Epoch 00391: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5030 - acc: 0.7548 - val_loss: 0.6211 - val_acc: 0.6890\n",
      "Epoch 392/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5023 - acc: 0.7558 val_auc: 76.0598%\n",
      "Epoch 00392: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5023 - acc: 0.7557 - val_loss: 0.6202 - val_acc: 0.6906\n",
      "Epoch 393/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5034 - acc: 0.7548 val_auc: 75.9957%\n",
      "Epoch 00393: val_auc did not improve\n",
      "171945/171945 [==============================] - 101s 585us/step - loss: 0.5034 - acc: 0.7547 - val_loss: 0.6181 - val_acc: 0.6907\n",
      "Epoch 394/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5034 - acc: 0.7533 val_auc: 76.0094%\n",
      "Epoch 00394: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5034 - acc: 0.7533 - val_loss: 0.6173 - val_acc: 0.6900\n",
      "Epoch 395/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5014 - acc: 0.7552 val_auc: 76.0557%\n",
      "Epoch 00395: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.5015 - acc: 0.7551 - val_loss: 0.6199 - val_acc: 0.6902\n",
      "Epoch 396/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5034 - acc: 0.7531 val_auc: 76.0396%\n",
      "Epoch 00396: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 583us/step - loss: 0.5036 - acc: 0.7529 - val_loss: 0.6199 - val_acc: 0.6898\n",
      "Epoch 397/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5011 - acc: 0.7558 val_auc: 75.9963%\n",
      "Epoch 00397: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.5012 - acc: 0.7558 - val_loss: 0.6196 - val_acc: 0.6902\n",
      "Epoch 398/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5000 - acc: 0.7560 val_auc: 75.9805%\n",
      "Epoch 00398: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.5002 - acc: 0.7559 - val_loss: 0.6217 - val_acc: 0.6896\n",
      "Epoch 399/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5007 - acc: 0.7555 val_auc: 75.9957%\n",
      "Epoch 00399: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.5008 - acc: 0.7555 - val_loss: 0.6211 - val_acc: 0.6901\n",
      "Epoch 400/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4994 - acc: 0.7577 val_auc: 76.0648%\n",
      "Epoch 00400: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.4992 - acc: 0.7578 - val_loss: 0.6217 - val_acc: 0.6907\n",
      "Epoch 401/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5002 - acc: 0.7565 val_auc: 75.9581%\n",
      "Epoch 00401: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.5002 - acc: 0.7566 - val_loss: 0.6210 - val_acc: 0.6895\n",
      "Epoch 402/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5002 - acc: 0.7561 val_auc: 75.9855%\n",
      "Epoch 00402: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.5002 - acc: 0.7561 - val_loss: 0.6194 - val_acc: 0.6900\n",
      "Epoch 403/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5003 - acc: 0.7561 val_auc: 76.0140%\n",
      "Epoch 00403: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.5006 - acc: 0.7559 - val_loss: 0.6195 - val_acc: 0.6900\n",
      "Epoch 404/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5004 - acc: 0.7555 val_auc: 75.9840%\n",
      "Epoch 00404: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.5005 - acc: 0.7555 - val_loss: 0.6212 - val_acc: 0.6894\n",
      "Epoch 405/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4996 - acc: 0.7561 val_auc: 75.9585%\n",
      "Epoch 00405: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.4994 - acc: 0.7563 - val_loss: 0.6211 - val_acc: 0.6902\n",
      "Epoch 406/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5008 - acc: 0.7557 val_auc: 76.0195%\n",
      "Epoch 00406: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.5009 - acc: 0.7556 - val_loss: 0.6219 - val_acc: 0.6896\n",
      "Epoch 407/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4979 - acc: 0.7585 val_auc: 75.9626%\n",
      "Epoch 00407: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.4980 - acc: 0.7586 - val_loss: 0.6226 - val_acc: 0.6899\n",
      "Epoch 408/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4997 - acc: 0.7558 val_auc: 76.0005%\n",
      "Epoch 00408: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.4996 - acc: 0.7560 - val_loss: 0.6215 - val_acc: 0.6904\n",
      "Epoch 409/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4966 - acc: 0.7590 val_auc: 76.0289%\n",
      "Epoch 00409: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.4970 - acc: 0.7588 - val_loss: 0.6220 - val_acc: 0.6906\n",
      "Epoch 410/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4974 - acc: 0.7575 val_auc: 75.9364%\n",
      "Epoch 00410: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.4976 - acc: 0.7575 - val_loss: 0.6217 - val_acc: 0.6900\n",
      "Epoch 411/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4964 - acc: 0.7590 val_auc: 75.9456%\n",
      "Epoch 00411: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.4965 - acc: 0.7591 - val_loss: 0.6231 - val_acc: 0.6896\n",
      "Epoch 412/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4979 - acc: 0.7577 val_auc: 75.9799%\n",
      "Epoch 00412: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.4978 - acc: 0.7577 - val_loss: 0.6224 - val_acc: 0.6894\n",
      "Epoch 413/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4972 - acc: 0.7580 val_auc: 75.9593%\n",
      "Epoch 00413: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.4970 - acc: 0.7582 - val_loss: 0.6214 - val_acc: 0.6902\n",
      "Epoch 414/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4952 - acc: 0.7593 val_auc: 75.9699%\n",
      "Epoch 00414: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.4953 - acc: 0.7593 - val_loss: 0.6224 - val_acc: 0.6903\n",
      "Epoch 415/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4950 - acc: 0.7596 val_auc: 76.0033%\n",
      "Epoch 00415: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.4949 - acc: 0.7596 - val_loss: 0.6239 - val_acc: 0.6893\n",
      "Epoch 416/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4956 - acc: 0.7596 val_auc: 76.0280%\n",
      "Epoch 00416: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 584us/step - loss: 0.4955 - acc: 0.7596 - val_loss: 0.6235 - val_acc: 0.6896\n",
      "Epoch 417/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4948 - acc: 0.7599 val_auc: 75.9710%\n",
      "Epoch 00417: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.4950 - acc: 0.7597 - val_loss: 0.6230 - val_acc: 0.6901\n",
      "Epoch 418/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4949 - acc: 0.7599 val_auc: 76.0143%\n",
      "Epoch 00418: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.4950 - acc: 0.7598 - val_loss: 0.6225 - val_acc: 0.6907\n",
      "Epoch 419/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4967 - acc: 0.7579 val_auc: 76.0291%\n",
      "Epoch 00419: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.4965 - acc: 0.7580 - val_loss: 0.6234 - val_acc: 0.6897\n",
      "Epoch 420/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4951 - acc: 0.7608 val_auc: 76.0479%\n",
      "Epoch 00420: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.4948 - acc: 0.7610 - val_loss: 0.6230 - val_acc: 0.6903\n",
      "Epoch 421/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4941 - acc: 0.7601 val_auc: 76.0152%\n",
      "Epoch 00421: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 580us/step - loss: 0.4943 - acc: 0.7598 - val_loss: 0.6225 - val_acc: 0.6902\n",
      "Epoch 422/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4937 - acc: 0.7604 val_auc: 75.9833%\n",
      "Epoch 00422: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.4937 - acc: 0.7604 - val_loss: 0.6236 - val_acc: 0.6899\n",
      "Epoch 423/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4954 - acc: 0.7595 val_auc: 75.9960%\n",
      "Epoch 00423: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.4952 - acc: 0.7595 - val_loss: 0.6224 - val_acc: 0.6901\n",
      "Epoch 424/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4932 - acc: 0.7605 val_auc: 75.9782%\n",
      "Epoch 00424: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.4932 - acc: 0.7604 - val_loss: 0.6238 - val_acc: 0.6894\n",
      "Epoch 425/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4924 - acc: 0.7621 val_auc: 75.9500%\n",
      "Epoch 00425: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 582us/step - loss: 0.4925 - acc: 0.7619 - val_loss: 0.6263 - val_acc: 0.6885\n",
      "Epoch 426/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4927 - acc: 0.7608 val_auc: 75.9997%\n",
      "Epoch 00426: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.4928 - acc: 0.7607 - val_loss: 0.6247 - val_acc: 0.6895\n",
      "Epoch 427/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.4921 - acc: 0.7622 val_auc: 75.9807%\n",
      "Epoch 00427: val_auc did not improve\n",
      "171945/171945 [==============================] - 100s 581us/step - loss: 0.4921 - acc: 0.7622 - val_loss: 0.6250 - val_acc: 0.6902\n",
      "Epoch 00427: early stopping\n"
     ]
    }
   ],
   "source": [
    "#now train\n",
    "#decrease learning rate from default of 0.001\n",
    "#increase patience to compensae to 50 from 25\n",
    "#and remove calculation of training auc to speed up\n",
    "history50_trained = nn.run_model(model=model50_trained,out_path=\"models/nn_50d_trained.hdf5\",\n",
    "                                 optimizer=Adam(lr=0.00025), patience=50, train_auc=False, **run_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/interim/nn50_trained_history.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save history\n",
    "joblib.dump(history50_trained.history, \"data/interim/nn50_trained_history.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5 - Train 300d model with trainable embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "joke_seq (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 300)          8218800   \n",
      "_________________________________________________________________\n",
      "mask_paddings (Masking)      (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "drop_words (SpatialDropout1D (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "mask_dropped_words (Masking) (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "reccurrent_layer (LSTM)      (None, 150)               270600    \n",
      "_________________________________________________________________\n",
      "drop_dense (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_sigmoid (Dense)        (None, 75)                11325     \n",
      "_________________________________________________________________\n",
      "avg_pred (GlobalAverage)     (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,500,725\n",
      "Trainable params: 8,500,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "model300_trained = nn.create_model(embedding_matrix=embedding_matrix300, n_hidden=150, train_embed=True)\n",
    "model300_trained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load in weights\n",
    "model300_trained.load_weights('models/nn_300d_fixed.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171945 samples, validate on 24564 samples\n",
      "Epoch 1/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6812 - acc: 0.5655 val_auc: 64.5726%\n",
      "Epoch 00001: val_auc improved from -inf to 0.64573, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 197s 1ms/step - loss: 0.6811 - acc: 0.5658 - val_loss: 0.6634 - val_acc: 0.5984\n",
      "Epoch 2/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6629 - acc: 0.5978 val_auc: 65.8839%\n",
      "Epoch 00002: val_auc improved from 0.64573 to 0.65884, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.6627 - acc: 0.5980 - val_loss: 0.6555 - val_acc: 0.6136\n",
      "Epoch 3/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6575 - acc: 0.6047 val_auc: 66.5378%\n",
      "Epoch 00003: val_auc improved from 0.65884 to 0.66538, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6575 - acc: 0.6048 - val_loss: 0.6517 - val_acc: 0.6174\n",
      "Epoch 4/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6545 - acc: 0.6097 val_auc: 67.1141%\n",
      "Epoch 00004: val_auc improved from 0.66538 to 0.67114, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.6544 - acc: 0.6099 - val_loss: 0.6486 - val_acc: 0.6222\n",
      "Epoch 5/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6526 - acc: 0.6123 val_auc: 67.6508%\n",
      "Epoch 00005: val_auc improved from 0.67114 to 0.67651, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.6525 - acc: 0.6125 - val_loss: 0.6461 - val_acc: 0.6269\n",
      "Epoch 6/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6498 - acc: 0.6186 val_auc: 67.8881%\n",
      "Epoch 00006: val_auc improved from 0.67651 to 0.67888, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6497 - acc: 0.6187 - val_loss: 0.6446 - val_acc: 0.6288\n",
      "Epoch 7/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6480 - acc: 0.6211 val_auc: 68.2731%\n",
      "Epoch 00007: val_auc improved from 0.67888 to 0.68273, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6481 - acc: 0.6210 - val_loss: 0.6422 - val_acc: 0.6325\n",
      "Epoch 8/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6465 - acc: 0.6248 val_auc: 68.5803%\n",
      "Epoch 00008: val_auc improved from 0.68273 to 0.68580, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6466 - acc: 0.6247 - val_loss: 0.6408 - val_acc: 0.6373\n",
      "Epoch 9/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6446 - acc: 0.6262 val_auc: 68.9153%\n",
      "Epoch 00009: val_auc improved from 0.68580 to 0.68915, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.6446 - acc: 0.6262 - val_loss: 0.6392 - val_acc: 0.6401\n",
      "Epoch 10/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6427 - acc: 0.6307 val_auc: 69.3397%\n",
      "Epoch 00010: val_auc improved from 0.68915 to 0.69340, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.6427 - acc: 0.6307 - val_loss: 0.6355 - val_acc: 0.6427\n",
      "Epoch 11/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6407 - acc: 0.6334 val_auc: 69.2828%\n",
      "Epoch 00011: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 665us/step - loss: 0.6406 - acc: 0.6334 - val_loss: 0.6371 - val_acc: 0.6430\n",
      "Epoch 12/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6399 - acc: 0.6344 val_auc: 69.7462%\n",
      "Epoch 00012: val_auc improved from 0.69340 to 0.69746, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6398 - acc: 0.6344 - val_loss: 0.6328 - val_acc: 0.6475\n",
      "Epoch 13/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6382 - acc: 0.6366 val_auc: 69.7689%\n",
      "Epoch 00013: val_auc improved from 0.69746 to 0.69769, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.6381 - acc: 0.6367 - val_loss: 0.6332 - val_acc: 0.6470\n",
      "Epoch 14/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6355 - acc: 0.6411 val_auc: 69.8982%\n",
      "Epoch 00014: val_auc improved from 0.69769 to 0.69898, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6356 - acc: 0.6411 - val_loss: 0.6327 - val_acc: 0.6474\n",
      "Epoch 15/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6343 - acc: 0.6429 val_auc: 70.1565%\n",
      "Epoch 00015: val_auc improved from 0.69898 to 0.70157, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.6342 - acc: 0.6430 - val_loss: 0.6306 - val_acc: 0.6479\n",
      "Epoch 16/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6325 - acc: 0.6448 val_auc: 70.2991%\n",
      "Epoch 00016: val_auc improved from 0.70157 to 0.70299, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.6325 - acc: 0.6449 - val_loss: 0.6304 - val_acc: 0.6494\n",
      "Epoch 17/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6313 - acc: 0.6455 val_auc: 70.4616%\n",
      "Epoch 00017: val_auc improved from 0.70299 to 0.70462, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6313 - acc: 0.6455 - val_loss: 0.6294 - val_acc: 0.6509\n",
      "Epoch 18/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6294 - acc: 0.6483 val_auc: 70.7079%\n",
      "Epoch 00018: val_auc improved from 0.70462 to 0.70708, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.6292 - acc: 0.6486 - val_loss: 0.6278 - val_acc: 0.6535\n",
      "Epoch 19/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6276 - acc: 0.6510 val_auc: 70.9607%\n",
      "Epoch 00019: val_auc improved from 0.70708 to 0.70961, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6275 - acc: 0.6510 - val_loss: 0.6262 - val_acc: 0.6548\n",
      "Epoch 20/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6249 - acc: 0.6549 val_auc: 71.2465%\n",
      "Epoch 00020: val_auc improved from 0.70961 to 0.71247, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.6250 - acc: 0.6548 - val_loss: 0.6258 - val_acc: 0.6584\n",
      "Epoch 21/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6241 - acc: 0.6556 val_auc: 71.2895%\n",
      "Epoch 00021: val_auc improved from 0.71247 to 0.71290, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6241 - acc: 0.6554 - val_loss: 0.6234 - val_acc: 0.6586\n",
      "Epoch 22/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6230 - acc: 0.6559 val_auc: 71.4651%\n",
      "Epoch 00022: val_auc improved from 0.71290 to 0.71465, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6231 - acc: 0.6559 - val_loss: 0.6233 - val_acc: 0.6601\n",
      "Epoch 23/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6208 - acc: 0.6586 val_auc: 71.6212%\n",
      "Epoch 00023: val_auc improved from 0.71465 to 0.71621, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6208 - acc: 0.6585 - val_loss: 0.6231 - val_acc: 0.6606\n",
      "Epoch 24/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6198 - acc: 0.6607 val_auc: 71.7877%\n",
      "Epoch 00024: val_auc improved from 0.71621 to 0.71788, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6198 - acc: 0.6608 - val_loss: 0.6221 - val_acc: 0.6622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6190 - acc: 0.6602 val_auc: 71.6608%\n",
      "Epoch 00025: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.6190 - acc: 0.6603 - val_loss: 0.6229 - val_acc: 0.6600\n",
      "Epoch 26/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6164 - acc: 0.6633 val_auc: 71.8314%\n",
      "Epoch 00026: val_auc improved from 0.71788 to 0.71831, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6162 - acc: 0.6636 - val_loss: 0.6213 - val_acc: 0.6622\n",
      "Epoch 27/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6145 - acc: 0.6665 val_auc: 71.8461%\n",
      "Epoch 00027: val_auc improved from 0.71831 to 0.71846, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6146 - acc: 0.6664 - val_loss: 0.6217 - val_acc: 0.6621\n",
      "Epoch 28/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6146 - acc: 0.6650 val_auc: 71.9915%\n",
      "Epoch 00028: val_auc improved from 0.71846 to 0.71992, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.6145 - acc: 0.6652 - val_loss: 0.6214 - val_acc: 0.6642\n",
      "Epoch 29/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6120 - acc: 0.6694 val_auc: 72.0510%\n",
      "Epoch 00029: val_auc improved from 0.71992 to 0.72051, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6120 - acc: 0.6695 - val_loss: 0.6197 - val_acc: 0.6650\n",
      "Epoch 30/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6101 - acc: 0.6714 val_auc: 72.1980%\n",
      "Epoch 00030: val_auc improved from 0.72051 to 0.72198, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.6101 - acc: 0.6714 - val_loss: 0.6202 - val_acc: 0.6661\n",
      "Epoch 31/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6105 - acc: 0.6697 val_auc: 72.2638%\n",
      "Epoch 00031: val_auc improved from 0.72198 to 0.72264, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6105 - acc: 0.6697 - val_loss: 0.6190 - val_acc: 0.6663\n",
      "Epoch 32/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6088 - acc: 0.6721 val_auc: 72.3924%\n",
      "Epoch 00032: val_auc improved from 0.72264 to 0.72392, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.6087 - acc: 0.6722 - val_loss: 0.6181 - val_acc: 0.6683\n",
      "Epoch 33/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6078 - acc: 0.6723 val_auc: 72.4370%\n",
      "Epoch 00033: val_auc improved from 0.72392 to 0.72437, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.6079 - acc: 0.6723 - val_loss: 0.6172 - val_acc: 0.6682\n",
      "Epoch 34/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6067 - acc: 0.6746 val_auc: 72.5328%\n",
      "Epoch 00034: val_auc improved from 0.72437 to 0.72533, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.6066 - acc: 0.6747 - val_loss: 0.6173 - val_acc: 0.6695\n",
      "Epoch 35/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6053 - acc: 0.6744 val_auc: 72.5820%\n",
      "Epoch 00035: val_auc improved from 0.72533 to 0.72582, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6053 - acc: 0.6743 - val_loss: 0.6177 - val_acc: 0.6696\n",
      "Epoch 36/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6050 - acc: 0.6756 val_auc: 72.6788%\n",
      "Epoch 00036: val_auc improved from 0.72582 to 0.72679, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.6049 - acc: 0.6755 - val_loss: 0.6160 - val_acc: 0.6705\n",
      "Epoch 37/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6034 - acc: 0.6771 val_auc: 72.7302%\n",
      "Epoch 00037: val_auc improved from 0.72679 to 0.72730, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.6032 - acc: 0.6773 - val_loss: 0.6175 - val_acc: 0.6697\n",
      "Epoch 38/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6020 - acc: 0.6779 val_auc: 72.7155%\n",
      "Epoch 00038: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 665us/step - loss: 0.6019 - acc: 0.6779 - val_loss: 0.6174 - val_acc: 0.6698\n",
      "Epoch 39/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6001 - acc: 0.6799 val_auc: 72.7483%\n",
      "Epoch 00039: val_auc improved from 0.72730 to 0.72748, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.6001 - acc: 0.6799 - val_loss: 0.6172 - val_acc: 0.6693\n",
      "Epoch 40/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6006 - acc: 0.6801 val_auc: 72.8493%\n",
      "Epoch 00040: val_auc improved from 0.72748 to 0.72849, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.6004 - acc: 0.6801 - val_loss: 0.6170 - val_acc: 0.6704\n",
      "Epoch 41/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5995 - acc: 0.6804 val_auc: 72.8244%\n",
      "Epoch 00041: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5995 - acc: 0.6804 - val_loss: 0.6177 - val_acc: 0.6707\n",
      "Epoch 42/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5975 - acc: 0.6820 val_auc: 72.9312%\n",
      "Epoch 00042: val_auc improved from 0.72849 to 0.72931, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5976 - acc: 0.6819 - val_loss: 0.6157 - val_acc: 0.6699\n",
      "Epoch 43/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5965 - acc: 0.6845 val_auc: 73.0126%\n",
      "Epoch 00043: val_auc improved from 0.72931 to 0.73013, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5965 - acc: 0.6845 - val_loss: 0.6156 - val_acc: 0.6716\n",
      "Epoch 44/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5955 - acc: 0.6850 val_auc: 73.0426%\n",
      "Epoch 00044: val_auc improved from 0.73013 to 0.73043, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5956 - acc: 0.6849 - val_loss: 0.6153 - val_acc: 0.6713\n",
      "Epoch 45/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5938 - acc: 0.6860 val_auc: 73.0434%\n",
      "Epoch 00045: val_auc improved from 0.73043 to 0.73043, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.5938 - acc: 0.6861 - val_loss: 0.6153 - val_acc: 0.6707\n",
      "Epoch 46/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5938 - acc: 0.6858 val_auc: 73.0899%\n",
      "Epoch 00046: val_auc improved from 0.73043 to 0.73090, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5940 - acc: 0.6856 - val_loss: 0.6167 - val_acc: 0.6716\n",
      "Epoch 47/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5931 - acc: 0.6871 val_auc: 73.1730%\n",
      "Epoch 00047: val_auc improved from 0.73090 to 0.73173, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.5931 - acc: 0.6870 - val_loss: 0.6152 - val_acc: 0.6709\n",
      "Epoch 48/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5920 - acc: 0.6884 val_auc: 73.1687%\n",
      "Epoch 00048: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5920 - acc: 0.6884 - val_loss: 0.6171 - val_acc: 0.6714\n",
      "Epoch 49/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5909 - acc: 0.6875 val_auc: 73.1415%\n",
      "Epoch 00049: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 665us/step - loss: 0.5908 - acc: 0.6876 - val_loss: 0.6153 - val_acc: 0.6715\n",
      "Epoch 50/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5893 - acc: 0.6894 val_auc: 73.2671%\n",
      "Epoch 00050: val_auc improved from 0.73173 to 0.73267, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.5893 - acc: 0.6896 - val_loss: 0.6156 - val_acc: 0.6724\n",
      "Epoch 51/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5889 - acc: 0.6910 val_auc: 73.3013%\n",
      "Epoch 00051: val_auc improved from 0.73267 to 0.73301, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.5889 - acc: 0.6910 - val_loss: 0.6172 - val_acc: 0.6726\n",
      "Epoch 52/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5881 - acc: 0.6919 val_auc: 73.3512%\n",
      "Epoch 00052: val_auc improved from 0.73301 to 0.73351, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.5883 - acc: 0.6917 - val_loss: 0.6156 - val_acc: 0.6730\n",
      "Epoch 53/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5875 - acc: 0.6913 val_auc: 73.4339%\n",
      "Epoch 00053: val_auc improved from 0.73351 to 0.73434, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 672us/step - loss: 0.5877 - acc: 0.6912 - val_loss: 0.6128 - val_acc: 0.6730\n",
      "Epoch 54/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5863 - acc: 0.6933 val_auc: 73.4280%\n",
      "Epoch 00054: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.5862 - acc: 0.6933 - val_loss: 0.6149 - val_acc: 0.6723\n",
      "Epoch 55/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5857 - acc: 0.6926 val_auc: 73.4465%\n",
      "Epoch 00055: val_auc improved from 0.73434 to 0.73446, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.5857 - acc: 0.6927 - val_loss: 0.6142 - val_acc: 0.6734\n",
      "Epoch 56/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5859 - acc: 0.6922 val_auc: 73.4982%\n",
      "Epoch 00056: val_auc improved from 0.73446 to 0.73498, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.5859 - acc: 0.6922 - val_loss: 0.6125 - val_acc: 0.6736\n",
      "Epoch 57/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5836 - acc: 0.6948 val_auc: 73.4910%\n",
      "Epoch 00057: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.5837 - acc: 0.6947 - val_loss: 0.6147 - val_acc: 0.6729\n",
      "Epoch 58/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5827 - acc: 0.6955 val_auc: 73.5145%\n",
      "Epoch 00058: val_auc improved from 0.73498 to 0.73514, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.5828 - acc: 0.6956 - val_loss: 0.6153 - val_acc: 0.6735\n",
      "Epoch 59/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5823 - acc: 0.6964 val_auc: 73.5046%\n",
      "Epoch 00059: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.5824 - acc: 0.6963 - val_loss: 0.6134 - val_acc: 0.6744\n",
      "Epoch 60/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5800 - acc: 0.6983 val_auc: 73.5637%\n",
      "Epoch 00060: val_auc improved from 0.73514 to 0.73564, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.5799 - acc: 0.6984 - val_loss: 0.6163 - val_acc: 0.6741\n",
      "Epoch 61/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5804 - acc: 0.6974 val_auc: 73.6127%\n",
      "Epoch 00061: val_auc improved from 0.73564 to 0.73613, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 670us/step - loss: 0.5806 - acc: 0.6973 - val_loss: 0.6129 - val_acc: 0.6753\n",
      "Epoch 62/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5805 - acc: 0.6971 val_auc: 73.6606%\n",
      "Epoch 00062: val_auc improved from 0.73613 to 0.73661, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.5805 - acc: 0.6971 - val_loss: 0.6145 - val_acc: 0.6753\n",
      "Epoch 63/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5793 - acc: 0.6977 val_auc: 73.6897%\n",
      "Epoch 00063: val_auc improved from 0.73661 to 0.73690, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.5792 - acc: 0.6979 - val_loss: 0.6141 - val_acc: 0.6759\n",
      "Epoch 64/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5784 - acc: 0.6982 val_auc: 73.7272%\n",
      "Epoch 00064: val_auc improved from 0.73690 to 0.73727, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.5783 - acc: 0.6982 - val_loss: 0.6130 - val_acc: 0.6752\n",
      "Epoch 65/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5768 - acc: 0.7000 val_auc: 73.7320%\n",
      "Epoch 00065: val_auc improved from 0.73727 to 0.73732, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 671us/step - loss: 0.5767 - acc: 0.7001 - val_loss: 0.6141 - val_acc: 0.6748\n",
      "Epoch 66/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5757 - acc: 0.7015 val_auc: 73.7223%\n",
      "Epoch 00066: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.5758 - acc: 0.7014 - val_loss: 0.6125 - val_acc: 0.6743\n",
      "Epoch 67/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5747 - acc: 0.7020 val_auc: 73.7257%\n",
      "Epoch 00067: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5747 - acc: 0.7020 - val_loss: 0.6142 - val_acc: 0.6750\n",
      "Epoch 68/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5740 - acc: 0.7024 val_auc: 73.7835%\n",
      "Epoch 00068: val_auc improved from 0.73732 to 0.73784, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5739 - acc: 0.7025 - val_loss: 0.6132 - val_acc: 0.6751\n",
      "Epoch 69/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5742 - acc: 0.7021 val_auc: 73.8298%\n",
      "Epoch 00069: val_auc improved from 0.73784 to 0.73830, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5741 - acc: 0.7021 - val_loss: 0.6123 - val_acc: 0.6753\n",
      "Epoch 70/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5727 - acc: 0.7034 val_auc: 73.8159%\n",
      "Epoch 00070: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5728 - acc: 0.7033 - val_loss: 0.6146 - val_acc: 0.6752\n",
      "Epoch 71/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5722 - acc: 0.7035 val_auc: 73.8533%\n",
      "Epoch 00071: val_auc improved from 0.73830 to 0.73853, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5720 - acc: 0.7035 - val_loss: 0.6143 - val_acc: 0.6762\n",
      "Epoch 72/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5720 - acc: 0.7043 val_auc: 73.8736%\n",
      "Epoch 00072: val_auc improved from 0.73853 to 0.73874, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5719 - acc: 0.7044 - val_loss: 0.6137 - val_acc: 0.6762\n",
      "Epoch 73/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5699 - acc: 0.7050 val_auc: 73.8889%\n",
      "Epoch 00073: val_auc improved from 0.73874 to 0.73889, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5697 - acc: 0.7053 - val_loss: 0.6137 - val_acc: 0.6766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5696 - acc: 0.7064 val_auc: 73.9339%\n",
      "Epoch 00074: val_auc improved from 0.73889 to 0.73934, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5696 - acc: 0.7063 - val_loss: 0.6141 - val_acc: 0.6765\n",
      "Epoch 75/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5693 - acc: 0.7065 val_auc: 73.9792%\n",
      "Epoch 00075: val_auc improved from 0.73934 to 0.73979, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5693 - acc: 0.7064 - val_loss: 0.6131 - val_acc: 0.6772\n",
      "Epoch 76/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5668 - acc: 0.7077 val_auc: 73.9983%\n",
      "Epoch 00076: val_auc improved from 0.73979 to 0.73998, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.5666 - acc: 0.7078 - val_loss: 0.6128 - val_acc: 0.6770\n",
      "Epoch 77/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5665 - acc: 0.7083 val_auc: 73.9859%\n",
      "Epoch 00077: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5666 - acc: 0.7082 - val_loss: 0.6134 - val_acc: 0.6773\n",
      "Epoch 78/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5660 - acc: 0.7092 val_auc: 73.9812%\n",
      "Epoch 00078: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5659 - acc: 0.7092 - val_loss: 0.6123 - val_acc: 0.6768\n",
      "Epoch 79/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5660 - acc: 0.7088 val_auc: 74.0510%\n",
      "Epoch 00079: val_auc improved from 0.73998 to 0.74051, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5659 - acc: 0.7091 - val_loss: 0.6132 - val_acc: 0.6778\n",
      "Epoch 80/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5656 - acc: 0.7085 val_auc: 73.9671%\n",
      "Epoch 00080: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 665us/step - loss: 0.5654 - acc: 0.7087 - val_loss: 0.6143 - val_acc: 0.6781\n",
      "Epoch 81/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5646 - acc: 0.7085 val_auc: 74.0182%\n",
      "Epoch 00081: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5646 - acc: 0.7085 - val_loss: 0.6155 - val_acc: 0.6779\n",
      "Epoch 82/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5639 - acc: 0.7095 val_auc: 74.0829%\n",
      "Epoch 00082: val_auc improved from 0.74051 to 0.74083, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5639 - acc: 0.7096 - val_loss: 0.6134 - val_acc: 0.6776\n",
      "Epoch 83/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5634 - acc: 0.7100 val_auc: 74.1249%\n",
      "Epoch 00083: val_auc improved from 0.74083 to 0.74125, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5632 - acc: 0.7101 - val_loss: 0.6152 - val_acc: 0.6786\n",
      "Epoch 84/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5630 - acc: 0.7104 val_auc: 74.0655%\n",
      "Epoch 00084: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.5632 - acc: 0.7102 - val_loss: 0.6156 - val_acc: 0.6785\n",
      "Epoch 85/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5622 - acc: 0.7118 val_auc: 74.1241%\n",
      "Epoch 00085: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5621 - acc: 0.7117 - val_loss: 0.6136 - val_acc: 0.6794\n",
      "Epoch 86/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5611 - acc: 0.7114 val_auc: 74.1947%\n",
      "Epoch 00086: val_auc improved from 0.74125 to 0.74195, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.5612 - acc: 0.7114 - val_loss: 0.6149 - val_acc: 0.6797\n",
      "Epoch 87/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5602 - acc: 0.7125 val_auc: 74.1653%\n",
      "Epoch 00087: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.5602 - acc: 0.7126 - val_loss: 0.6137 - val_acc: 0.6788\n",
      "Epoch 88/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5580 - acc: 0.7140 val_auc: 74.1851%\n",
      "Epoch 00088: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.5579 - acc: 0.7142 - val_loss: 0.6151 - val_acc: 0.6786\n",
      "Epoch 89/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5579 - acc: 0.7133 val_auc: 74.1762%\n",
      "Epoch 00089: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5578 - acc: 0.7134 - val_loss: 0.6151 - val_acc: 0.6792\n",
      "Epoch 90/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5573 - acc: 0.7151 val_auc: 74.2067%\n",
      "Epoch 00090: val_auc improved from 0.74195 to 0.74207, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 669us/step - loss: 0.5573 - acc: 0.7150 - val_loss: 0.6151 - val_acc: 0.6790\n",
      "Epoch 91/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5562 - acc: 0.7157 val_auc: 74.1953%\n",
      "Epoch 00091: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5562 - acc: 0.7157 - val_loss: 0.6159 - val_acc: 0.6801\n",
      "Epoch 92/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5555 - acc: 0.7158 val_auc: 74.2324%\n",
      "Epoch 00092: val_auc improved from 0.74207 to 0.74232, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5554 - acc: 0.7157 - val_loss: 0.6157 - val_acc: 0.6790\n",
      "Epoch 93/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5538 - acc: 0.7172 val_auc: 74.2367%\n",
      "Epoch 00093: val_auc improved from 0.74232 to 0.74237, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.5537 - acc: 0.7172 - val_loss: 0.6178 - val_acc: 0.6798\n",
      "Epoch 94/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5540 - acc: 0.7178 val_auc: 74.2518%\n",
      "Epoch 00094: val_auc improved from 0.74237 to 0.74252, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.5541 - acc: 0.7177 - val_loss: 0.6161 - val_acc: 0.6791\n",
      "Epoch 95/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5537 - acc: 0.7164 val_auc: 74.2839%\n",
      "Epoch 00095: val_auc improved from 0.74252 to 0.74284, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5537 - acc: 0.7163 - val_loss: 0.6167 - val_acc: 0.6801\n",
      "Epoch 96/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5543 - acc: 0.7175 val_auc: 74.2339%\n",
      "Epoch 00096: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 665us/step - loss: 0.5541 - acc: 0.7176 - val_loss: 0.6159 - val_acc: 0.6795\n",
      "Epoch 97/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5517 - acc: 0.7183 val_auc: 74.2741%\n",
      "Epoch 00097: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5515 - acc: 0.7185 - val_loss: 0.6158 - val_acc: 0.6801\n",
      "Epoch 98/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5510 - acc: 0.7187 val_auc: 74.2704%\n",
      "Epoch 00098: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5510 - acc: 0.7188 - val_loss: 0.6158 - val_acc: 0.6794\n",
      "Epoch 99/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5496 - acc: 0.7197 val_auc: 74.3121%\n",
      "Epoch 00099: val_auc improved from 0.74284 to 0.74312, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.5498 - acc: 0.7196 - val_loss: 0.6190 - val_acc: 0.6790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5488 - acc: 0.7212 val_auc: 74.3045%\n",
      "Epoch 00100: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5487 - acc: 0.7214 - val_loss: 0.6176 - val_acc: 0.6796\n",
      "Epoch 101/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5485 - acc: 0.7206 val_auc: 74.3060%\n",
      "Epoch 00101: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5485 - acc: 0.7207 - val_loss: 0.6176 - val_acc: 0.6797\n",
      "Epoch 102/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5468 - acc: 0.7223 val_auc: 74.3434%\n",
      "Epoch 00102: val_auc improved from 0.74312 to 0.74343, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.5468 - acc: 0.7223 - val_loss: 0.6193 - val_acc: 0.6795\n",
      "Epoch 103/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5469 - acc: 0.7223 val_auc: 74.3514%\n",
      "Epoch 00103: val_auc improved from 0.74343 to 0.74351, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.5467 - acc: 0.7225 - val_loss: 0.6192 - val_acc: 0.6798\n",
      "Epoch 104/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5465 - acc: 0.7220 val_auc: 74.3296%\n",
      "Epoch 00104: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.5465 - acc: 0.7219 - val_loss: 0.6187 - val_acc: 0.6791\n",
      "Epoch 105/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5442 - acc: 0.7243 val_auc: 74.3498%\n",
      "Epoch 00105: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5443 - acc: 0.7242 - val_loss: 0.6204 - val_acc: 0.6798\n",
      "Epoch 106/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5433 - acc: 0.7255 val_auc: 74.3142%\n",
      "Epoch 00106: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5434 - acc: 0.7254 - val_loss: 0.6218 - val_acc: 0.6794\n",
      "Epoch 107/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5435 - acc: 0.7239 val_auc: 74.3183%\n",
      "Epoch 00107: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5437 - acc: 0.7238 - val_loss: 0.6197 - val_acc: 0.6808\n",
      "Epoch 108/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5427 - acc: 0.7249 val_auc: 74.3520%\n",
      "Epoch 00108: val_auc improved from 0.74351 to 0.74352, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5428 - acc: 0.7249 - val_loss: 0.6208 - val_acc: 0.6795\n",
      "Epoch 109/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5420 - acc: 0.7255 val_auc: 74.3506%\n",
      "Epoch 00109: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.5421 - acc: 0.7254 - val_loss: 0.6207 - val_acc: 0.6794\n",
      "Epoch 110/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5406 - acc: 0.7257 val_auc: 74.3440%\n",
      "Epoch 00110: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 665us/step - loss: 0.5407 - acc: 0.7255 - val_loss: 0.6221 - val_acc: 0.6791\n",
      "Epoch 111/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5400 - acc: 0.7275 val_auc: 74.3321%\n",
      "Epoch 00111: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5401 - acc: 0.7273 - val_loss: 0.6216 - val_acc: 0.6803\n",
      "Epoch 112/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5397 - acc: 0.7273 val_auc: 74.3505%\n",
      "Epoch 00112: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.5399 - acc: 0.7271 - val_loss: 0.6221 - val_acc: 0.6802\n",
      "Epoch 113/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5383 - acc: 0.7279 val_auc: 74.3826%\n",
      "Epoch 00113: val_auc improved from 0.74352 to 0.74383, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5381 - acc: 0.7280 - val_loss: 0.6234 - val_acc: 0.6798\n",
      "Epoch 114/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5378 - acc: 0.7273 val_auc: 74.3654%\n",
      "Epoch 00114: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.5378 - acc: 0.7273 - val_loss: 0.6247 - val_acc: 0.6792\n",
      "Epoch 115/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5361 - acc: 0.7300 val_auc: 74.3494%\n",
      "Epoch 00115: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5360 - acc: 0.7302 - val_loss: 0.6235 - val_acc: 0.6774\n",
      "Epoch 116/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5361 - acc: 0.7294 val_auc: 74.3411%\n",
      "Epoch 00116: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5361 - acc: 0.7293 - val_loss: 0.6259 - val_acc: 0.6801\n",
      "Epoch 117/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5353 - acc: 0.7315 val_auc: 74.3171%\n",
      "Epoch 00117: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5352 - acc: 0.7315 - val_loss: 0.6237 - val_acc: 0.6792\n",
      "Epoch 118/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5347 - acc: 0.7307 val_auc: 74.3803%\n",
      "Epoch 00118: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 665us/step - loss: 0.5346 - acc: 0.7308 - val_loss: 0.6251 - val_acc: 0.6805\n",
      "Epoch 119/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5339 - acc: 0.7312 val_auc: 74.3844%\n",
      "Epoch 00119: val_auc improved from 0.74383 to 0.74384, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5339 - acc: 0.7311 - val_loss: 0.6281 - val_acc: 0.6803\n",
      "Epoch 120/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5326 - acc: 0.7311 val_auc: 74.3017%\n",
      "Epoch 00120: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5325 - acc: 0.7311 - val_loss: 0.6245 - val_acc: 0.6792\n",
      "Epoch 121/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5311 - acc: 0.7325 val_auc: 74.3500%\n",
      "Epoch 00121: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5310 - acc: 0.7325 - val_loss: 0.6279 - val_acc: 0.6789\n",
      "Epoch 122/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5308 - acc: 0.7334 val_auc: 74.3707%\n",
      "Epoch 00122: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5308 - acc: 0.7335 - val_loss: 0.6281 - val_acc: 0.6797\n",
      "Epoch 123/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5312 - acc: 0.7336 val_auc: 74.3583%\n",
      "Epoch 00123: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.5312 - acc: 0.7334 - val_loss: 0.6271 - val_acc: 0.6811\n",
      "Epoch 124/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5293 - acc: 0.7335 val_auc: 74.3737%\n",
      "Epoch 00124: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 665us/step - loss: 0.5294 - acc: 0.7334 - val_loss: 0.6287 - val_acc: 0.6809\n",
      "Epoch 125/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5290 - acc: 0.7344 val_auc: 74.3459%\n",
      "Epoch 00125: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.5290 - acc: 0.7344 - val_loss: 0.6295 - val_acc: 0.6791\n",
      "Epoch 126/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5275 - acc: 0.7359 val_auc: 74.4057%\n",
      "Epoch 00126: val_auc improved from 0.74384 to 0.74406, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5274 - acc: 0.7359 - val_loss: 0.6309 - val_acc: 0.6798\n",
      "Epoch 127/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5267 - acc: 0.7361 val_auc: 74.3595%\n",
      "Epoch 00127: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 665us/step - loss: 0.5268 - acc: 0.7361 - val_loss: 0.6300 - val_acc: 0.6799\n",
      "Epoch 128/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5249 - acc: 0.7365 val_auc: 74.3689%\n",
      "Epoch 00128: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5250 - acc: 0.7364 - val_loss: 0.6326 - val_acc: 0.6802\n",
      "Epoch 129/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5259 - acc: 0.7360 val_auc: 74.3655%\n",
      "Epoch 00129: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5258 - acc: 0.7360 - val_loss: 0.6321 - val_acc: 0.6806\n",
      "Epoch 130/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5235 - acc: 0.7384 val_auc: 74.3307%\n",
      "Epoch 00130: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5235 - acc: 0.7384 - val_loss: 0.6298 - val_acc: 0.6803\n",
      "Epoch 131/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5231 - acc: 0.7390 val_auc: 74.3313%\n",
      "Epoch 00131: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5230 - acc: 0.7391 - val_loss: 0.6319 - val_acc: 0.6801\n",
      "Epoch 132/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5225 - acc: 0.7370 val_auc: 74.2932%\n",
      "Epoch 00132: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.5225 - acc: 0.7371 - val_loss: 0.6305 - val_acc: 0.6805\n",
      "Epoch 133/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5229 - acc: 0.7383 val_auc: 74.3538%\n",
      "Epoch 00133: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.5229 - acc: 0.7382 - val_loss: 0.6322 - val_acc: 0.6801\n",
      "Epoch 134/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5215 - acc: 0.7391 val_auc: 74.3405%\n",
      "Epoch 00134: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5214 - acc: 0.7391 - val_loss: 0.6338 - val_acc: 0.6816\n",
      "Epoch 135/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5201 - acc: 0.7396 val_auc: 74.2931%\n",
      "Epoch 00135: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5203 - acc: 0.7395 - val_loss: 0.6349 - val_acc: 0.6810\n",
      "Epoch 136/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5187 - acc: 0.7416 val_auc: 74.2746%\n",
      "Epoch 00136: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.5189 - acc: 0.7415 - val_loss: 0.6338 - val_acc: 0.6802\n",
      "Epoch 137/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5186 - acc: 0.7400 val_auc: 74.3395%\n",
      "Epoch 00137: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5187 - acc: 0.7399 - val_loss: 0.6369 - val_acc: 0.6804\n",
      "Epoch 138/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5194 - acc: 0.7399 val_auc: 74.3567%\n",
      "Epoch 00138: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 665us/step - loss: 0.5192 - acc: 0.7401 - val_loss: 0.6388 - val_acc: 0.6804\n",
      "Epoch 139/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5179 - acc: 0.7416 val_auc: 74.3184%\n",
      "Epoch 00139: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 665us/step - loss: 0.5179 - acc: 0.7415 - val_loss: 0.6360 - val_acc: 0.6812\n",
      "Epoch 140/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5162 - acc: 0.7426 val_auc: 74.2960%\n",
      "Epoch 00140: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5163 - acc: 0.7425 - val_loss: 0.6363 - val_acc: 0.6803\n",
      "Epoch 141/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5156 - acc: 0.7425 val_auc: 74.3133%\n",
      "Epoch 00141: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5157 - acc: 0.7425 - val_loss: 0.6368 - val_acc: 0.6817\n",
      "Epoch 142/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5157 - acc: 0.7416 val_auc: 74.3312%\n",
      "Epoch 00142: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.5156 - acc: 0.7416 - val_loss: 0.6391 - val_acc: 0.6821\n",
      "Epoch 143/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5133 - acc: 0.7441 val_auc: 74.3476%\n",
      "Epoch 00143: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.5133 - acc: 0.7441 - val_loss: 0.6414 - val_acc: 0.6823\n",
      "Epoch 144/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5133 - acc: 0.7443 val_auc: 74.3286%\n",
      "Epoch 00144: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.5136 - acc: 0.7441 - val_loss: 0.6384 - val_acc: 0.6815\n",
      "Epoch 145/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5126 - acc: 0.7448 val_auc: 74.3366%\n",
      "Epoch 00145: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5128 - acc: 0.7447 - val_loss: 0.6429 - val_acc: 0.6831\n",
      "Epoch 146/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5128 - acc: 0.7456 val_auc: 74.2762%\n",
      "Epoch 00146: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5126 - acc: 0.7456 - val_loss: 0.6417 - val_acc: 0.6817\n",
      "Epoch 147/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5109 - acc: 0.7446 val_auc: 74.3027%\n",
      "Epoch 00147: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 664us/step - loss: 0.5109 - acc: 0.7446 - val_loss: 0.6425 - val_acc: 0.6823\n",
      "Epoch 148/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5099 - acc: 0.7465 val_auc: 74.3651%\n",
      "Epoch 00148: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 665us/step - loss: 0.5098 - acc: 0.7466 - val_loss: 0.6463 - val_acc: 0.6818\n",
      "Epoch 149/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5086 - acc: 0.7469 val_auc: 74.3002%\n",
      "Epoch 00149: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5084 - acc: 0.7470 - val_loss: 0.6435 - val_acc: 0.6817\n",
      "Epoch 150/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5091 - acc: 0.7466 val_auc: 74.3197%\n",
      "Epoch 00150: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 665us/step - loss: 0.5091 - acc: 0.7467 - val_loss: 0.6451 - val_acc: 0.6821\n",
      "Epoch 151/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5080 - acc: 0.7477 val_auc: 74.3116%\n",
      "Epoch 00151: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5081 - acc: 0.7475 - val_loss: 0.6461 - val_acc: 0.6825\n",
      "Epoch 152/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5077 - acc: 0.7480 val_auc: 74.2793%\n",
      "Epoch 00152: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5079 - acc: 0.7480 - val_loss: 0.6455 - val_acc: 0.6812\n",
      "Epoch 153/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5060 - acc: 0.7490 val_auc: 74.2477%\n",
      "Epoch 00153: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 665us/step - loss: 0.5064 - acc: 0.7487 - val_loss: 0.6448 - val_acc: 0.6816\n",
      "Epoch 154/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5057 - acc: 0.7490 val_auc: 74.2699%\n",
      "Epoch 00154: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5057 - acc: 0.7490 - val_loss: 0.6454 - val_acc: 0.6825\n",
      "Epoch 155/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5032 - acc: 0.7513 val_auc: 74.2972%\n",
      "Epoch 00155: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 665us/step - loss: 0.5033 - acc: 0.7512 - val_loss: 0.6482 - val_acc: 0.6822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5037 - acc: 0.7500 val_auc: 74.2853%\n",
      "Epoch 00156: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5038 - acc: 0.7499 - val_loss: 0.6505 - val_acc: 0.6826\n",
      "Epoch 157/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5028 - acc: 0.7520 val_auc: 74.2937%\n",
      "Epoch 00157: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.5029 - acc: 0.7519 - val_loss: 0.6520 - val_acc: 0.6814\n",
      "Epoch 158/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5022 - acc: 0.7515 val_auc: 74.3251%\n",
      "Epoch 00158: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.5023 - acc: 0.7514 - val_loss: 0.6529 - val_acc: 0.6838\n",
      "Epoch 159/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5017 - acc: 0.7525 val_auc: 74.2922%\n",
      "Epoch 00159: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5016 - acc: 0.7525 - val_loss: 0.6534 - val_acc: 0.6816\n",
      "Epoch 160/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4998 - acc: 0.7530 val_auc: 74.2259%\n",
      "Epoch 00160: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.5000 - acc: 0.7529 - val_loss: 0.6517 - val_acc: 0.6814\n",
      "Epoch 161/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4998 - acc: 0.7536 val_auc: 74.2148%\n",
      "Epoch 00161: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.4997 - acc: 0.7536 - val_loss: 0.6537 - val_acc: 0.6813\n",
      "Epoch 162/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4987 - acc: 0.7539 val_auc: 74.1811%\n",
      "Epoch 00162: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.4988 - acc: 0.7538 - val_loss: 0.6540 - val_acc: 0.6811\n",
      "Epoch 163/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4987 - acc: 0.7533 val_auc: 74.2338%\n",
      "Epoch 00163: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.4986 - acc: 0.7533 - val_loss: 0.6581 - val_acc: 0.6807\n",
      "Epoch 164/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4970 - acc: 0.7554 val_auc: 74.2767%\n",
      "Epoch 00164: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.4971 - acc: 0.7553 - val_loss: 0.6568 - val_acc: 0.6814\n",
      "Epoch 165/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4971 - acc: 0.7544 val_auc: 74.2358%\n",
      "Epoch 00165: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.4969 - acc: 0.7545 - val_loss: 0.6546 - val_acc: 0.6806\n",
      "Epoch 166/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4955 - acc: 0.7556 val_auc: 74.2516%\n",
      "Epoch 00166: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.4955 - acc: 0.7556 - val_loss: 0.6599 - val_acc: 0.6812\n",
      "Epoch 167/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4948 - acc: 0.7548 val_auc: 74.1883%\n",
      "Epoch 00167: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.4948 - acc: 0.7548 - val_loss: 0.6586 - val_acc: 0.6820\n",
      "Epoch 168/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4946 - acc: 0.7561 val_auc: 74.2455%\n",
      "Epoch 00168: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.4945 - acc: 0.7561 - val_loss: 0.6615 - val_acc: 0.6816\n",
      "Epoch 169/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4951 - acc: 0.7557 val_auc: 74.1600%\n",
      "Epoch 00169: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.4951 - acc: 0.7556 - val_loss: 0.6592 - val_acc: 0.6823\n",
      "Epoch 170/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4929 - acc: 0.7581 val_auc: 74.1696%\n",
      "Epoch 00170: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 665us/step - loss: 0.4928 - acc: 0.7581 - val_loss: 0.6615 - val_acc: 0.6825\n",
      "Epoch 171/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4915 - acc: 0.7588 val_auc: 74.2109%\n",
      "Epoch 00171: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 667us/step - loss: 0.4913 - acc: 0.7590 - val_loss: 0.6634 - val_acc: 0.6826\n",
      "Epoch 172/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4907 - acc: 0.7594 val_auc: 74.1822%\n",
      "Epoch 00172: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 666us/step - loss: 0.4907 - acc: 0.7594 - val_loss: 0.6632 - val_acc: 0.6828\n",
      "Epoch 173/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4914 - acc: 0.7585 val_auc: 74.1675%\n",
      "Epoch 00173: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.4917 - acc: 0.7584 - val_loss: 0.6607 - val_acc: 0.6835\n",
      "Epoch 174/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4896 - acc: 0.7595 val_auc: 74.1849%\n",
      "Epoch 00174: val_auc did not improve\n",
      "171945/171945 [==============================] - 115s 668us/step - loss: 0.4898 - acc: 0.7595 - val_loss: 0.6656 - val_acc: 0.6828\n",
      "Epoch 175/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4886 - acc: 0.7605 val_auc: 74.1190%\n",
      "Epoch 00175: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.4886 - acc: 0.7604 - val_loss: 0.6649 - val_acc: 0.6828\n",
      "Epoch 176/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.4892 - acc: 0.7607 val_auc: 74.1341%\n",
      "Epoch 00176: val_auc did not improve\n",
      "171945/171945 [==============================] - 114s 666us/step - loss: 0.4894 - acc: 0.7606 - val_loss: 0.6669 - val_acc: 0.6825\n",
      "Epoch 00176: early stopping\n",
      "Wall time: 5h 38min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history300_trained = nn.run_model(model=model300_trained, out_path=\"models/nn_300d_trained.hdf5\",\n",
    "                                 optimizer=Adam(lr=0.00025), patience=50, train_auc=False, **run_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/interim/nn300_trained_history.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save history\n",
    "joblib.dump(history300_trained.history, \"data/interim/nn300_trained_history.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 -  Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identify best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load histories\n",
    "model_names = (\"nn50_fixed\",\"nn300_fixed\",\"nn50_trained\",\"nn300_trained\")\n",
    "hist_list = [joblib.load(\"data/interim/\"+hist+\"_history.pkl\") for hist in model_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model nn50_fixed obtained a maximum AUC of 0.7313\n",
      "The model nn300_fixed obtained a maximum AUC of 0.7487\n",
      "The model nn50_trained obtained a maximum AUC of 0.7609\n",
      "The model nn300_trained obtained a maximum AUC of 0.7441\n",
      "\n",
      "Best model is nn50_trained with a validation AUC of 76.0851%\n"
     ]
    }
   ],
   "source": [
    "#identify best\n",
    "val_auc = 0\n",
    "best_model = 0\n",
    "for i, hist in enumerate(hist_list):\n",
    "    current_best = max(hist[\"val_auc\"])\n",
    "    print(\"The model {0} obtained a maximum AUC of {1:.4f}\".format(model_names[i], current_best))\n",
    "    if current_best > val_auc:\n",
    "        best_model = i\n",
    "        val_auc = current_best\n",
    "print(\"\\nBest model is {0} with a validation AUC of {1:.4%}\".format(model_names[best_model], val_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model50_trained = load_model(\"models/nn_50d_trained.hdf5\", custom_objects={\"GlobalAverage\":nn.GlobalAverage})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model has an accuracy of 68.6710% on the test set\n",
      "Wall time: 9.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = model50_trained.predict(test[\"seqs\"], batch_size = 2000)\n",
    "acc = np.mean((np.squeeze(preds) > 0.5) == test[\"labels\"])\n",
    "print(\"Best model has an accuracy of {:.4%} on the test set\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x285683d0c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#AUC comparision\n",
    "#first, load the predictions from the other models\n",
    "dt_best_preds = joblib.load(\"data/processed/dt_probs.pkl\")\n",
    "lin_probs = joblib.load(\"data/processed/linear_probs.pkl\")\n",
    "rf_probs = joblib.load(\"data/processed/rf_probs.pkl\")\n",
    "roc_plot(test[\"labels\"], [preds, dt_best_preds, lin_probs, rf_probs],\n",
    "         [\"Best Neural Network\", \"Best Tree\", \"Benchmark Linear\", \"Best Random Forest\"], 'reports/figures/ROC_nn.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd4VFX6wPHvm0YSSKF3CEgH6YKCKBYQK7oqoqKLa8Nd\n61p3XbuubfVn12XtCiJ2RRCpgiLSQXqJlFBDCy193t8f55JMQoAJZDIp7+d55sncc8u8cxnmnXvO\nueeIqmKMMcYcTVioAzDGGFM+WMIwxhgTEEsYxhhjAmIJwxhjTEAsYRhjjAmIJQxjjDEBsYRRiYhI\nExHZJyLhoY6lohORJBFREYkIdSzHS0SmisgNx3mMkH72SuI9GEsYFZKIrBWRdO8/6MFHA1Vdr6rV\nVDW3DMR48AvVP8aHjuN4j3rHG+RXFuGVJZVEzCXJ+zfaJiJV/cpuEJGpAe7/vog8GbQAj1Ggn72j\nfYEX8flYKyIPBBjDoyLycUm9J5PPEkbFdaH3H/TgY1MwX+w4fkkn+sX4xHGGsRN4rDR+xZbQa4QD\nd5TAcYJCnGP5jijJz16iqlYDrgQeFpEBx3Esc5wsYVQihatJRKSZiEwTkb0iMlFEXj/4y0xE+opI\nSqH914rI2d7zR0XkcxH5WET2AENFJExEHhCRNSKyQ0RGi0iNUnyLPwBZwJCiVopIFRH5j4isF5Gt\nIvKWiMR464aKyM+FtlcRaeE9f19E3hSRsSKyHzhDRM4XkfkiskdENojIo8WM93ngHhFJPEy8bURk\ngojsFJEVB6+eROQm4GrgPu/X93cicp2IfOe37yoR+cxveYOIdPae9xKR2SKS5v3t5bfdVBF5SkR+\nAQ4AzQvFVF9EFonIvcV5o/6fPRF5CugDvObF/9rR9lfVX4ElQAfveC9772mPiMwVkT5e+QDgn8AV\n3rEX+h2mqYj84n3efxSRWsV5D8YSRmU3EpgF1AQeBa4p5v4Dgc+BRGAEcBtwMXA60ADYBbx+lGOs\nE5EUEXmvBP4DK/AQ8IiIRBax/hmgFdAZaAE0BB4uxvGvAp4C4oCfgf3Atbj3fz5wi4hcXIzjzQGm\nAvcUXuFVVU3A/RvVAQYDb4hIO1Udjjvfz3m/4C8EfgL6eEm7ARAFnOIdqzlQDVjkJfDvgVdw/+4v\nAt+LSE2/l78GuMl7n+v8Ymrmvc5rqvp8Md5nAar6IDAduNWL/9Yjbe9d6fQG2gPzveLZuH/HGrhz\n9JmIRKvqD8C/gU+9Y3fyO9RVwHW48xlFEefdHJkljIrraxHZ7T2+LrxSRJoAJwEPq2qWqv4MfFvM\n1/hVVb9WVZ+qpgPDgAdVNUVVM3FJ6LLDVFdt916/KdAN9+U0opivfwhV/RZIBQrUj4uI4L4E71LV\nnaq6F/fFMrgYh/9GVX/x3m+Gqk5V1d+95UXAJ7hkWRwPA7eJSO1C5RcAa1X1PVXNUdX5wBfA5UUd\nRFWTgb24L9HTgPHAJhFp48U0XVV9uMS2SlU/8o77CbAcuNDvcO+r6hJvfbZX1g6YAjziJawjOeJn\nr5i246oa3wYeUNVJ3vv9WFV3eDG+AFQBWh/lWO+p6krvszoad65MMZT7HhzmsC5W1YlHWN8A2Kmq\nB/zKNgCNi/EaGwotNwW+EhGfX1kuUBfY6L+hqu7D/cIG2CoitwKbRSTO+zLP41U3jPMW16lq+6PE\n9S/gPeAjv7LaQCww1+UOd2hcO0KgCrxfEemJu2rpgPvFWgX4rIj9DktVF4vIGOABYJnfqqZATxHZ\n7VcWQcH3VNhPQF/c1dNPwG5csjjFWwb3776u0H7rcFdbBxX+dwVXBbYad0V5NEf77BVHLVXNKVwo\nIvcA1+PejwLxwNGuULf4PT+Au+oyxWBXGJXXZqCGiMT6lfkni/24L1ggr5G38K/gwkMdbwDOVdVE\nv0e0qm7k6A4e65DPpKpO92tAPVqyQFUn4L7c/upXvB1IB9r7xZbgNajCoe+33hFiPGgk7qqssaom\nAG/hklBxPQLcyKFf2j8VOpfVVPWWw8QC+Qmjj/f8J1zCOJ38hLEJl4z8NaFgQi/q2I/izuFIKZkG\n/2MeJtv7AXEfMAiorqqJQBr5596G4A4SSxiVlKquw/3Cf1REokTkFApWS6wEor2G3Ujcr/YqRzns\nW8BTItIUQERqi8jAojYUkZ4i0tqrc6+Jq1Ofqqppx/nWDnoQ96UCgFcd8z/g/0SkjhdDQxE5x9tk\nIdBeRDqLSDTuC/Jo4nBXaRki0gNXR15sqroa+BS43a94DNBKRK4RkUjvcZKItPXWb6VQgzQuKZwB\nxKhqCq6dYACureJg3f9Y77hXeQ3QV+Cqm8YcJcxsXHVYVeBDObbeU/6Kij9QcUAOruoxQkQexl1h\n+B87qQRiNIXYCa3crsZVV+wAnsR9aWUCeF/cf8XVHW/E/QJPKfoweV7G/eL+UUT2AjOBnofZtjmu\nV9NeYLH3ulcex3spQFV/wTXo+7sfd+UxU1zProl49d6quhJ43CtbhWvUPpq/Ao977/VhXL34sXoc\n92V8MP69QH9cG8smXHXKs+Qn7XeAdv7tBN572IdLFKjqHiAZ+OXg/Q+qugPXPnI37t/9PuACVd1+\ntABVNQv4E66K8d3j/EJ+Gde+tUtEXinmvuNxn52VuOq0DApWox2sFtwhIvOOI0ZTiNgESuYgEfkU\nWK6qj4Q6FmNM2WNXGJWYV8VxglctNADXTfZ4e7UYYyoo6yVVudUDvsTVcacAt3jdN40x5hBWJWWM\nMSYgViVljDEmIBWqSqpWrVqalJQU6jCMMabcmDt37nZVLXyPVZEqVMJISkpizpw5R9/QGGMMACJS\n+M7/w7IqKWOMMQGxhGGMMSYgljCMMcYExBKGMcaYgFjCMMYYExBLGMYYYwJiCcMYY0xALGFsWgAf\n/QnG3BXqSIwxpkyrUDfuHZPwSFgzCRKbhDoSY4wplmWb99Coegxx0ZGl8np2hVG7DUTFwe71sHdr\nqKMxxpiALNywm3Nfns4NH5Te6BaWMMLCoVE39zyl8ARtxhhTNo1bvAWA3/7YydPjlpXKa1rCAGjU\nw/1dPzO0cRhjTIA2p6XnPf/vT8n8umZH0F/TEgZA01Pc33UzQhuHMcb4SU7dx+DhvzL2980AZOf6\n8PmUn1amMnfdrrzt/tK7Ge3qxwc9Hmv0BneFIeGwaR7sTIYazUMdkTGmksrK8fHq5FX0bV2bbxZs\nYmbyTmb9sZOOjRJZumkPiNsGICo8jEWP9ic6MrxUYrOEAVClGjQ5Bdb9DB9dAjdOgdgaoY7KGFNJ\n7M/M4a5PF9C+QQI1qkXx6uTVvDp5NZHhAoBPYcGG3Yfs1z2peqklC7AqqXyXvAlxDWDXWniuGST/\nFOqIjDEVzLY9GQyftoanvl/KmEWb8sr/PXYZPy7dyv9NXMlDXy/OK8/OVRokRHP/gDYAhIdJXhIB\nGNorqdRihyBfYYjIAOBlIBx4W1WfKWKbvsBLQCSwXVVPF5HGwIdAXUCB4ar6cjBjJbEJnPUwfD3M\nLU9+EpJOdb2ojDGmmFZs2cv/pidzV79WNEyMAeCVyav4eOb6vG3ioiN5YsxSVm/bd9jjXNe7GTee\n1pwLOtanXkI0qXszyc71sWFnOqe2rBX09+FPVDU4BxYJB1YC/YAUYDZwpaou9dsmEZgBDFDV9SJS\nR1W3iUh9oL6qzhOROGAucLH/vkXp3r27HveMeyvHw8hB7nnbC2HQRyBy5H2MMaaQwcN/ZWbyThpV\nj+Hn+88EoMvjP7LrQHaR2197SlN27Muie1J1TjmhJhOWbGXRxjReHtyZ2Kjg/bYXkbmq2j2QbYN5\nhdEDWK2qyV5Qo4CBgP+X/lXAl6q6HkBVt3l/NwObved7RWQZ0LDQvsHR6hy4ajR8NhSWfQef/RlO\nOBPqtIeaJ1jbhjGVVHpWLtGRYchhfkDePXohSzal8eVfezFh6VZmJu8EIGVXOs/9sJz/TU8mO9f9\nQH/tqi7cOnJ+3r43nNqMB89vW+DYbeoFv9dTcQWzDaMhsMFvOcUr89cKqC4iU0VkrohcW/ggIpIE\ndAF+K+pFROQmEZkjInNSU1NLJHBanQMXvgwILP0GvrsD3jkbXu0K+7aVzGsYY8qNCUu30v6RH/ho\n5qHTXy/dtIf/TUvmi3kpLN+ylzemrOGOUQsKbPPG1DV5yaJnsxpc0LEBLepUy1t/8+knHDYRlSWh\n7iUVAXQDzgJigF9FZKaqrgQQkWrAF8CdqrqnqAOo6nBgOLgqqRKLrOMgqNMORl/jutoCpO+C6S/C\nuYc0xRhjKoj0rFyqRIQRFub1UPIpN37oqrof/mYJAzs1JCE2kll/7ORvI+eRujezwP6vTVl92GPf\ncVZLzu9YH4D7zmnNiN/WM6BDPWrHVQnSuylZwUwYG4HGfsuNvDJ/KcAOVd0P7BeRaUAnYKWIROKS\nxQhV/TKIcR5evQ5w61wIC3Oj2g7vC7+96RLIRa9AXL2QhGWMKXk+nzJ15TbuHr2Qbk1r0L99XVBo\nW+iGuF7PTOLPvZJ4Y+qawx6rS5NErurRhGpVIrhlxDwAalWrwl39WuVt0799Pfq3L1/fIcFMGLOB\nliLSDJcoBuPaLPx9A7wmIhFAFNAT+D9x12bvAMtU9cUgxnh0YV6tXYPOcN7zMPZeWDUeXmgNLc6G\nS9+BmMSQhmiMOX7Pjl/Of39ytQkTl21l4jI3GOmZbeoU2G5/Vm5esujUOJGXrujM1/M30rB6DPd9\nvgiAVwZ3oXGNWHw+JTJcyM5VGteIKcV3ExxBSxiqmiMitwLjcd1q31XVJSIyzFv/lqouE5EfgEWA\nD9f1drGInApcA/wuIgcrA/+pqmODFW9AetwIzU6HkZe7+zVWT4T/ngb1O7lh0i94CaLLXkOVMSbf\nzOQd5ORqXpfUA1k5/J6SxoczDm2fAJi83LVbPnFxB6Yu38Ykb7lWtSi+/msvRCTvykFVaVw9lsY1\nYgEICxN+uPM0nhyzlFvPbBHstxZ0QetWGwol0q02EKqwdQkMPx18Ofnl9TtBn3tAfdD+4uDHYYwp\nlsycXDo/NoH07FxeHNSJgZ0bcvlbM5i33t1FfULtqqRn5bIpLQOArk0Smbd+NyIw6e+n88vq7Tz0\nzRIABnZuwMuDu4TsvZSUstKttuISce0bl78Pq36EeR+68s0LXSM5QLVx0LRXyEI0xjhb0jL4dPYG\n+revy72fLyQ9OxdwI7zOXbcrL1lUiQjjpSu6cP8Xi/ISxmfDejF1xTbCw4TmtatRrUoEL01cxY79\nWZzWsnbI3lOo2BVGSfD54Kub4ffR+WXVk6D3nW4gw+anl35MxlRwqkrqvkzqxEUXKM/MyaVKRP4I\nDb2fmczG3emFd88TJvDMpR05vVVt6sZH8/S4Zfz3p2RObJjAd7edesj2ezKyWbV1L12bVC8XXWGP\nxq4wSltYGFz6P6gSB3PecWW71sKYO93zLtfAuc/B1sXQoCuE22k35ni9Pf0Pnhq7jLeGdCMzJ5du\nTavz0NeLmbZqO+8OPYn46Agysn1HTBYAV5zUhEHd8zt03nV2K+rFRzOwc+Hbxpz46Ei6Na2cN/Da\nFUZJyslyXW7j68M750BqEbNgnfUI9Pl76cdmTAWT9MD3h10XHRlGRrbvsOsbJsbkJZL/Xdudfu3q\nlnh85UVxrjBstNqSFBEFddpAdALcNAVumwd/GQ+1WudvM+kx2L4qdDEaUwHs2Jd5xPWHSxYnJVWn\ndd04vvpbLwaf1JhuTatzaovSHcCvPLMrjGOQlp5NVHgYMVEFR7LdtDud8Uu2MOTkpkSG++XirP0w\n9RmY8Up+WZUEqNMWzvintXEYU8jrU1azYsteLunakK6Nq7Nq216qRIRzICuHns1r8sSYpbzz8x+H\n7NelSSLt6scze+1OXrmyCzv3ZxEmwg+LtzB/w24+ubFnUAfyK4+sDeM45fqUjOxc/ti+n70ZOSTE\nRHJCnao8+u0Svpy3kcwcH/HRETx6UXtio8JpVz+BJjVj+cv7s1m+ZS9p6dncdmZLwg8OLRARC2c/\nTlj1pvD93e5FMtNgw0z4ZDAMHgl1O8AfP0Hbi9yVijEVzK79WUxavo2BnRsU+EGVk+vDpxAVEcaB\nrBwWpaTx/PgVAHy7cNMhx+nUKIGFKWmEhwm5voI/eJvWiOWpS048ZJ+Tm9cs4XdTOdkVBu6KITMn\nl59XbWdRShpjf9/MNr/xYaLCw+jcOJFZa3cWuX+j6jFc0b0xL0xYmVdWrUoEl3VrxJ97JXHPZwvZ\nuieDz4adwoHfPuSEGfcdPpjW57kEIkJ2ro+IMKkQPTFM5aOqvPvLWlrWqcZprWpz68h5jFnk5qb+\n9yUnclXPJuT6lKv+N5Olm/ZwfZ9mfDBj7WGH/y6sa5NE7unfmj927OfBr9ykQ1d0b8yzl3UM2nuq\niIpzhVHpE8a0lancPmo+VaMijtqbwl/b+vFs3ZPBzv1ZxYxS6Rc2l1m+NvgI4+6I0QyN+LHAFi/V\nepTkmn0Zv2QLrerG8fjA9nw6ewMXd2lov5RMmbdjXyYz1uxgb0YO//zqdwDG3t6H816ZXmC75U8M\nYNSs9Tz63aGzFrSqW40NO9M5sWECT13SgWa1qrJhVzrb9mRwxfCZAAw5uQlPXuyuJh77bgkfzFjL\n+DtPo2XduCC/w4rFEkYxbNqdzhn/mUqmN6n6Oe3r0rpePJ/P2UDXptW55uSmfLNwE98u2MSD57el\nU6NEft+4m0HdGyMizPpjJ395fzb7MnOIigjjtJa12JyWQUxkOAkxkfy0MpUcv8vm2KhwOjVKZOPu\ndNbvPADAF1GP0C0svyF8ra8u7+SeSzUy+Cq3N1vITxJ392vFtb2S8tpQMrJzeXXyKs4/sQHtGtiw\nJCa00g5kc+YLU9kRwA+pPi1rMXfdLg5k5RYoP7NNHd6+tjtZuT5vStKCfXMOTkL01pCuDOjgRn7N\nyfWRnp1LXHRkyb2ZSsISRjG9+OMKXpm8mlZ1qzH65lNIjD20DcHn07zhjgvbtT+L1H2ZtCril01G\ndi4isH7HAbJyfbSrH59XxXTwdZvKFv4b/RpvZ/Xj5vAxtAwrOKjvCl8jLsp6kkzy40qMjWTEDT2Z\n9cdOHvN+oS18uD8JsYf+h8nO9bH7QHa5GULZlH1rt+8nISaS6lWj2Lg7nWfHLSfXp0RFhPHV/MKD\nUh/ZuR3qUS8hmvd+WQvApzedTM8jXEmn7DrA3HW7uKhTA6uuLQGWMIpJVfl9Yxqt68UVuEM02HJy\nfUxftZ1TW9YiMjwMn09JWTSFhr/8i/CE+m5wQ8/7jZ6gXpVMvlq2j/G+HkUer0bVKK7s0ZgwERJi\nIsnM8TF33S5Wb9vH5rR0vvprb1Rh+ZY9tKhTjS5NqpfWWzXlRGZOLp/O3sAPi7fQul4cj1zYHnCf\n1ave/o2o8DAeH9ieAS9Np2nNWHq3qMX7M9YWOEZEmORdVYcJvH5VVx75dkleu+DSx89hxMz1xMdE\nuM9h4+qEhQlp6dkkp+6zz2Ups4RRUXx5Eyz6FACt1QrZ7hrVL6n+BYu2ZhXoIVInrkqBhvpA3Hx6\nc/akZzPrj51c1q0xg7o3oma1w1+FZObk8vTY5XRtWp2LOjU47HYLNuxm+95Mzq7EN0OVhmkrU0lO\n3cdVPZsSFVGw2iYrx8fKrXtpXD22yKvOg1SVeet3M2nZVjo3TmTxpj28Mim/enTKPX1pVqsqE5du\n5YYPA/u/9eKgTmzclc4LE1by2lVduKBjA16fsprnx6+gTlwVZj149rG9YRMUljAqiow9sPgL+P7v\nbgRcP1vPfIl7VrVjwfrdXNK1IY9d1J5vFmzitSmrSU7dh39vw9Na1WbayqNPX9upUQKXd29MRnYu\nuw9ks+tAFn/q2jBvGIS3pyfz5PfLiAwX6iVE06RGLHXiotm4O50P/9KD6Mhw0rNy6fbkBA5k5TLy\nxp70OuHQm6JUFREhIzuXrFwf8cdQ7/x7Shpb92QEJSntz8whIlyO62pTVcnK9QXtinX22p0MHj6T\nXJ9y3on1eOPqboCrKvp9Yxr/N3Elyan7qRtfhY+u70lWjo9G1WPIzlVqVI1iT3o2Szbt4elxy1iy\nqcjJLAP2xtVdad8gnnNemkaLOtX49m+n4lNlw650mtWqCriu6u/PWMtpLWtZo3QZYwmjovn6r7Bg\nxKHl5z4HPW8ucpcpy7cx4rf1PHFxe+rFR3PGf6aydseBvPUH+7Bf1q0Rq7buZWFKWpHHEYETGybw\n+8Y0jvRR+df5bbnmlKZ8NW8jD3zpesaclFSdz4YVHLH332OX8cXcFD4bdgoPfPE7ydv3MenvfakS\nGcark1exOS2Df5zbljlrdzJx2TYevrAdCTEFE0pWjo+Tn57Ezv1Z3HFWS5rVqsrAzgXrs30+xadK\nRHjxBjPYsS+TC1/9mfiYSMbd0eeY68ivfXcWSzel8cFfetC+QQI5uT7W7TxAbJTrDOF/89gf2/dT\nPTayyLazfZk5vDxxJWe3rcs3CzfRvkE8YxZu5tfkHXnbhAnMfvBsvpy3kafGFjEczVHUqBpFYmwk\nyan7AagbX4WnLj7xkCuKqIgwsnJ81ImrwuCTGrNjfxZDTm6aNyPdxt3pxEVHHNMPABM6ljAqmow9\nsGAkZOyGqU8XXNflGjc+VWzN/NkBi7B6215uHTmfxNhITm1Rixv6NGdzWkbeL8DHvluS1+gI7su+\nbf14Pvy14KQyzWtVJXn7/oBDv7RrIzo3SSQrx8fejGxemuiqO5JqxuYlsKf/dCL7M3N48nv3ZXdl\nj8Z8MmsDABd1asB9A1pTLz6aFVv30rZePFNWbOP6Dwr+O795dVfOPdH1mMnO9THgpWlERYTz+bBT\nqFolsPtTpyzfxnXvz85bnvuvs9m2N5PacVWodZiquk2706kdVyWvDcqnyvPjV/DfaW7mthpVo3jh\n8k58NX9j3k1o1WMjuatfKxrXiGX84i2Mmu3ea7NaVYmODGdLWjrvX9eDExsm8PfRC/h6waE3rx3U\nICGaTWkZDO2VxIe/rnU3wIWH0adlLa7s0YSbP54LcMgNbgdj69uqNk9e0gGADo+Mx6fw7KUncsVJ\nTZixejsjflvPnoxs7unfmo6NEth9IJvE2EhrbK5ALGFUVD4fLPnSzfq3chyMuSt/Aqeew+DcZ4/5\n0Psycxg1az29TqhFw8QY4mMiEBG+mp/CXZ8uzNvu+9tP5YfFWxi3eAvndajHq1NWH3LlcUmXhizZ\nlMbKrfuOOZ7Duad/K9btOMBnc1MOWVezahT3D2hDbJVwbh05H4ChvZJ49CLXcLtpdzo3fzSXExsl\ncGnXRtSoGsXcdbuIjgzjgo4NuPmjOYxfsjXveP+5vBP3f7GIevHRTL/vjLxecnszsnl+/ArGLd5C\nqtdulFQzlo270+ncOJHZa3eV+Ps+nGf+dGLeFR0UvDcBYOueDBK9NowZq3fQul4co+dsoE/L2nRr\nWrBx+edV21m7Yz9X92xiCaESsYRRWSz8FL66KX/5tnlu/o0S/M+e61NuHzWf6rGRBb6I/B3sOvzG\nlDXERIVzY5/m/G96Ms+MW054mNDrhJrUqlblqN0tW9apRtOasUxcti2g2F6/qitfzd+YN/fy4Vx7\nSlP2Zebw5bzDv/7zl3Xk0W+XsD8rl/YN4g+p129bP56LOzfg5tNP4L7PFzJ6zqEJq7B/nteGf49d\nfkh5yzrVaF67Kiu37iM8TFi97ciJ9aqeTRj52/pDylvVrcaY2/pw1otT2bDT3XQ68e+n06JOtaPG\nZsxBljAqC58PvrsN5n+cX1a1jqueatkP+j8RstAyc3KZtGwbZ7SukzdI48GJae7u14rqVaN4f8Za\n3ry6K3PX7WLaqlQeuqAdmdk+Br7+C50bJ/LkxR24Y9R85q3fTZt6cSzfsrfAa6x+6lwiwsP419e/\n8/HMQ79Qi9rnaNrWj6d/u7q8PKnoEYV7nVCTGWt2FLnuoOjIMD4f1ov2DeIZ+t5sfvI6HFzRvTE9\nmtXg0m6NCmyf61OmrthG7xa18Kly2nNT2e6NxvrUJR24umdTJi/fytx1u1i/M51bTj+BNan76J5U\nnfoJMazaupc3pq6hRZ1q/O2M8j9vtCldljAqm/Rd8N/TYXehSexjasDQMVC3fWjiKsTnU35N3kH3\npOpH7D2UlePu8D04eOPBz+i0Vdv587uzADefwS8PnAm4KqIXflzJxt3pREWEcXKzGnRomEDb+vFM\nW5nKY98tzRv2JSo8jCqRYezNyGH0zadQrUoEH81cxyezXMJ5cVAnqlaJ4OaP5ubF07x21bwG4YPu\nPLslCzbsJiYynH+c25YmNWO54r+/8tsfO3ni4g5cc3JTwN35vGHXATo0TAj4PC3dtIetezM4rWXt\nvHNgTLCUmYQhIgOAl4Fw4G1VfaaIbfoCLwGRwHZVPT3QfQurtAkDICMNMvfClsXw6dX5bRsx1eHW\nOSBhEFv+ZwlLz8rl9SmrGdChXsBfwtv3ZTJq1nra1IunYfUYYiLDSUvPplPjRMD9wn/rpzXs2p/F\nA+e2QUT46Ne1ZOb4iI4M58+9ksjIzmXBht2s2LKXJjViOaNNnUNeZ+PudJZu2sPZbetYG4ApN8pE\nwhCRcGAl0A9IAWYDV6rqUr9tEoEZwABVXS8idVR1WyD7FqVSJwx/2Rnwy8vw07Og3jg9EdFwxcdw\nwpkQVnp3sxtjyrayMuNeD2C1qiarahYwChhYaJurgC9VdT2Aqm4rxr7mcCKjoe/9bpj0g3IyYMRl\n8FYfmPkm7Dx08hljjDmSYCaMhsAGv+UUr8xfK6C6iEwVkbkicm0x9gVARG4SkTkiMic19eh3M1cq\nrc6Bc5+HOn5tGNuWwA8PwIcXuTnIjTEmQKGecS8C6AacBcQAv4rIzOIcQFWHA8PBVUmVeITlmQj0\nvMk9dq2D7HSY8BCs+hF2r4eP/wRtzofIWOh8NYSH+uNgjCnLgvkNsRFo7LfcyCvzlwLsUNX9wH4R\nmQZ08sqPtq8pjuqu1w5XfwarJ7mpYddOdw+A3z9zDee5WTB0LFS1iZqMMQUFs0pqNtBSRJqJSBQw\nGPi20DYVJTwgAAAgAElEQVTfAKeKSISIxAI9gWUB7muOVYuz4PYFbiyqg9ZOhy2LIHU5rJ4QutiM\nMWVW0BKGquYAtwLjcUlgtKouEZFhIjLM22YZ8AOwCJiF6z67+HD7BivWSimhoRu48OovDl234bfS\nj8cYU+bZjXuV3Z7N8GIb97zbdTD3PYhvCDdOhiVfQf1O0LTXkY9hjCm3itOt1lo5K7u4evnPew5z\nSWLPRnihdX75mQ9Bt6FQ9dC5LYwxlUcw2zBMeSACN0+Da76GOm1co3i9ju7O8IMmP+Hu39i1NmRh\nGmNCz6qkTNH2bYPUFTDvQ0ieAvu9e1yu+BhaDYBwmyTHmIqgrNzpbcqzanWgWR+49H/uquOgT4fA\n041g2Xdu2eeDn1+C5J9CE6cxptRYG4Y5ugZd4F/b4PUerloqJ8MljqQ+0LQ3/OSNC/nI7hKdi8MY\nU7bYFYYJTEQVuGES/G0WVKvrytZOz08WYG0cxlRwljBM4KrWgtqt4bL34KQbIL7gREBMfAR8uaGJ\nzRgTdJYwTPEl9YbzX4CbpsLpD0DL/q586Tcw7Xn3fNN82LslVBEaY4LAekmZkrFoNHx5o3tevRns\n+gManQTXT7B2DWPKMOslZUpfx0Ew8A038u0ub66NlNnwWCLsWBPa2IwxJcIShik5Xa52Q4rEFroj\nfNrzbhbACnQ1a0xlZAnDlKw6beGvM+GMB/PLFn4CT9V1Vxvf3m6Jw5hyyhKGKXnVasNp98JdS6Bh\nt4Lr5n3g5t6wpGFMuWMJwwSHCCQ0gh435ZeFefeJfnkjDO8LuTkhCc0Yc2zsTm8TXB2vgMgYaNLL\n3ccxcpCbInbzApj/EXS/LtQRGmMCZFcYJrhEoN1AV00lAoNHwoBn3boxd8LHl8KBnW45fbdVVRlT\nhlnCMKUrPNLN9NfNu7JYPRE+uRImPwnPJsH4f4Y0PGPM4dmNeyZ0Ni2AEZfD/m0Fy2u2dHN0RMWG\nJi5jKhG7cc+UDw06wxUfQUITqBIPtbxZ/nascj2pjDFlijV6m9BqcjLcucgNWnhgB3x0MWxbCt/d\nDgkNocXZoY7QGOMJ6hWGiAwQkRUislpEHihifV8RSRORBd7jYb91d4nIEhFZLCKfiEh0MGM1ISQC\n4REQV9fdKd6ohyv/9Bo3OZMNLWJMmRC0hCEi4cDrwLlAO+BKEWlXxKbTVbWz93jc27chcDvQXVU7\nAOHA4GDFasqQyBgYOgaq1obsA27I9Fe7wk/Pu9n9crNDHaExlVYwrzB6AKtVNVlVs4BRwMBi7B8B\nxIhIBBALbApCjKYsiqgCF/yfG+32oClPwuPV4dlmsDM5dLEZU4kFM2E0BDb4Lad4ZYX1EpFFIjJO\nRNoDqOpG4D/AemAzkKaqPxb1IiJyk4jMEZE5qampJfsOTOi0vRBumAhDvixYnrUXXukC62aEJi5j\nKrFQ95KaBzRR1Y7Aq8DXACJSHXc10gxoAFQVkSFFHUBVh6tqd1XtXrt27VIK25SaFme5ucL/9Lbr\nbnvQe+fCmL9b+4YxpSiYCWMj0NhvuZFXlkdV96jqPu/5WCBSRGoBZwN/qGqqqmYDXwK9ghirKctE\noOPlbj7xDpfml895x7Vv/Piv/LvFjTFBE8yEMRtoKSLNRCQK12j9rf8GIlJPxE3HJiI9vHh24Kqi\nThaRWG/9WcCyIMZqyoOwMLjsXWh9XsHyGa/Cm70hY09o4jKmkghawlDVHOBWYDzuy360qi4RkWEi\nMszb7DJgsYgsBF4BBqvzG/A5rsrqdy/O4cGK1ZQz578A5z4PD26BU+9yZXs3wXPN4L3z3GRNxpgS\nZ0ODmPJv0wL44CLITHPLJ93gBjjcNM9N6FQlLrTxGVOG2dAgpnJp0BnuWgwdLnPLs9+G13vAO/3g\nq2FH3tcYEzBLGKZiiI6HAU/nL+/0ek8tHwMLP3VVVet/C01sxlQQljBMxVGtDjy8C5qfUbD8q5tg\n3S8w5anQxGVMBWEJw1QsYWFuBNwL/g+uGAEN/apmt/wOKXMgc2/o4jOmHLNGb1Ox+XywJwXe6gMZ\nu11Z1TpwyZs2Eq4xWKO3MfnCwiCxCXS9Jr9s/zY3NeyWxTYlrDHFcNSEISJ3iEi8OO+IyDwR6V8a\nwRlTYs5+HM77T8Eqqrd6wwcXWhWVMQEK5ArjL6q6B+gPVAeuAZ4JalTGlLSwMOhxI9w4CQa+kV++\ndjo819zdKb72l9DFZ0w5EEjCEO/vecBHqrrEr8yY8qf1uVA9CcK8CSdzs2DrYvhkMOyzEY+NOZxA\nEsZcEfkRlzDGi0gc4AtuWMYEUWwNuGMh/GMjJDaFhMYQnQiZe+C3N0MdnTFlViBzel8PdAaSVfWA\niNQArgtuWMaUgshouNXrVbdpPrzbH355BU440/Wkmv8h9L4LqtYMbZzGlBGBJIxTgAWqut+bk6Ir\n8HJwwzKmlEREub9NekLPW9wVxohBkJMBmusmarphkhti3ZhKLpAqqTeBAyLSCbgbWAN8GNSojAmF\nc56CjldA9n6XLAA2znXjUe3fEdrYjCkDAkkYOeru7hsIvKaqrwM2/KepeMLC4eI34YSzCpYvGgUj\nL4eUubBsDGSnhyY+Y0IskCqpvSLyD1x32j4iEgZEBjcsY0IkLByu+NjN5hdXH7643pVvnAtvn+me\n12kHN06GyJjQxWlMCARyhXEFkIm7H2MLbqrV54MalTGhFBULvW6DEy+D68ZBXIOC67cthVUTQhOb\nMSF01IThJYkRQIKIXABkqKq1YZjKoWkvuGECDP4Eho6F0+515Ys+DW1cxoRAIEODDAJmAZcDg4Df\nROSyYAdmTJmR0AjanAdJvaHrnyEs0s2z8VR9+HAgrJkMcz+wcalMhXfU0Wq9+bb7qeo2b7k2MFFV\nO5VCfMVio9WaUrFoNHxzK+RmFixvfDIM+hDi6oYmLmOOQUmPVht2MFl4dgS4nzEVU8dBcF8y9Lmn\nYPmGmfBCK5dQjKmAAvni/0FExovIUBEZCnwPjA1uWMaUcVWqwWn3FL3u61sgc1/pxmNMKQik0fte\nYDjQ0XsMV9X7Azm4iAwQkRUislpEHihifV8RSRORBd7jYb91iSLyuYgsF5FlInJK4G/LmFIQGQN9\n7nbPrxoNw7zRbn05sGle6OIyJkiCNuOeiIQDK4F+QAowG7hSVZf6bdMXuEdVLyhi/w+A6ar6tohE\nAbGquvtIr2ltGKbU+XyQtt6Nfgsw9l6YNdw9v22eazDP3Asx1d09HsaUMcVpwzjsjXsishcoKpsI\noKoaf5Rj9wBWq2qyd7xRuLvFlx5xL7dtAnAaMBT3YllA1tH2M6bUhYXlJwuAJifnJ4xXu0J4lBs+\nPb4hDPkS6rQJSZjGlITDVkmpapyqxhfxiAsgWQA0BDb4Lad4ZYX1EpFFIjJORNp7Zc2AVOA9EZkv\nIm+LSNWiXkREbhKROSIyJzXV5jIwIdb2Img3MH851/uds2cjjLkTVk2Encmhic2Y4xTq3k7zgCaq\n2hF4FfjaK4/AjYr7pqp2AfYDh7SBAKjqcFXtrqrda9euXRoxG3N44ZFw2fvuigLc2FT3r4PIqrD+\nVxhxqRsN1+7ZMOVQMBPGRqCx33IjryyPqu5R1X3e87FApIjUwl2NpKjqb96mn+MSiDFlX1iYq366\n9hvofBXEJELnK/PX71jlhhcxppwJZsKYDbQUkWZeo/Vg4Fv/DUSknoibaEBEenjx7PCGI9kgIq29\nTc8igLYPY8qMOm2ged/85f5PwZ+/gw6XuuXFX8KONZCdEYrojDkmgYxWe0xUNUdEbgXGA+HAu6q6\nRESGeevfAi4DbhGRHCAdGKz53bZuA0Z4ySYZm+XPlGeR0dDsNPd88Rcw/T/uEd8IhnwB+7a6cavC\nbSBoU3YFMjRIUb2l0oA5wN0He0GVBdat1pR5qvBmb9i2pOj15z4HPW8u3ZhMpVYi3Wr9vIRrUxiJ\n61I7GDgB12D9LtD32MI0phISgStHwrpf3d3inw4puH7cfdCyP9RoFpr4jDmCQBLGRYUGGhwuIgtU\n9X4R+WewAjOmwqqe5B7+w4e0vRCWfeeez34bNi+EJqfAmQ+GIkJjihRIo/cBERkkImHeYxBwsKXO\n+gYac6yqVIPed0KLfvCnt13PKoBfX4O102Hac7D2F+uCa8qMQBLG1bjpWbd5j2uAISISA9waxNiM\nqfj6PQZDPneN4s37QkyNguvfPw+m/DsUkRlziKNWSXmN2hceZvXPJRuOMZVYWDj0vgMmPlKwfNrz\nkNAQcrPhpBtcO4gxIXDUhCEijXB3Yff2iqYDd6hqSjADM6ZS6n0HdL8OwiJg/ghY8T0kT4Xv7nDr\nRVzSMCYEAmn0fg/XQ+pyb3mIV9YvWEEZU2mJQHSCe97zJmjQ2SWMg76/G3b+AfVOhKQ+7srDmFIS\nSBtGbVV9T1VzvMf7gA3aZExpaNwD+v7DXXHE1Xdlv74GX90MHxwyK4AxQRVIwtghIkNEJNx7DMFN\n02qMKQ19H4AHt8Dt86HuifnlO5Phnf4w6mrYMCt08ZlKI5CE8RdgELAF2IwbzmNoEGMyxhQWHulm\n+Lviw4LlG36D5WPgvXNh0hOhic1UGoH0kloHXORfJiJ34u4AN8aUphrN3UCGAImNYeZbsH6GmxZ2\n+n+g258hsUloYzQV1jFN0Soi61W1zH0qbSwpUympwkeXQPIUt3zLDKjb/sj7GOMpzlhSxzq8uXUE\nN6asEIHuf8lf/u/p8NKJbgh1Y0rQsSYMG6vAmLKk7YVueJHwKPBlw+718M2tMOM1+ORK2LrUzb/h\nyw11pKYcO2yV1GGGNQd3dRGjqkGbS+NYWZWUqfSyM2Ddz/DDP2D7ykPXn/0YnHpn6cdlyqwSqZJS\n1ThVjS/iEVcWk4UxBjcmVYuz4arR7mqjsCVflX5MpsII5hStxphQqdEMbpgEw36Gh3fC+S+68s0L\n4MeHbARcc0wsYRhTUdXv6IYQCQuHk66H2m1d+YxX4IML4Y/psGoCZO0PbZym3LCEYUxlcdbD+c/X\nTndDi4y4DCY9HrqYTLliCcOYyqLNefBoGgz7BXrdll8++52Cs/8ZcxhBTRgiMkBEVojIahF5oIj1\nfUUkTUQWeI+HC60PF5H5IjImmHEaU6nU6wD9n4S/zYZarV033Kcbwsw3YduyUEdnyrCgJQwRCQde\nB84F2gFXiki7IjadrqqdvUfha+M7APsEGxMMtVvBJW/mL//wALxxMqTMgf073N3j1qvK+AnmFUYP\nYLWqJqtqFjAKGBjozt7ETecDbwcpPmNMw24w9PuCZW+fBc83hzWT4bOhIQnLlE3BTBgNgQ1+yyle\nWWG9RGSRiIwTEf8BcF4C7gN8R3oREblJROaIyJzU1NTjDtqYSifpVLh5mptTvCi+I/4XNJVIqBu9\n5wFNVLUjbhrYrwFE5AJgm6rOPdoBVHW4qnZX1e61a9u8TsYck/qd4Npv3LwbhaeA/f7vsPJHyMmE\ntI2QkxWaGE3IBTNhbAQa+y038sryqOoeVd3nPR8LRIpILdz84ReJyFpcVdaZIvJxEGM1xoCbc2PA\ns9Dzlvyyue/ByMvhrT7wUgf4/q7QxWdCKpgJYzbQUkSaiUgUMBj41n8DEaknIuI97+HFs0NV/6Gq\njVQ1ydtvsqoOCWKsxpiDwiPg3GcK3rcBsH0FqA/mf+waxU2lE7SEoao5wK3AeFxPp9GqukREhonI\nMG+zy4DFIrIQeAUYrMcyQYcxpuT1vgvuWgL3r4NuQwuu+320G+jQ/rtWKsc0gVJZZaPVGhMk62a4\naWD9STjE1YPrJ0BCUf1ZTHlQGhMoGWMqk8YnwwlnQot+EFvLlWku7NkIn18HaSmhjc+UChum3Bhz\ndGFhcI13E1/KHEieCns2wZx3YMNv8P75MORLWDgKul8H8Q1CGq4JDquSMsYcmx1r4NWuRa8bOhaS\nepduPOaYWJWUMSb4ajSHLofpvPj+eTagYQVkCcMYc2xEYODrbgTcfk8cun79TOtFVcFYwjDGHL8W\nZx9aNuJSeLEdrP2l9OMxQWEJwxhz/Oq2g7+Mh65/Lli+dxN8MhjGPwhj74WtS0MTnykR1uhtjClZ\nqjD1aZj1P0jfBfh9x8TWgut/hJonhCw8U5A1ehtjQkcEzvgn3JcM966GNhdAtXpu3YHtrmfVrrUh\nDdEcG0sYxpjgEIGqtWDwCLhnBZz3n/x1iz6DNVPg19fd/RymXLAb94wxpaPHjZDQyLVpTHkyv3zN\nZBjyRejiMgGzKwxjTOlp0c/NI+5v9URYMBJ2byh6H1NmWMIwxpSe8Ag473mIqgZV4iGmuiv/+hZ3\ns9/eLbBhlpusyZQ51kvKGFP6fD43t8byMTDuPti3teD6zlfDxW+EJrZKxnpJGWPKtrAwd7XR/mK4\nZyVc/YUbLv2g5d+DLzd08ZkiWcIwxoRey7PhrzNh0IeQ0BgydsOoq2D1JJjwiJusyYSc9ZIyxpQN\ntVu5R/JUmPMurPzBPcC1eZx+b0jDM3aFYYwpa858CM56pGDZlCddEjEhZQnDGFO2xNaAPn+Hk24s\nWD7mLhh9LWxeaHeKh4hVSRljyqZznoL6HaFlf/juDlc9tfQb90Dg2m+g+emhjrJSCeoVhogMEJEV\nIrJaRB4oYn1fEUkTkQXe42GvvLGITBGRpSKyRETuCGacxpgyKKIKdL0W4uq5xvCr/e8GV3fFoWpz\nbpSioF1hiEg48DrQD0gBZovIt6paeHzj6ap6QaGyHOBuVZ0nInHAXBGZUMS+xpjKIKKK60nVpBes\nn+HKdq6BZ5pAdAIMm55/E6AJmmBeYfQAVqtqsqpmAaOAgYHsqKqbVXWe93wvsAxoGLRIjTHlw4Uv\nQcPuUK+jW87cA2kb4MOL4aUT4cubIXVFaGOswIKZMBoC/oPDpFD0l34vEVkkIuNEpH3hlSKSBHQB\nfivqRUTkJhGZIyJzUlNTjz9qY0zZVbs13DjJjYBbs2V++eYFsHs9LBoF39wauvgquFA3es8Dmqjq\nPhE5D/gayPsUiEg14AvgTlXdU9QBVHU4MBzc0CDBD9kYE3KJTeC2OZC1393gFxHjhhpZNR5SZsGe\nzbB3M9TtABFRoY62wghmwtgINPZbbuSV5fFPAqo6VkTeEJFaqrpdRCJxyWKEqn4ZxDiNMeVVVFXX\nW+qgkYNh5Th4sY1bPu1eOPNfoYmtAgpmldRsoKWINBORKGAw8K3/BiJST0TEe97Di2eHV/YOsExV\nXwxijMaYiqTXbYDkL097HjL3wvKxkJsTsrAqiqAlDFXNAW4FxuMarUer6hIRGSYiw7zNLgMWi8hC\n4BVgsLrhc3sD1wBn+nW5PS9YsRpjKoik3nDRKxDXIL/shbYw6kqXPNJSrBvucbDhzY0xFdOXN8Gi\nTw8tP+ffcMrfSj+eMsqGNzfGmNPuLThk+kFz3oMDO0s/ngog1L2kjDEmOGq1hGu/dlVQddq6brdv\nnwU7VsELreHuFe5mP5GjH8sAljCMMRVZs9Pyn1erA83PgOQpkJsFzzVzbR03ToLIGLtTPABWJWWM\nqTwuehV63Z6/vHcTvNgW/tPKjYJrjsgShjGm8khsDP2fgDqFBpXIzYJfXw9NTOWIVUkZYyqfq0bB\n3A9g9zr4/TNXtmIcbFoAWxZBrdZQswVUrRnaOMsYSxjGmMonsQmc9RDkZEHLc2D+h/DHNBjuP7+G\nwKVvQ/s/QZhVxoBVSRljKrOIKOh4OVw1GpqeWmilwhfXw/d/D0loZZElDGOMiYyBa76EoWOhTaHp\neea+B2smQ/out+zzwY41pR9jGWAJwxhjwE3SlNQbzn8BOl4Bw35x3XABProEPr7UPf/pWXi1Kyz7\nLnSxhoglDGOM8RdXD/40HOp1gLMedhM2AWycC79/Dj8945anV75xUS1hGGPM4TTs6m7sa3exW/7i\n+vx1vso3+q0lDGOMOZouQ/KfV6vn/m5Z5K44svaHJqYQsIRhjDFH07IfXD8RLn4L7lqSP6f4F9fD\ny50rTSO4DW9ujDHFlbYR5n0Iv4+Gncmu7PL3YftqN+94u4tCGl5xFGd4c0sYxhhzrPZsgle6QE5G\nwfKOV8AFL0FUbGjiKgabD8MYY0pDfAO4fgLUbluwfNGnsHBkaGIKIhsaxBhjjkf9jnDjZHinH2xd\nnF+eusLNxTHvQ0jbANtXQrW6cN7zoYv1OFmVlDHGlITsdNi6xE3SdCR/Xw7x9UsnpgBYlZQxxpS2\nyBho1B0eWA8cYRa/TfNLLaSSFtSEISIDRGSFiKwWkQeKWN9XRNJEZIH3eDjQfY0xpkyKTnATNfW5\nG+p3hupJBdeX44QRtDYMEQkHXgf6ASnAbBH5VlWXFtp0uqpecIz7GmNM2dP1Gvf3LO838Lj74be3\n3PNpz7m/ff8BK8bCgR2ujWPbMrjsPTeCbhkVzEbvHsBqVU0GEJFRwEAgkC/949nXGGPKlv5PQa/b\n4P+8mf6mPZefOPxt+A2a9Snd2IohmFVSDYENfsspXllhvURkkYiME5GD8yYGui8icpOIzBGROamp\nqSURtzHGlKzwCEho5K4qjuSDC8r0KLihbvSeBzRR1Y7Aq8DXxT2Aqg5X1e6q2r127dolHqAxxpSY\n0+6DP72dv3z7Auh+fcFtPh1CWRXMKqmNQGO/5UZeWR5V3eP3fKyIvCEitQLZ1xhjyp2wMDjxMti3\nBWqcADWawYBnICIaZr6ev13WAVg7HVqcDWHhoYu3kGBeYcwGWopIMxGJAgYD3/pvICL1RES85z28\neHYEsq8xxpRLIq49o815bjkiCk75a8Ft/l0fRg6CSY+XfnxHELSEoao5wK3AeGAZMFpVl4jIMBEZ\n5m12GbBYRBYCrwCD1Sly32DFaowxIZXQCG6YfGj5Ly/B/u3uecYeWPAJ5GaXbmx+7E5vY4wpKxaM\nhK9vKVh28VvQ+UrXtrHsO+hzD5z1UIm9pI1Wa4wx5VVuNsx4xc2xsWCEK6vZAnasds+j4uCGibB6\nApz81+Nu4yhOwrDBB40xpiwJj3R3ie9a66440PxkAZC9H97o6Z5HVYXufym10ELdrdYYY0xRqifB\n4BHQ5BSoeyIk9YHwKqC+/G02zC7VkOwKwxhjyqo257vHQRl74J3+kLrMLW9e6IZQlyMMdliC7ArD\nGGPKi+h4uHo0dLrSLW9bAo8lwpJi3/N8TCxhGGNMeZLYBC55CwY8m1/2zd/cfOJBZgnDGGPKo543\nw9Cxro2jau1D5xUPAmvDMMaY8kgEknrD1Z+5dozo+KC/pCUMY4wpz6rEldpLWZWUMcaYgFjCMMYY\nExBLGMYYYwJiCcMYY0xALGEYY4wJiCUMY4wxAbGEYYwxJiAVaj4MEUkF1h3j7rWA7SUYTkVi5+bI\n7Pwcnp2bIysL56epqtYOZMMKlTCOh4jMCXQSkcrGzs2R2fk5PDs3R1bezo9VSRljjAmIJQxjjDEB\nsYSRb3ioAyjD7NwcmZ2fw7Nzc2Tl6vxYG4YxxpiA2BWGMcaYgFjCMMYYE5BKnzBEZICIrBCR1SLy\nQKjjCQUReVdEtonIYr+yGiIyQURWeX+r+637h3e+VojIOaGJunSISGMRmSIiS0VkiYjc4ZVX+vMj\nItEiMktEFnrn5jGvvNKfm4NEJFxE5ovIGG+5XJ+bSp0wRCQceB04F2gHXCki7UIbVUi8DwwoVPYA\nMElVWwKTvGW88zMYaO/t84Z3HiuqHOBuVW0HnAz8zTsHdn4gEzhTVTsBnYEBInIydm783QEs81su\n1+emUicMoAewWlWTVTULGAUMDHFMpU5VpwE7CxUPBD7wnn8AXOxXPkpVM1X1D2A17jxWSKq6WVXn\nec/34v7zN8TOD+rs8xYjvYdi5wYAEWkEnA+87Vdcrs9NZU8YDYENfsspXpmBuqq62Xu+BajrPa+0\n50xEkoAuwG/Y+QHyqlwWANuACapq5ybfS8B9gM+vrFyfm8qeMEwA1PW9rtT9r0WkGvAFcKeq7vFf\nV5nPj6rmqmpnoBHQQ0Q6FFpfKc+NiFwAbFPVuYfbpjyem8qeMDYCjf2WG3llBraKSH0A7+82r7zS\nnTMRicQlixGq+qVXbOfHj6ruBqbg6t/t3EBv4CIRWYur6j5TRD6mnJ+byp4wZgMtRaSZiEThGp2+\nDXFMZcW3wJ+9538GvvErHywiVUSkGdASmBWC+EqFiAjwDrBMVV/0W1Xpz4+I1BaRRO95DNAPWI6d\nG1T1H6raSFWTcN8rk1V1COX83ESEOoBQUtUcEbkVGA+EA++q6pIQh1XqROQToC9QS0RSgEeAZ4DR\nInI9bsj4QQCqukRERgNLcT2I/qaquSEJvHT0Bq4Bfvfq6gH+iZ0fgPrAB15vnjBgtKqOEZFfsXNz\nOOX6c2NDgxhjjAlIZa+SMsYYEyBLGMYYYwJiCcMYY0xALGEYY4wJiCUMY4z5//bumDWKKArD8Psh\nFgFBREEEkS1MJVqIlX/DIoiVpYVYBf+AlWXURguxsLYVIYII2mrsJV2EpFAQJMhyLOZGBlGcDbO6\nkPeBYe+ehWGmOnPn7j1Hg5gwpBkkmSZ51ztGq3CcZNKvGCwtmgO9D0Pah2+tFIZ04DjDkEaQZDPJ\n3SQfWo+Isy0+SfIyyUaS9SRnWvxkkmetl8T7JJfbqQ4ledT6S7xoO6ilhWDCkGaz9MsrqZXeb1+q\n6jxwn65SKcA94ElVXQCeAmstvga8ar0kLgJ7FQaWgQdVdQ74DFyZ8/1Ig7nTW5pBkq9VdeQ38U26\nZkIfW7HCT1V1PMkOcKqqvrf4VlWdSLINnK6q3d45JnQlwpfb99vA4aq6M/87k/7OGYY0nvrDeBa7\nvfEU1xm1QEwY0nhWep9v2/gNXbVSgGvA6zZeB27AzyZER//VRUr75dOLNJulXtVagOdVtffX2mNJ\nNuhmCVdb7CbwOMkqsA1cb/FbwMNWtXRKlzy2kBaYaxjSCNoaxqWq2vnf1yLNi6+kJEmDOMOQJA3i\nDL7HHkAAAAAdSURBVEOSNIgJQ5I0iAlDkjSICUOSNIgJQ5I0yA9SLZD9JyrMbwAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28568985668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#validation vs train loss\n",
    "epochs = range(0,len(hist_list[2][\"val_loss\"]))\n",
    "plt.plot(epochs, hist_list[2][\"val_loss\"], lw=2, label='Validation')\n",
    "plt.plot(epochs, hist_list[2][\"loss\"], lw=2, label='Train')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Log loss')\n",
    "plt.title('Figure 5 - Neural Network Fit Path')\n",
    "plt.savefig(\"reports/figures/nn_loss_path.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 7 - Evaluate on quotes\n",
    "Let us see what the model thinks of some of the top quotes from https://www.brainyquote.com/top_100_quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unfunny_quotes = [\"Find a place inside where there's joy, and the joy will burn out the pain.\",\n",
    "          \"Try to be a rainbow in someone's cloud.\",\n",
    "          \"It is during our darkest moments that we must focus to see the light.\",\n",
    "         \"Keep love in your heart. A life without it is like a sunless garden when the flowers are dead.\",\n",
    "         \"The best and most beautiful things in the world cannot be seen or even touched - they must be felt with the heart.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now need to convert to seqs\n",
    "#load neuralnetowrk vocab\n",
    "vocab = joblib.load(\"data/interim/nn_vocab.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_seqs(texts, vocab, max_len):\n",
    "    tokens = []\n",
    "    for text in texts:\n",
    "        tokens.append(wordpunct_tokenize(text.lower()))\n",
    "    seqs = np.zeros((len(tokens), max_len), dtype=np.int32)\n",
    "    \n",
    "    for i, text in enumerate(tokens):\n",
    "        for j, word in enumerate(text):\n",
    "            if j >= max_len:\n",
    "                break\n",
    "            #need to increment by 1 since first row in embedding matrix is reserved\n",
    "            #if word doesn't exist, it will return -1, whicll be incrmented to 1\n",
    "            seqs[i,j] = vocab.get(word, -1) + 2\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9641,  1112, 18217, ...,     0,     0,     0],\n",
       "       [25191, 24674,  2986, ...,     0,     0,     0],\n",
       "       [13207, 13171,  8219, ...,     0,     0,     0],\n",
       "       [13638, 14662, 12592, ...,     0,     0,     0],\n",
       "       [24349,  3225,  1888, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make seqss\n",
    "unfunny_seqs = create_seqs(unfunny_quotes, vocab, 300)\n",
    "unfunny_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.28092721,  0.29726008,  0.5709604 ,  0.37078726,  0.19481923], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now predict\n",
    "unfunny_quote_probs = np.squeeze(model50_trained.predict(unfunny_seqs, batch_size = 2000))\n",
    "unfunny_quote_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.280927</td>\n",
       "      <td>Find a place inside where there's joy, and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.297260</td>\n",
       "      <td>Try to be a rainbow in someone's cloud.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.570960</td>\n",
       "      <td>It is during our darkest moments that we must ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.370787</td>\n",
       "      <td>Keep love in your heart. A life without it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194819</td>\n",
       "      <td>The best and most beautiful things in the worl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction                                               text\n",
       "0    0.280927  Find a place inside where there's joy, and the...\n",
       "1    0.297260            Try to be a rainbow in someone's cloud.\n",
       "2    0.570960  It is during our darkest moments that we must ...\n",
       "3    0.370787  Keep love in your heart. A life without it is ...\n",
       "4    0.194819  The best and most beautiful things in the worl..."
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfunny_results = pd.DataFrame({\"text\": unfunny_quotes, \"prediction\": unfunny_quote_probs})\n",
    "unfunny_results.to_csv(\"data/processed/unfunny_quotes.csv\")\n",
    "unfunny_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now somme funny quotes from http://www.coolfunnyquotes.com/category/top-100-funny-quotes/\n",
    "funny_quotes = [\"If I won the award for laziness, I would send somebody to pick it up for me.\",\n",
    "          \"Me and my bed are perfect for each other, but my alarm clock keeps trying to break us up.\",\n",
    "         \"If we shouldn't eat at night, why is there a light in the fridge?\",\n",
    "         \"Sometimes I wish I was an octopus, so I could slap eight people at once.\",\n",
    "         \"Some people are like clouds. When they go away, it's a brighter day.\"]\n",
    "funny_seqs = create_seqs(funny_quotes, vocab, 300)\n",
    "funny_seqs\n",
    "#now predict\n",
    "funny_quote_probs = np.squeeze(model50_trained.predict(funny_seqs, batch_size = 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.762339</td>\n",
       "      <td>If I won the award for laziness, I would send ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.698758</td>\n",
       "      <td>Me and my bed are perfect for each other, but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.779744</td>\n",
       "      <td>If we shouldn't eat at night, why is there a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.765071</td>\n",
       "      <td>Sometimes I wish I was an octopus, so I could ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.765436</td>\n",
       "      <td>Some people are like clouds. When they go away...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction                                               text\n",
       "0    0.762339  If I won the award for laziness, I would send ...\n",
       "1    0.698758  Me and my bed are perfect for each other, but ...\n",
       "2    0.779744  If we shouldn't eat at night, why is there a l...\n",
       "3    0.765071  Sometimes I wish I was an octopus, so I could ...\n",
       "4    0.765436  Some people are like clouds. When they go away..."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funny_quotes = pd.DataFrame({\"text\": funny_quotes, \"prediction\": funny_quote_probs})\n",
    "funny_quotes.to_csv(\"data/processed/funny_quotes.csv\")\n",
    "funny_quotes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
