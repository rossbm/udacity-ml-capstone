{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook train four different neural network models. They are all pretty similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.1 Load Packages and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.externals import joblib\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.join(os.getcwd(), os.pardir)\n",
    "os.chdir(PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import src.neural_networks as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "nn = reload(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2- Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and validation neural network data sets if they are present, otherwise raise an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load sequnces\n",
    "try:\n",
    "    train = joblib.load('data/processed/train_nn.pkl')\n",
    "    valid = joblib.load('data/processed/valid_nn.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load embedding matrix of 50 dimensions\n",
    "try:\n",
    "    embedding_matrix50 = joblib.load('data/interim/embeddings50.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load embedding matrix of 300 dimensions\n",
    "try:\n",
    "    embedding_matrix300 = joblib.load('data/interim/embeddings300.pkl')\n",
    "except FileNotFoundError:\n",
    "    #need to run earlier notebook if files not present\n",
    "    raise Exception(\"Files not found. Run Notebook 4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these arguments will be the same when training both models\n",
    "run_args = {\"train\":(train[\"seqs\"],train[\"labels\"]),\n",
    "            \"valid\":(valid[\"seqs\"],valid[\"labels\"])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Train 50d model with fixed embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "joke_seq (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 50)           1369800   \n",
      "_________________________________________________________________\n",
      "mask_paddings (Masking)      (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "drop_words (SpatialDropout1D (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "mask_dropped_words (Masking) (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "reccurrent_layer (LSTM)      (None, 150)               120600    \n",
      "_________________________________________________________________\n",
      "drop_dense (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_sigmoid (Dense)        (None, 75)                11325     \n",
      "_________________________________________________________________\n",
      "avg_pred (GlobalAverage)     (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,501,725\n",
      "Trainable params: 131,925\n",
      "Non-trainable params: 1,369,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM, average final\n",
    "model50_fixed = nn.create_model(embedding_matrix=embedding_matrix50, n_hidden=150, train_embed=False)\n",
    "model50_fixed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output model as svg plot\n",
    "plot_model(model50_fixed, to_file='reports/figures/nn_50d.svg', show_shapes =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171945 samples, validate on 24564 samples\n",
      "Epoch 1/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6712 - acc: 0.5800Epoch 00001: val_loss improved from inf to 0.66251, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 136s 789us/step - loss: 0.6713 - acc: 0.5802 - val_loss: 0.6625 - val_acc: 0.5970\n",
      "Epoch 2/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6613 - acc: 0.5965Epoch 00002: val_loss improved from 0.66251 to 0.65785, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6613 - acc: 0.5963 - val_loss: 0.6578 - val_acc: 0.6029\n",
      "Epoch 3/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6602 - acc: 0.5954Epoch 00003: val_loss improved from 0.65785 to 0.65493, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6601 - acc: 0.5956 - val_loss: 0.6549 - val_acc: 0.6074\n",
      "Epoch 4/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6562 - acc: 0.6028Epoch 00004: val_loss improved from 0.65493 to 0.64932, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6562 - acc: 0.6027 - val_loss: 0.6493 - val_acc: 0.6087\n",
      "Epoch 5/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6548 - acc: 0.6039Epoch 00005: val_loss improved from 0.64932 to 0.64850, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6548 - acc: 0.6038 - val_loss: 0.6485 - val_acc: 0.6109\n",
      "Epoch 6/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6521 - acc: 0.6076Epoch 00006: val_loss improved from 0.64850 to 0.64663, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6519 - acc: 0.6077 - val_loss: 0.6466 - val_acc: 0.6163\n",
      "Epoch 7/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6507 - acc: 0.6067Epoch 00007: val_loss improved from 0.64663 to 0.64398, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6508 - acc: 0.6067 - val_loss: 0.6440 - val_acc: 0.6112\n",
      "Epoch 8/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6508 - acc: 0.6081Epoch 00008: val_loss improved from 0.64398 to 0.64322, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6507 - acc: 0.6081 - val_loss: 0.6432 - val_acc: 0.6170\n",
      "Epoch 9/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6491 - acc: 0.6123Epoch 00009: val_loss improved from 0.64322 to 0.64216, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6491 - acc: 0.6123 - val_loss: 0.6422 - val_acc: 0.6221\n",
      "Epoch 10/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6487 - acc: 0.6118Epoch 00010: val_loss improved from 0.64216 to 0.64141, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6487 - acc: 0.6119 - val_loss: 0.6414 - val_acc: 0.6238\n",
      "Epoch 11/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6478 - acc: 0.6128Epoch 00011: val_loss improved from 0.64141 to 0.64034, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6478 - acc: 0.6127 - val_loss: 0.6403 - val_acc: 0.6270\n",
      "Epoch 12/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6466 - acc: 0.6153Epoch 00012: val_loss did not improve\n",
      "171945/171945 [==============================] - 91s 526us/step - loss: 0.6466 - acc: 0.6153 - val_loss: 0.6408 - val_acc: 0.6223\n",
      "Epoch 13/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6460 - acc: 0.6170Epoch 00013: val_loss improved from 0.64034 to 0.63944, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6460 - acc: 0.6171 - val_loss: 0.6394 - val_acc: 0.6288\n",
      "Epoch 14/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6452 - acc: 0.6180Epoch 00014: val_loss improved from 0.63944 to 0.63894, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 91s 527us/step - loss: 0.6451 - acc: 0.6180 - val_loss: 0.6389 - val_acc: 0.6271\n",
      "Epoch 15/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6444 - acc: 0.6185Epoch 00015: val_loss improved from 0.63894 to 0.63698, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6444 - acc: 0.6185 - val_loss: 0.6370 - val_acc: 0.6293\n",
      "Epoch 16/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6441 - acc: 0.6195Epoch 00016: val_loss improved from 0.63698 to 0.63682, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6439 - acc: 0.6197 - val_loss: 0.6368 - val_acc: 0.6310\n",
      "Epoch 17/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6434 - acc: 0.6213Epoch 00017: val_loss improved from 0.63682 to 0.63634, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6434 - acc: 0.6214 - val_loss: 0.6363 - val_acc: 0.6280\n",
      "Epoch 18/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6428 - acc: 0.6210Epoch 00018: val_loss improved from 0.63634 to 0.63618, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 91s 531us/step - loss: 0.6428 - acc: 0.6210 - val_loss: 0.6362 - val_acc: 0.6317\n",
      "Epoch 19/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6423 - acc: 0.6238Epoch 00019: val_loss improved from 0.63618 to 0.63567, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 93s 540us/step - loss: 0.6423 - acc: 0.6235 - val_loss: 0.6357 - val_acc: 0.6321\n",
      "Epoch 20/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6419 - acc: 0.6231Epoch 00020: val_loss improved from 0.63567 to 0.63438, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 92s 535us/step - loss: 0.6419 - acc: 0.6232 - val_loss: 0.6344 - val_acc: 0.6328\n",
      "Epoch 21/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6412 - acc: 0.6256Epoch 00021: val_loss improved from 0.63438 to 0.63351, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 91s 531us/step - loss: 0.6414 - acc: 0.6255 - val_loss: 0.6335 - val_acc: 0.6364\n",
      "Epoch 22/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6408 - acc: 0.6254Epoch 00022: val_loss did not improve\n",
      "171945/171945 [==============================] - 91s 529us/step - loss: 0.6407 - acc: 0.6254 - val_loss: 0.6335 - val_acc: 0.6356\n",
      "Epoch 23/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6395 - acc: 0.6281Epoch 00023: val_loss improved from 0.63351 to 0.63240, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 91s 528us/step - loss: 0.6395 - acc: 0.6279 - val_loss: 0.6324 - val_acc: 0.6390\n",
      "Epoch 24/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6390 - acc: 0.6294Epoch 00024: val_loss improved from 0.63240 to 0.63122, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 92s 536us/step - loss: 0.6390 - acc: 0.6295 - val_loss: 0.6312 - val_acc: 0.6383\n",
      "Epoch 25/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6385 - acc: 0.6285Epoch 00025: val_loss did not improve\n",
      "171945/171945 [==============================] - 96s 557us/step - loss: 0.6385 - acc: 0.6286 - val_loss: 0.6317 - val_acc: 0.6389\n",
      "Epoch 26/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6376 - acc: 0.6314Epoch 00026: val_loss improved from 0.63122 to 0.63071, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 96s 560us/step - loss: 0.6377 - acc: 0.6313 - val_loss: 0.6307 - val_acc: 0.6407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6380 - acc: 0.6297Epoch 00027: val_loss improved from 0.63071 to 0.63014, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 91s 530us/step - loss: 0.6379 - acc: 0.6298 - val_loss: 0.6301 - val_acc: 0.6390\n",
      "Epoch 28/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6364 - acc: 0.6310Epoch 00028: val_loss did not improve\n",
      "171945/171945 [==============================] - 91s 527us/step - loss: 0.6364 - acc: 0.6309 - val_loss: 0.6315 - val_acc: 0.6409\n",
      "Epoch 29/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6363 - acc: 0.6324Epoch 00029: val_loss improved from 0.63014 to 0.62954, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6363 - acc: 0.6324 - val_loss: 0.6295 - val_acc: 0.6401\n",
      "Epoch 30/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6355 - acc: 0.6340Epoch 00030: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6354 - acc: 0.6341 - val_loss: 0.6301 - val_acc: 0.6413\n",
      "Epoch 31/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6351 - acc: 0.6341Epoch 00031: val_loss improved from 0.62954 to 0.62841, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6350 - acc: 0.6343 - val_loss: 0.6284 - val_acc: 0.6429\n",
      "Epoch 32/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6351 - acc: 0.6346Epoch 00032: val_loss improved from 0.62841 to 0.62779, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6350 - acc: 0.6348 - val_loss: 0.6278 - val_acc: 0.6422\n",
      "Epoch 33/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6338 - acc: 0.6358Epoch 00033: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6338 - acc: 0.6358 - val_loss: 0.6281 - val_acc: 0.6441\n",
      "Epoch 34/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6333 - acc: 0.6370Epoch 00034: val_loss improved from 0.62779 to 0.62741, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6334 - acc: 0.6367 - val_loss: 0.6274 - val_acc: 0.6451\n",
      "Epoch 35/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6326 - acc: 0.6381Epoch 00035: val_loss improved from 0.62741 to 0.62726, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 91s 532us/step - loss: 0.6324 - acc: 0.6381 - val_loss: 0.6273 - val_acc: 0.6462\n",
      "Epoch 36/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6324 - acc: 0.6380Epoch 00036: val_loss improved from 0.62726 to 0.62594, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 91s 529us/step - loss: 0.6325 - acc: 0.6378 - val_loss: 0.6259 - val_acc: 0.6452\n",
      "Epoch 37/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6321 - acc: 0.6385Epoch 00037: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6321 - acc: 0.6384 - val_loss: 0.6274 - val_acc: 0.6446\n",
      "Epoch 38/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6317 - acc: 0.6393Epoch 00038: val_loss improved from 0.62594 to 0.62561, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6318 - acc: 0.6393 - val_loss: 0.6256 - val_acc: 0.6472\n",
      "Epoch 39/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6305 - acc: 0.6393Epoch 00039: val_loss improved from 0.62561 to 0.62356, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6306 - acc: 0.6391 - val_loss: 0.6236 - val_acc: 0.6484\n",
      "Epoch 40/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6302 - acc: 0.6414Epoch 00040: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6303 - acc: 0.6414 - val_loss: 0.6267 - val_acc: 0.6459\n",
      "Epoch 41/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6306 - acc: 0.6405Epoch 00041: val_loss improved from 0.62356 to 0.62338, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6306 - acc: 0.6405 - val_loss: 0.6234 - val_acc: 0.6509\n",
      "Epoch 42/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6296 - acc: 0.6414Epoch 00042: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6296 - acc: 0.6414 - val_loss: 0.6236 - val_acc: 0.6508\n",
      "Epoch 43/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6293 - acc: 0.6421Epoch 00043: val_loss improved from 0.62338 to 0.62324, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6293 - acc: 0.6420 - val_loss: 0.6232 - val_acc: 0.6520\n",
      "Epoch 44/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6285 - acc: 0.6443Epoch 00044: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6284 - acc: 0.6444 - val_loss: 0.6239 - val_acc: 0.6496\n",
      "Epoch 45/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6279 - acc: 0.6445Epoch 00045: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6280 - acc: 0.6445 - val_loss: 0.6236 - val_acc: 0.6495\n",
      "Epoch 46/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6276 - acc: 0.6440Epoch 00046: val_loss improved from 0.62324 to 0.62304, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6276 - acc: 0.6441 - val_loss: 0.6230 - val_acc: 0.6531\n",
      "Epoch 47/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6266 - acc: 0.6457Epoch 00047: val_loss improved from 0.62304 to 0.62301, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6265 - acc: 0.6459 - val_loss: 0.6230 - val_acc: 0.6483\n",
      "Epoch 48/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6271 - acc: 0.6447Epoch 00048: val_loss improved from 0.62301 to 0.62210, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6271 - acc: 0.6447 - val_loss: 0.6221 - val_acc: 0.6512\n",
      "Epoch 49/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6269 - acc: 0.6457Epoch 00049: val_loss improved from 0.62210 to 0.62066, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6271 - acc: 0.6455 - val_loss: 0.6207 - val_acc: 0.6526\n",
      "Epoch 50/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6256 - acc: 0.6470Epoch 00050: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6257 - acc: 0.6469 - val_loss: 0.6210 - val_acc: 0.6546\n",
      "Epoch 51/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6262 - acc: 0.6450Epoch 00051: val_loss improved from 0.62066 to 0.61945, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 91s 527us/step - loss: 0.6262 - acc: 0.6449 - val_loss: 0.6194 - val_acc: 0.6563\n",
      "Epoch 52/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6255 - acc: 0.6475Epoch 00052: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6255 - acc: 0.6475 - val_loss: 0.6204 - val_acc: 0.6550\n",
      "Epoch 53/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6247 - acc: 0.6482Epoch 00053: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6245 - acc: 0.6485 - val_loss: 0.6199 - val_acc: 0.6547\n",
      "Epoch 54/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6249 - acc: 0.6475Epoch 00054: val_loss improved from 0.61945 to 0.61900, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 92s 532us/step - loss: 0.6249 - acc: 0.6475 - val_loss: 0.6190 - val_acc: 0.6571\n",
      "Epoch 55/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6245 - acc: 0.6493Epoch 00055: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6245 - acc: 0.6493 - val_loss: 0.6193 - val_acc: 0.6573\n",
      "Epoch 56/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6244 - acc: 0.6488Epoch 00056: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6243 - acc: 0.6488 - val_loss: 0.6203 - val_acc: 0.6537\n",
      "Epoch 57/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6229 - acc: 0.6500Epoch 00057: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6232 - acc: 0.6497 - val_loss: 0.6191 - val_acc: 0.6553\n",
      "Epoch 58/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6235 - acc: 0.6483Epoch 00058: val_loss improved from 0.61900 to 0.61769, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6235 - acc: 0.6483 - val_loss: 0.6177 - val_acc: 0.6593\n",
      "Epoch 59/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6224 - acc: 0.6509Epoch 00059: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6223 - acc: 0.6510 - val_loss: 0.6192 - val_acc: 0.6555\n",
      "Epoch 60/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6226 - acc: 0.6510Epoch 00060: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6225 - acc: 0.6511 - val_loss: 0.6213 - val_acc: 0.6552\n",
      "Epoch 61/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6214 - acc: 0.6513Epoch 00061: val_loss improved from 0.61769 to 0.61720, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6215 - acc: 0.6512 - val_loss: 0.6172 - val_acc: 0.6573\n",
      "Epoch 62/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6227 - acc: 0.6500Epoch 00062: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6228 - acc: 0.6499 - val_loss: 0.6198 - val_acc: 0.6534\n",
      "Epoch 63/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6226 - acc: 0.6505Epoch 00063: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6225 - acc: 0.6506 - val_loss: 0.6197 - val_acc: 0.6571\n",
      "Epoch 64/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6219 - acc: 0.6511Epoch 00064: val_loss improved from 0.61720 to 0.61709, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6218 - acc: 0.6511 - val_loss: 0.6171 - val_acc: 0.6579\n",
      "Epoch 65/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6214 - acc: 0.6525Epoch 00065: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6213 - acc: 0.6525 - val_loss: 0.6198 - val_acc: 0.6544\n",
      "Epoch 66/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6205 - acc: 0.6527Epoch 00066: val_loss improved from 0.61709 to 0.61589, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6206 - acc: 0.6528 - val_loss: 0.6159 - val_acc: 0.6597\n",
      "Epoch 67/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6200 - acc: 0.6542Epoch 00067: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6200 - acc: 0.6541 - val_loss: 0.6169 - val_acc: 0.6569\n",
      "Epoch 68/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6202 - acc: 0.6537Epoch 00068: val_loss improved from 0.61589 to 0.61519, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6202 - acc: 0.6538 - val_loss: 0.6152 - val_acc: 0.6589\n",
      "Epoch 69/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6192 - acc: 0.6545Epoch 00069: val_loss improved from 0.61519 to 0.61503, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6191 - acc: 0.6547 - val_loss: 0.6150 - val_acc: 0.6574\n",
      "Epoch 70/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6189 - acc: 0.6558Epoch 00070: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6189 - acc: 0.6559 - val_loss: 0.6182 - val_acc: 0.6574\n",
      "Epoch 71/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6191 - acc: 0.6546Epoch 00071: val_loss did not improve\n",
      "171945/171945 [==============================] - 91s 527us/step - loss: 0.6191 - acc: 0.6548 - val_loss: 0.6168 - val_acc: 0.6589\n",
      "Epoch 72/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6185 - acc: 0.6551Epoch 00072: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6185 - acc: 0.6551 - val_loss: 0.6164 - val_acc: 0.6584\n",
      "Epoch 73/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6182 - acc: 0.6553Epoch 00073: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6183 - acc: 0.6551 - val_loss: 0.6165 - val_acc: 0.6574\n",
      "Epoch 74/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6170 - acc: 0.6560Epoch 00074: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6171 - acc: 0.6560 - val_loss: 0.6166 - val_acc: 0.6580\n",
      "Epoch 75/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6165 - acc: 0.6584Epoch 00075: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6166 - acc: 0.6582 - val_loss: 0.6158 - val_acc: 0.6584\n",
      "Epoch 76/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6174 - acc: 0.6564Epoch 00076: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 523us/step - loss: 0.6175 - acc: 0.6564 - val_loss: 0.6160 - val_acc: 0.6571\n",
      "Epoch 77/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6166 - acc: 0.6573Epoch 00077: val_loss improved from 0.61503 to 0.61492, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6165 - acc: 0.6573 - val_loss: 0.6149 - val_acc: 0.6607\n",
      "Epoch 78/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6170 - acc: 0.6559Epoch 00078: val_loss improved from 0.61492 to 0.61332, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6169 - acc: 0.6559 - val_loss: 0.6133 - val_acc: 0.6622\n",
      "Epoch 79/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6158 - acc: 0.6585Epoch 00079: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6160 - acc: 0.6582 - val_loss: 0.6139 - val_acc: 0.6597\n",
      "Epoch 80/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6166 - acc: 0.6569Epoch 00080: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6165 - acc: 0.6571 - val_loss: 0.6157 - val_acc: 0.6577\n",
      "Epoch 81/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6153 - acc: 0.6589Epoch 00081: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6151 - acc: 0.6592 - val_loss: 0.6160 - val_acc: 0.6566\n",
      "Epoch 82/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6159 - acc: 0.6590Epoch 00082: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6160 - acc: 0.6590 - val_loss: 0.6136 - val_acc: 0.6620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6149 - acc: 0.6598Epoch 00083: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6150 - acc: 0.6599 - val_loss: 0.6153 - val_acc: 0.6608\n",
      "Epoch 84/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6154 - acc: 0.6596Epoch 00084: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6154 - acc: 0.6596 - val_loss: 0.6138 - val_acc: 0.6599\n",
      "Epoch 85/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6145 - acc: 0.6605Epoch 00085: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 523us/step - loss: 0.6144 - acc: 0.6605 - val_loss: 0.6163 - val_acc: 0.6597\n",
      "Epoch 86/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6143 - acc: 0.6611Epoch 00086: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6143 - acc: 0.6610 - val_loss: 0.6141 - val_acc: 0.6619\n",
      "Epoch 87/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6146 - acc: 0.6585Epoch 00087: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6146 - acc: 0.6584 - val_loss: 0.6138 - val_acc: 0.6624\n",
      "Epoch 88/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6141 - acc: 0.6592Epoch 00088: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6141 - acc: 0.6594 - val_loss: 0.6140 - val_acc: 0.6604\n",
      "Epoch 89/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6134 - acc: 0.6607Epoch 00089: val_loss improved from 0.61332 to 0.61197, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6135 - acc: 0.6607 - val_loss: 0.6120 - val_acc: 0.6623\n",
      "Epoch 90/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6139 - acc: 0.6612Epoch 00090: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6141 - acc: 0.6609 - val_loss: 0.6129 - val_acc: 0.6615\n",
      "Epoch 91/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6133 - acc: 0.6608Epoch 00091: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6134 - acc: 0.6608 - val_loss: 0.6137 - val_acc: 0.6629\n",
      "Epoch 92/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6126 - acc: 0.6617Epoch 00092: val_loss improved from 0.61197 to 0.61077, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6127 - acc: 0.6615 - val_loss: 0.6108 - val_acc: 0.6646\n",
      "Epoch 93/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6129 - acc: 0.6618Epoch 00093: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6130 - acc: 0.6617 - val_loss: 0.6115 - val_acc: 0.6646\n",
      "Epoch 94/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6129 - acc: 0.6616Epoch 00094: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6131 - acc: 0.6614 - val_loss: 0.6118 - val_acc: 0.6639\n",
      "Epoch 95/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6131 - acc: 0.6619Epoch 00095: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6130 - acc: 0.6620 - val_loss: 0.6134 - val_acc: 0.6617\n",
      "Epoch 96/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6132 - acc: 0.6616Epoch 00096: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6132 - acc: 0.6615 - val_loss: 0.6114 - val_acc: 0.6641\n",
      "Epoch 97/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6126 - acc: 0.6620Epoch 00097: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6126 - acc: 0.6619 - val_loss: 0.6121 - val_acc: 0.6641\n",
      "Epoch 98/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6123 - acc: 0.6620Epoch 00098: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6122 - acc: 0.6620 - val_loss: 0.6124 - val_acc: 0.6633\n",
      "Epoch 99/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6121 - acc: 0.6627Epoch 00099: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 523us/step - loss: 0.6123 - acc: 0.6626 - val_loss: 0.6123 - val_acc: 0.6630\n",
      "Epoch 100/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6120 - acc: 0.6627Epoch 00100: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6120 - acc: 0.6627 - val_loss: 0.6134 - val_acc: 0.6613\n",
      "Epoch 101/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6120 - acc: 0.6635Epoch 00101: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6120 - acc: 0.6636 - val_loss: 0.6113 - val_acc: 0.6651\n",
      "Epoch 102/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6110 - acc: 0.6640Epoch 00102: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6111 - acc: 0.6640 - val_loss: 0.6111 - val_acc: 0.6661\n",
      "Epoch 103/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6100 - acc: 0.6658Epoch 00103: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6099 - acc: 0.6660 - val_loss: 0.6127 - val_acc: 0.6625\n",
      "Epoch 104/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6113 - acc: 0.6641Epoch 00104: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 523us/step - loss: 0.6115 - acc: 0.6639 - val_loss: 0.6136 - val_acc: 0.6604\n",
      "Epoch 105/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6110 - acc: 0.6642Epoch 00105: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6109 - acc: 0.6643 - val_loss: 0.6125 - val_acc: 0.6637\n",
      "Epoch 106/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6106 - acc: 0.6645Epoch 00106: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6107 - acc: 0.6644 - val_loss: 0.6118 - val_acc: 0.6638\n",
      "Epoch 107/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6111 - acc: 0.6631Epoch 00107: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6111 - acc: 0.6631 - val_loss: 0.6122 - val_acc: 0.6633\n",
      "Epoch 108/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6106 - acc: 0.6664Epoch 00108: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6106 - acc: 0.6664 - val_loss: 0.6109 - val_acc: 0.6646\n",
      "Epoch 109/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6094 - acc: 0.6644Epoch 00109: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6095 - acc: 0.6644 - val_loss: 0.6121 - val_acc: 0.6643\n",
      "Epoch 110/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6098 - acc: 0.6653Epoch 00110: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6099 - acc: 0.6652 - val_loss: 0.6109 - val_acc: 0.6638\n",
      "Epoch 111/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6095 - acc: 0.6658Epoch 00111: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6094 - acc: 0.6661 - val_loss: 0.6112 - val_acc: 0.6626\n",
      "Epoch 112/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6093 - acc: 0.6661Epoch 00112: val_loss improved from 0.61077 to 0.60994, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6092 - acc: 0.6661 - val_loss: 0.6099 - val_acc: 0.6658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6091 - acc: 0.6663Epoch 00113: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6089 - acc: 0.6664 - val_loss: 0.6115 - val_acc: 0.6637\n",
      "Epoch 114/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6091 - acc: 0.6652Epoch 00114: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6092 - acc: 0.6651 - val_loss: 0.6103 - val_acc: 0.6648\n",
      "Epoch 115/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6087 - acc: 0.6668Epoch 00115: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6088 - acc: 0.6667 - val_loss: 0.6124 - val_acc: 0.6617\n",
      "Epoch 116/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6089 - acc: 0.6659Epoch 00116: val_loss improved from 0.60994 to 0.60933, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6090 - acc: 0.6659 - val_loss: 0.6093 - val_acc: 0.6657\n",
      "Epoch 117/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6086 - acc: 0.6668Epoch 00117: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6086 - acc: 0.6667 - val_loss: 0.6099 - val_acc: 0.6658\n",
      "Epoch 118/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6084 - acc: 0.6671Epoch 00118: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6085 - acc: 0.6671 - val_loss: 0.6102 - val_acc: 0.6658\n",
      "Epoch 119/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6077 - acc: 0.6680Epoch 00119: val_loss improved from 0.60933 to 0.60879, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6077 - acc: 0.6681 - val_loss: 0.6088 - val_acc: 0.6668\n",
      "Epoch 120/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6083 - acc: 0.6662Epoch 00120: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6084 - acc: 0.6663 - val_loss: 0.6098 - val_acc: 0.6656\n",
      "Epoch 121/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6083 - acc: 0.6675Epoch 00121: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6083 - acc: 0.6675 - val_loss: 0.6109 - val_acc: 0.6635\n",
      "Epoch 122/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6081 - acc: 0.6663Epoch 00122: val_loss improved from 0.60879 to 0.60771, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6081 - acc: 0.6662 - val_loss: 0.6077 - val_acc: 0.6661\n",
      "Epoch 123/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6083 - acc: 0.6664Epoch 00123: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6085 - acc: 0.6662 - val_loss: 0.6087 - val_acc: 0.6659\n",
      "Epoch 124/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6085 - acc: 0.6677Epoch 00124: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6086 - acc: 0.6677 - val_loss: 0.6087 - val_acc: 0.6654\n",
      "Epoch 125/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6081 - acc: 0.6662Epoch 00125: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6081 - acc: 0.6663 - val_loss: 0.6089 - val_acc: 0.6670\n",
      "Epoch 126/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6073 - acc: 0.6692Epoch 00126: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6073 - acc: 0.6692 - val_loss: 0.6102 - val_acc: 0.6634\n",
      "Epoch 127/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6073 - acc: 0.6685Epoch 00127: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6075 - acc: 0.6684 - val_loss: 0.6100 - val_acc: 0.6659\n",
      "Epoch 128/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6070 - acc: 0.6685Epoch 00128: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6068 - acc: 0.6685 - val_loss: 0.6090 - val_acc: 0.6684\n",
      "Epoch 129/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6065 - acc: 0.6680Epoch 00129: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6065 - acc: 0.6681 - val_loss: 0.6096 - val_acc: 0.6645\n",
      "Epoch 130/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6069 - acc: 0.6690Epoch 00130: val_loss improved from 0.60771 to 0.60729, saving model to models/nn_50d_fixed.hdf5\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6069 - acc: 0.6690 - val_loss: 0.6073 - val_acc: 0.6684\n",
      "Epoch 131/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6070 - acc: 0.6680Epoch 00131: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6072 - acc: 0.6680 - val_loss: 0.6074 - val_acc: 0.6683\n",
      "Epoch 132/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6067 - acc: 0.6689Epoch 00132: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6064 - acc: 0.6693 - val_loss: 0.6095 - val_acc: 0.6652\n",
      "Epoch 133/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6064 - acc: 0.6688Epoch 00133: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6064 - acc: 0.6688 - val_loss: 0.6092 - val_acc: 0.6664\n",
      "Epoch 134/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6063 - acc: 0.6692Epoch 00134: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6063 - acc: 0.6692 - val_loss: 0.6094 - val_acc: 0.6661\n",
      "Epoch 135/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6057 - acc: 0.6694Epoch 00135: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6056 - acc: 0.6695 - val_loss: 0.6101 - val_acc: 0.6653\n",
      "Epoch 136/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6056 - acc: 0.6693Epoch 00136: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6055 - acc: 0.6694 - val_loss: 0.6112 - val_acc: 0.6644\n",
      "Epoch 137/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6058 - acc: 0.6695Epoch 00137: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6058 - acc: 0.6694 - val_loss: 0.6085 - val_acc: 0.6673\n",
      "Epoch 138/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6051 - acc: 0.6698Epoch 00138: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6051 - acc: 0.6696 - val_loss: 0.6091 - val_acc: 0.6663\n",
      "Epoch 139/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6059 - acc: 0.6698Epoch 00139: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6060 - acc: 0.6697 - val_loss: 0.6085 - val_acc: 0.6662\n",
      "Epoch 140/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6050 - acc: 0.6707Epoch 00140: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6051 - acc: 0.6707 - val_loss: 0.6077 - val_acc: 0.6670\n",
      "Epoch 141/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6048 - acc: 0.6706Epoch 00141: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6047 - acc: 0.6708 - val_loss: 0.6087 - val_acc: 0.6680\n",
      "Epoch 142/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6058 - acc: 0.6688Epoch 00142: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6056 - acc: 0.6690 - val_loss: 0.6092 - val_acc: 0.6649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6050 - acc: 0.6703Epoch 00143: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6051 - acc: 0.6702 - val_loss: 0.6084 - val_acc: 0.6670\n",
      "Epoch 144/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6049 - acc: 0.6714Epoch 00144: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6049 - acc: 0.6714 - val_loss: 0.6083 - val_acc: 0.6680\n",
      "Epoch 145/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6048 - acc: 0.6713Epoch 00145: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6047 - acc: 0.6714 - val_loss: 0.6111 - val_acc: 0.6638\n",
      "Epoch 146/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6040 - acc: 0.6719Epoch 00146: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6042 - acc: 0.6717 - val_loss: 0.6088 - val_acc: 0.6674\n",
      "Epoch 147/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6040 - acc: 0.6707Epoch 00147: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 526us/step - loss: 0.6039 - acc: 0.6707 - val_loss: 0.6097 - val_acc: 0.6641\n",
      "Epoch 148/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6046 - acc: 0.6704Epoch 00148: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6046 - acc: 0.6703 - val_loss: 0.6101 - val_acc: 0.6646\n",
      "Epoch 149/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6045 - acc: 0.6709Epoch 00149: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6045 - acc: 0.6709 - val_loss: 0.6090 - val_acc: 0.6649\n",
      "Epoch 150/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6044 - acc: 0.6703Epoch 00150: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6046 - acc: 0.6702 - val_loss: 0.6093 - val_acc: 0.6648\n",
      "Epoch 151/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6040 - acc: 0.6723Epoch 00151: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6040 - acc: 0.6725 - val_loss: 0.6087 - val_acc: 0.6664\n",
      "Epoch 152/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6038 - acc: 0.6703Epoch 00152: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 524us/step - loss: 0.6038 - acc: 0.6704 - val_loss: 0.6086 - val_acc: 0.6672\n",
      "Epoch 153/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6039 - acc: 0.6716Epoch 00153: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6040 - acc: 0.6715 - val_loss: 0.6100 - val_acc: 0.6654\n",
      "Epoch 154/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6044 - acc: 0.6707Epoch 00154: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6043 - acc: 0.6708 - val_loss: 0.6082 - val_acc: 0.6686\n",
      "Epoch 155/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6039 - acc: 0.6714Epoch 00155: val_loss did not improve\n",
      "171945/171945 [==============================] - 90s 525us/step - loss: 0.6040 - acc: 0.6713 - val_loss: 0.6091 - val_acc: 0.6663\n",
      "Epoch 00155: early stopping\n",
      "Wall time: 3h 55min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#now train\n",
    "history50_fixed = nn.run_model(model=model50_fixed, out_path=\"models/nn_50d_fixed.hdf5\", **run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Train 300d model with fixed embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second model 300 dimensionhal word embeddings. However the number of hidden units is decreases in order mtianta  aprocaml the same number of trainable paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "joke_seq (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 300)          8218800   \n",
      "_________________________________________________________________\n",
      "mask_paddings (Masking)      (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "drop_words (SpatialDropout1D (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "mask_dropped_words (Masking) (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "reccurrent_layer (LSTM)      (None, 150)               270600    \n",
      "_________________________________________________________________\n",
      "drop_dense (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_sigmoid (Dense)        (None, 75)                11325     \n",
      "_________________________________________________________________\n",
      "avg_pred (GlobalAverage)     (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,500,725\n",
      "Trainable params: 281,925\n",
      "Non-trainable params: 8,218,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM, average final\n",
    "model300_fixed = nn.create_model(embedding_matrix=embedding_matrix300, n_hidden=150)\n",
    "model300_fixed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171945 samples, validate on 24564 samples\n",
      "Epoch 1/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6592 - acc: 0.6018Epoch 00001: val_loss improved from inf to 0.64760, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 143s 834us/step - loss: 0.6592 - acc: 0.6016 - val_loss: 0.6476 - val_acc: 0.6214\n",
      "Epoch 2/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6500 - acc: 0.6155Epoch 00002: val_loss improved from 0.64760 to 0.64185, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.6501 - acc: 0.6154 - val_loss: 0.6419 - val_acc: 0.6242\n",
      "Epoch 3/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6433 - acc: 0.6244Epoch 00003: val_loss improved from 0.64185 to 0.63596, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.6431 - acc: 0.6245 - val_loss: 0.6360 - val_acc: 0.6354\n",
      "Epoch 4/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6398 - acc: 0.6277Epoch 00004: val_loss improved from 0.63596 to 0.63419, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 566us/step - loss: 0.6396 - acc: 0.6279 - val_loss: 0.6342 - val_acc: 0.6360\n",
      "Epoch 5/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6375 - acc: 0.6310Epoch 00005: val_loss improved from 0.63419 to 0.63255, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.6374 - acc: 0.6312 - val_loss: 0.6326 - val_acc: 0.6383\n",
      "Epoch 6/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6341 - acc: 0.6367Epoch 00006: val_loss improved from 0.63255 to 0.63020, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.6341 - acc: 0.6366 - val_loss: 0.6302 - val_acc: 0.6403\n",
      "Epoch 7/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6317 - acc: 0.6396Epoch 00007: val_loss improved from 0.63020 to 0.62823, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.6316 - acc: 0.6397 - val_loss: 0.6282 - val_acc: 0.6466\n",
      "Epoch 8/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6299 - acc: 0.6423Epoch 00008: val_loss improved from 0.62823 to 0.62721, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.6297 - acc: 0.6425 - val_loss: 0.6272 - val_acc: 0.6466\n",
      "Epoch 9/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6273 - acc: 0.6451Epoch 00009: val_loss improved from 0.62721 to 0.62461, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.6274 - acc: 0.6451 - val_loss: 0.6246 - val_acc: 0.6500\n",
      "Epoch 10/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6245 - acc: 0.6492Epoch 00010: val_loss improved from 0.62461 to 0.62332, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.6245 - acc: 0.6492 - val_loss: 0.6233 - val_acc: 0.6499\n",
      "Epoch 11/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6229 - acc: 0.6520Epoch 00011: val_loss improved from 0.62332 to 0.62168, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.6229 - acc: 0.6521 - val_loss: 0.6217 - val_acc: 0.6528\n",
      "Epoch 12/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6205 - acc: 0.6543Epoch 00012: val_loss improved from 0.62168 to 0.61898, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.6204 - acc: 0.6545 - val_loss: 0.6190 - val_acc: 0.6560\n",
      "Epoch 13/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6180 - acc: 0.6571Epoch 00013: val_loss improved from 0.61898 to 0.61861, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.6181 - acc: 0.6570 - val_loss: 0.6186 - val_acc: 0.6562\n",
      "Epoch 14/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6157 - acc: 0.6594Epoch 00014: val_loss improved from 0.61861 to 0.61851, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.6157 - acc: 0.6594 - val_loss: 0.6185 - val_acc: 0.6583\n",
      "Epoch 15/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6141 - acc: 0.6612Epoch 00015: val_loss improved from 0.61851 to 0.61617, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.6140 - acc: 0.6613 - val_loss: 0.6162 - val_acc: 0.6595\n",
      "Epoch 16/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6115 - acc: 0.6651Epoch 00016: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.6116 - acc: 0.6651 - val_loss: 0.6196 - val_acc: 0.6544\n",
      "Epoch 17/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6101 - acc: 0.6667Epoch 00017: val_loss improved from 0.61617 to 0.61458, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.6101 - acc: 0.6667 - val_loss: 0.6146 - val_acc: 0.6630\n",
      "Epoch 18/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6091 - acc: 0.6674Epoch 00018: val_loss improved from 0.61458 to 0.61383, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.6093 - acc: 0.6672 - val_loss: 0.6138 - val_acc: 0.6639\n",
      "Epoch 19/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6062 - acc: 0.6699Epoch 00019: val_loss improved from 0.61383 to 0.61273, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 566us/step - loss: 0.6063 - acc: 0.6700 - val_loss: 0.6127 - val_acc: 0.6637\n",
      "Epoch 20/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6039 - acc: 0.6714Epoch 00020: val_loss improved from 0.61273 to 0.61188, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.6041 - acc: 0.6712 - val_loss: 0.6119 - val_acc: 0.6640\n",
      "Epoch 21/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6035 - acc: 0.6722Epoch 00021: val_loss improved from 0.61188 to 0.61128, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.6035 - acc: 0.6721 - val_loss: 0.6113 - val_acc: 0.6667\n",
      "Epoch 22/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6014 - acc: 0.6747Epoch 00022: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.6014 - acc: 0.6748 - val_loss: 0.6113 - val_acc: 0.6662\n",
      "Epoch 23/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5997 - acc: 0.6783Epoch 00023: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5997 - acc: 0.6784 - val_loss: 0.6113 - val_acc: 0.6673\n",
      "Epoch 24/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5990 - acc: 0.6773Epoch 00024: val_loss improved from 0.61128 to 0.60974, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5990 - acc: 0.6772 - val_loss: 0.6097 - val_acc: 0.6672\n",
      "Epoch 25/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5959 - acc: 0.6796Epoch 00025: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5960 - acc: 0.6794 - val_loss: 0.6101 - val_acc: 0.6680\n",
      "Epoch 26/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5952 - acc: 0.6815Epoch 00026: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5951 - acc: 0.6816 - val_loss: 0.6101 - val_acc: 0.6695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5936 - acc: 0.6813Epoch 00027: val_loss improved from 0.60974 to 0.60952, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5938 - acc: 0.6812 - val_loss: 0.6095 - val_acc: 0.6679\n",
      "Epoch 28/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5921 - acc: 0.6845Epoch 00028: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5922 - acc: 0.6845 - val_loss: 0.6121 - val_acc: 0.6663\n",
      "Epoch 29/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5899 - acc: 0.6863Epoch 00029: val_loss improved from 0.60952 to 0.60647, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5899 - acc: 0.6861 - val_loss: 0.6065 - val_acc: 0.6707\n",
      "Epoch 30/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5883 - acc: 0.6868Epoch 00030: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5882 - acc: 0.6870 - val_loss: 0.6074 - val_acc: 0.6712\n",
      "Epoch 31/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5869 - acc: 0.6889Epoch 00031: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5870 - acc: 0.6889 - val_loss: 0.6077 - val_acc: 0.6692\n",
      "Epoch 32/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5863 - acc: 0.6885Epoch 00032: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5862 - acc: 0.6886 - val_loss: 0.6069 - val_acc: 0.6723\n",
      "Epoch 33/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5852 - acc: 0.6893Epoch 00033: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5854 - acc: 0.6892 - val_loss: 0.6077 - val_acc: 0.6723\n",
      "Epoch 34/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5842 - acc: 0.6908Epoch 00034: val_loss improved from 0.60647 to 0.60550, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5841 - acc: 0.6909 - val_loss: 0.6055 - val_acc: 0.6734\n",
      "Epoch 35/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5833 - acc: 0.6912Epoch 00035: val_loss improved from 0.60550 to 0.60433, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5832 - acc: 0.6913 - val_loss: 0.6043 - val_acc: 0.6765\n",
      "Epoch 36/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5811 - acc: 0.6942Epoch 00036: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5811 - acc: 0.6942 - val_loss: 0.6061 - val_acc: 0.6757\n",
      "Epoch 37/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5793 - acc: 0.6958Epoch 00037: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5796 - acc: 0.6955 - val_loss: 0.6052 - val_acc: 0.6733\n",
      "Epoch 38/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5778 - acc: 0.6965Epoch 00038: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5778 - acc: 0.6965 - val_loss: 0.6055 - val_acc: 0.6745\n",
      "Epoch 39/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5776 - acc: 0.6981Epoch 00039: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5775 - acc: 0.6983 - val_loss: 0.6074 - val_acc: 0.6751\n",
      "Epoch 40/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5764 - acc: 0.6992Epoch 00040: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5764 - acc: 0.6992 - val_loss: 0.6074 - val_acc: 0.6750\n",
      "Epoch 41/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5755 - acc: 0.6998Epoch 00041: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5756 - acc: 0.6996 - val_loss: 0.6058 - val_acc: 0.6751\n",
      "Epoch 42/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5746 - acc: 0.7007Epoch 00042: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5744 - acc: 0.7008 - val_loss: 0.6056 - val_acc: 0.6740\n",
      "Epoch 43/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5741 - acc: 0.7009Epoch 00043: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5742 - acc: 0.7009 - val_loss: 0.6059 - val_acc: 0.6756\n",
      "Epoch 44/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5721 - acc: 0.7022Epoch 00044: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5721 - acc: 0.7022 - val_loss: 0.6052 - val_acc: 0.6745\n",
      "Epoch 45/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5718 - acc: 0.7022Epoch 00045: val_loss improved from 0.60433 to 0.60278, saving model to models/nn_300d_fixed.hdf5\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5719 - acc: 0.7021 - val_loss: 0.6028 - val_acc: 0.6770\n",
      "Epoch 46/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5710 - acc: 0.7036Epoch 00046: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5712 - acc: 0.7035 - val_loss: 0.6058 - val_acc: 0.6768\n",
      "Epoch 47/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5689 - acc: 0.7047Epoch 00047: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5690 - acc: 0.7046 - val_loss: 0.6053 - val_acc: 0.6758\n",
      "Epoch 48/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5690 - acc: 0.7058Epoch 00048: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5689 - acc: 0.7059 - val_loss: 0.6040 - val_acc: 0.6761\n",
      "Epoch 49/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5680 - acc: 0.7060Epoch 00049: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5682 - acc: 0.7058 - val_loss: 0.6042 - val_acc: 0.6738\n",
      "Epoch 50/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5666 - acc: 0.7080Epoch 00050: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5664 - acc: 0.7082 - val_loss: 0.6099 - val_acc: 0.6728\n",
      "Epoch 51/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5653 - acc: 0.7087Epoch 00051: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5654 - acc: 0.7087 - val_loss: 0.6049 - val_acc: 0.6761\n",
      "Epoch 52/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5654 - acc: 0.7080Epoch 00052: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5654 - acc: 0.7079 - val_loss: 0.6070 - val_acc: 0.6753\n",
      "Epoch 53/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5638 - acc: 0.7094Epoch 00053: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5637 - acc: 0.7095 - val_loss: 0.6110 - val_acc: 0.6719\n",
      "Epoch 54/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5632 - acc: 0.7099Epoch 00054: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5631 - acc: 0.7100 - val_loss: 0.6053 - val_acc: 0.6762\n",
      "Epoch 55/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5613 - acc: 0.7119Epoch 00055: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5613 - acc: 0.7119 - val_loss: 0.6042 - val_acc: 0.6783\n",
      "Epoch 56/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5615 - acc: 0.7109Epoch 00056: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5614 - acc: 0.7108 - val_loss: 0.6066 - val_acc: 0.6749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5608 - acc: 0.7112Epoch 00057: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5609 - acc: 0.7110 - val_loss: 0.6075 - val_acc: 0.6760\n",
      "Epoch 58/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5598 - acc: 0.7129Epoch 00058: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5598 - acc: 0.7129 - val_loss: 0.6053 - val_acc: 0.6768\n",
      "Epoch 59/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5582 - acc: 0.7123Epoch 00059: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5582 - acc: 0.7123 - val_loss: 0.6069 - val_acc: 0.6764\n",
      "Epoch 60/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5577 - acc: 0.7141Epoch 00060: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5579 - acc: 0.7140 - val_loss: 0.6047 - val_acc: 0.6785\n",
      "Epoch 61/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5578 - acc: 0.7142Epoch 00061: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5579 - acc: 0.7141 - val_loss: 0.6039 - val_acc: 0.6780\n",
      "Epoch 62/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5565 - acc: 0.7153Epoch 00062: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5564 - acc: 0.7153 - val_loss: 0.6091 - val_acc: 0.6759\n",
      "Epoch 63/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5547 - acc: 0.7172Epoch 00063: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 564us/step - loss: 0.5549 - acc: 0.7169 - val_loss: 0.6064 - val_acc: 0.6788\n",
      "Epoch 64/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5556 - acc: 0.7161Epoch 00064: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5557 - acc: 0.7160 - val_loss: 0.6093 - val_acc: 0.6749\n",
      "Epoch 65/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5550 - acc: 0.7173Epoch 00065: val_loss did not improve\n",
      "171945/171945 [==============================] - 99s 574us/step - loss: 0.5550 - acc: 0.7173 - val_loss: 0.6072 - val_acc: 0.6777\n",
      "Epoch 66/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5542 - acc: 0.7162Epoch 00066: val_loss did not improve\n",
      "171945/171945 [==============================] - 98s 571us/step - loss: 0.5542 - acc: 0.7162 - val_loss: 0.6065 - val_acc: 0.6766\n",
      "Epoch 67/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5524 - acc: 0.7188Epoch 00067: val_loss did not improve\n",
      "171945/171945 [==============================] - 99s 574us/step - loss: 0.5525 - acc: 0.7187 - val_loss: 0.6073 - val_acc: 0.6791\n",
      "Epoch 68/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5526 - acc: 0.7179Epoch 00068: val_loss did not improve\n",
      "171945/171945 [==============================] - 99s 574us/step - loss: 0.5527 - acc: 0.7179 - val_loss: 0.6077 - val_acc: 0.6763\n",
      "Epoch 69/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5524 - acc: 0.7180Epoch 00069: val_loss did not improve\n",
      "171945/171945 [==============================] - 98s 573us/step - loss: 0.5523 - acc: 0.7181 - val_loss: 0.6058 - val_acc: 0.6781\n",
      "Epoch 70/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5509 - acc: 0.7197Epoch 00070: val_loss did not improve\n",
      "171945/171945 [==============================] - 97s 565us/step - loss: 0.5509 - acc: 0.7199 - val_loss: 0.6079 - val_acc: 0.6783\n",
      "Epoch 00070: early stopping\n",
      "Wall time: 1h 55min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#now train\n",
    "history300_fixed = nn.run_model(model=model300_fixed, out_path=\"models/nn_300d_fixed.hdf5\", **run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Train 50d model with trainable embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "joke_seq (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 50)           1369800   \n",
      "_________________________________________________________________\n",
      "mask_paddings (Masking)      (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "drop_words (SpatialDropout1D (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "mask_dropped_words (Masking) (None, 300, 50)           0         \n",
      "_________________________________________________________________\n",
      "reccurrent_layer (LSTM)      (None, 150)               120600    \n",
      "_________________________________________________________________\n",
      "drop_dense (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_sigmoid (Dense)        (None, 75)                11325     \n",
      "_________________________________________________________________\n",
      "avg_pred (GlobalAverage)     (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,501,725\n",
      "Trainable params: 1,501,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM, average final\n",
    "model50_trained = nn.create_model(embedding_matrix=embedding_matrix50, n_hidden=150, train_embed=True)\n",
    "model50_trained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171945 samples, validate on 24564 samples\n",
      "Epoch 1/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6729 - acc: 0.5784Epoch 00001: val_loss improved from inf to 0.65330, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 152s 886us/step - loss: 0.6728 - acc: 0.5787 - val_loss: 0.6533 - val_acc: 0.6074\n",
      "Epoch 2/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6614 - acc: 0.6025Epoch 00002: val_loss improved from 0.65330 to 0.64367, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 95s 550us/step - loss: 0.6614 - acc: 0.6023 - val_loss: 0.6437 - val_acc: 0.6231\n",
      "Epoch 3/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6555 - acc: 0.6106Epoch 00003: val_loss improved from 0.64367 to 0.64247, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 95s 550us/step - loss: 0.6555 - acc: 0.6106 - val_loss: 0.6425 - val_acc: 0.6285\n",
      "Epoch 4/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6521 - acc: 0.6168Epoch 00004: val_loss improved from 0.64247 to 0.63840, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6521 - acc: 0.6167 - val_loss: 0.6384 - val_acc: 0.6377\n",
      "Epoch 5/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6493 - acc: 0.6213Epoch 00005: val_loss improved from 0.63840 to 0.63438, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6494 - acc: 0.6213 - val_loss: 0.6344 - val_acc: 0.6402\n",
      "Epoch 6/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6474 - acc: 0.6254Epoch 00006: val_loss improved from 0.63438 to 0.63144, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 95s 550us/step - loss: 0.6475 - acc: 0.6252 - val_loss: 0.6314 - val_acc: 0.6470\n",
      "Epoch 7/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6471 - acc: 0.6245Epoch 00007: val_loss improved from 0.63144 to 0.63095, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 95s 550us/step - loss: 0.6471 - acc: 0.6245 - val_loss: 0.6310 - val_acc: 0.6486\n",
      "Epoch 8/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6432 - acc: 0.6317Epoch 00008: val_loss did not improve\n",
      "171945/171945 [==============================] - 95s 550us/step - loss: 0.6431 - acc: 0.6319 - val_loss: 0.6321 - val_acc: 0.6479\n",
      "Epoch 9/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6406 - acc: 0.6351Epoch 00009: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6404 - acc: 0.6353 - val_loss: 0.6327 - val_acc: 0.6485\n",
      "Epoch 10/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6385 - acc: 0.6372Epoch 00010: val_loss improved from 0.63095 to 0.63073, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 95s 551us/step - loss: 0.6386 - acc: 0.6370 - val_loss: 0.6307 - val_acc: 0.6512\n",
      "Epoch 11/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6381 - acc: 0.6373Epoch 00011: val_loss improved from 0.63073 to 0.63028, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6380 - acc: 0.6372 - val_loss: 0.6303 - val_acc: 0.6505\n",
      "Epoch 12/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6368 - acc: 0.6401Epoch 00012: val_loss did not improve\n",
      "171945/171945 [==============================] - 95s 550us/step - loss: 0.6370 - acc: 0.6399 - val_loss: 0.6317 - val_acc: 0.6510\n",
      "Epoch 13/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6352 - acc: 0.6423Epoch 00013: val_loss improved from 0.63028 to 0.63004, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 95s 550us/step - loss: 0.6352 - acc: 0.6425 - val_loss: 0.6300 - val_acc: 0.6542\n",
      "Epoch 14/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6320 - acc: 0.6462Epoch 00014: val_loss improved from 0.63004 to 0.62947, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 95s 550us/step - loss: 0.6320 - acc: 0.6462 - val_loss: 0.6295 - val_acc: 0.6534\n",
      "Epoch 15/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6325 - acc: 0.6456Epoch 00015: val_loss improved from 0.62947 to 0.62718, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6324 - acc: 0.6458 - val_loss: 0.6272 - val_acc: 0.6572\n",
      "Epoch 16/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6303 - acc: 0.6483Epoch 00016: val_loss improved from 0.62718 to 0.62382, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6303 - acc: 0.6484 - val_loss: 0.6238 - val_acc: 0.6589\n",
      "Epoch 17/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6296 - acc: 0.6498Epoch 00017: val_loss did not improve\n",
      "171945/171945 [==============================] - 95s 550us/step - loss: 0.6296 - acc: 0.6499 - val_loss: 0.6239 - val_acc: 0.6585\n",
      "Epoch 18/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6284 - acc: 0.6510Epoch 00018: val_loss improved from 0.62382 to 0.62360, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6284 - acc: 0.6509 - val_loss: 0.6236 - val_acc: 0.6577\n",
      "Epoch 19/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6284 - acc: 0.6502Epoch 00019: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6283 - acc: 0.6502 - val_loss: 0.6238 - val_acc: 0.6596\n",
      "Epoch 20/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6265 - acc: 0.6525Epoch 00020: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6266 - acc: 0.6524 - val_loss: 0.6246 - val_acc: 0.6602\n",
      "Epoch 21/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6249 - acc: 0.6545Epoch 00021: val_loss improved from 0.62360 to 0.62314, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6248 - acc: 0.6545 - val_loss: 0.6231 - val_acc: 0.6586\n",
      "Epoch 22/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6282 - acc: 0.6505Epoch 00022: val_loss improved from 0.62314 to 0.62252, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6283 - acc: 0.6503 - val_loss: 0.6225 - val_acc: 0.6614\n",
      "Epoch 23/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6269 - acc: 0.6532Epoch 00023: val_loss improved from 0.62252 to 0.62122, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6267 - acc: 0.6533 - val_loss: 0.6212 - val_acc: 0.6626\n",
      "Epoch 24/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6253 - acc: 0.6546Epoch 00024: val_loss improved from 0.62122 to 0.62062, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6253 - acc: 0.6546 - val_loss: 0.6206 - val_acc: 0.6636\n",
      "Epoch 25/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6241 - acc: 0.6555Epoch 00025: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6241 - acc: 0.6555 - val_loss: 0.6221 - val_acc: 0.6614\n",
      "Epoch 26/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6225 - acc: 0.6576Epoch 00026: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6225 - acc: 0.6577 - val_loss: 0.6217 - val_acc: 0.6637\n",
      "Epoch 27/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6204 - acc: 0.6607Epoch 00027: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6204 - acc: 0.6608 - val_loss: 0.6223 - val_acc: 0.6622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6207 - acc: 0.6600Epoch 00028: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6206 - acc: 0.6600 - val_loss: 0.6227 - val_acc: 0.6612\n",
      "Epoch 29/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6200 - acc: 0.6596Epoch 00029: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 547us/step - loss: 0.6199 - acc: 0.6596 - val_loss: 0.6233 - val_acc: 0.6622\n",
      "Epoch 30/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6193 - acc: 0.6613Epoch 00030: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6193 - acc: 0.6613 - val_loss: 0.6224 - val_acc: 0.6639\n",
      "Epoch 31/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6185 - acc: 0.6621Epoch 00031: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6185 - acc: 0.6622 - val_loss: 0.6237 - val_acc: 0.6647\n",
      "Epoch 32/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6176 - acc: 0.6637Epoch 00032: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6176 - acc: 0.6638 - val_loss: 0.6208 - val_acc: 0.6645\n",
      "Epoch 33/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6165 - acc: 0.6644Epoch 00033: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6164 - acc: 0.6646 - val_loss: 0.6212 - val_acc: 0.6655\n",
      "Epoch 34/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6156 - acc: 0.6657Epoch 00034: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6156 - acc: 0.6657 - val_loss: 0.6236 - val_acc: 0.6632\n",
      "Epoch 35/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6154 - acc: 0.6661Epoch 00035: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6156 - acc: 0.6658 - val_loss: 0.6222 - val_acc: 0.6645\n",
      "Epoch 36/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6146 - acc: 0.6670Epoch 00036: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6147 - acc: 0.6668 - val_loss: 0.6222 - val_acc: 0.6650\n",
      "Epoch 37/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6126 - acc: 0.6692Epoch 00037: val_loss improved from 0.62062 to 0.62059, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6127 - acc: 0.6691 - val_loss: 0.6206 - val_acc: 0.6654\n",
      "Epoch 38/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6136 - acc: 0.6679Epoch 00038: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6135 - acc: 0.6681 - val_loss: 0.6208 - val_acc: 0.6643\n",
      "Epoch 39/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6124 - acc: 0.6700Epoch 00039: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 547us/step - loss: 0.6124 - acc: 0.6700 - val_loss: 0.6207 - val_acc: 0.6654\n",
      "Epoch 40/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6111 - acc: 0.6710Epoch 00040: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6113 - acc: 0.6708 - val_loss: 0.6220 - val_acc: 0.6657\n",
      "Epoch 41/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6102 - acc: 0.6709Epoch 00041: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6102 - acc: 0.6709 - val_loss: 0.6213 - val_acc: 0.6645\n",
      "Epoch 42/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6104 - acc: 0.6709Epoch 00042: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6103 - acc: 0.6710 - val_loss: 0.6224 - val_acc: 0.6657\n",
      "Epoch 43/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6092 - acc: 0.6722Epoch 00043: val_loss improved from 0.62059 to 0.62035, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6091 - acc: 0.6724 - val_loss: 0.6204 - val_acc: 0.6672\n",
      "Epoch 44/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6098 - acc: 0.6719Epoch 00044: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6096 - acc: 0.6721 - val_loss: 0.6248 - val_acc: 0.6666\n",
      "Epoch 45/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6099 - acc: 0.6717Epoch 00045: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6098 - acc: 0.6719 - val_loss: 0.6227 - val_acc: 0.6664\n",
      "Epoch 46/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6090 - acc: 0.6726Epoch 00046: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6090 - acc: 0.6726 - val_loss: 0.6209 - val_acc: 0.6667\n",
      "Epoch 47/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6081 - acc: 0.6739Epoch 00047: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6080 - acc: 0.6740 - val_loss: 0.6219 - val_acc: 0.6675\n",
      "Epoch 48/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6076 - acc: 0.6743Epoch 00048: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6076 - acc: 0.6744 - val_loss: 0.6218 - val_acc: 0.6684\n",
      "Epoch 49/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6069 - acc: 0.6748Epoch 00049: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6068 - acc: 0.6750 - val_loss: 0.6216 - val_acc: 0.6683\n",
      "Epoch 50/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6057 - acc: 0.6758Epoch 00050: val_loss improved from 0.62035 to 0.61771, saving model to models/nn_50d_trained.hdf5\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6060 - acc: 0.6755 - val_loss: 0.6177 - val_acc: 0.6699\n",
      "Epoch 51/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6055 - acc: 0.6759Epoch 00051: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6055 - acc: 0.6759 - val_loss: 0.6186 - val_acc: 0.6685\n",
      "Epoch 52/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6052 - acc: 0.6767Epoch 00052: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 547us/step - loss: 0.6050 - acc: 0.6768 - val_loss: 0.6199 - val_acc: 0.6692\n",
      "Epoch 53/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6035 - acc: 0.6776Epoch 00053: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6035 - acc: 0.6778 - val_loss: 0.6202 - val_acc: 0.6686\n",
      "Epoch 54/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6036 - acc: 0.6787Epoch 00054: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6037 - acc: 0.6786 - val_loss: 0.6221 - val_acc: 0.6687\n",
      "Epoch 55/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6035 - acc: 0.6783Epoch 00055: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6036 - acc: 0.6781 - val_loss: 0.6196 - val_acc: 0.6688\n",
      "Epoch 56/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.6791Epoch 00056: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6020 - acc: 0.6791 - val_loss: 0.6226 - val_acc: 0.6681\n",
      "Epoch 57/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.6795Epoch 00057: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6023 - acc: 0.6794 - val_loss: 0.6227 - val_acc: 0.6693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.6799Epoch 00058: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.6017 - acc: 0.6799 - val_loss: 0.6224 - val_acc: 0.6701\n",
      "Epoch 59/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6009 - acc: 0.6811Epoch 00059: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6007 - acc: 0.6813 - val_loss: 0.6209 - val_acc: 0.6710\n",
      "Epoch 60/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.6003 - acc: 0.6813Epoch 00060: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.6004 - acc: 0.6814 - val_loss: 0.6230 - val_acc: 0.6700\n",
      "Epoch 61/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5991 - acc: 0.6830Epoch 00061: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.5992 - acc: 0.6830 - val_loss: 0.6246 - val_acc: 0.6707\n",
      "Epoch 62/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5994 - acc: 0.6830Epoch 00062: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.5994 - acc: 0.6831 - val_loss: 0.6230 - val_acc: 0.6707\n",
      "Epoch 63/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5989 - acc: 0.6826Epoch 00063: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.5988 - acc: 0.6825 - val_loss: 0.6248 - val_acc: 0.6702\n",
      "Epoch 64/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5982 - acc: 0.6842Epoch 00064: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.5983 - acc: 0.6841 - val_loss: 0.6216 - val_acc: 0.6697\n",
      "Epoch 65/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5975 - acc: 0.6836Epoch 00065: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.5975 - acc: 0.6837 - val_loss: 0.6199 - val_acc: 0.6711\n",
      "Epoch 66/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5969 - acc: 0.6833Epoch 00066: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.5967 - acc: 0.6835 - val_loss: 0.6224 - val_acc: 0.6710\n",
      "Epoch 67/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5969 - acc: 0.6843Epoch 00067: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.5969 - acc: 0.6845 - val_loss: 0.6215 - val_acc: 0.6722\n",
      "Epoch 68/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5967 - acc: 0.6843Epoch 00068: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 550us/step - loss: 0.5965 - acc: 0.6844 - val_loss: 0.6232 - val_acc: 0.6723\n",
      "Epoch 69/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5955 - acc: 0.6854Epoch 00069: val_loss did not improve\n",
      "171945/171945 [==============================] - 95s 550us/step - loss: 0.5955 - acc: 0.6854 - val_loss: 0.6197 - val_acc: 0.6717\n",
      "Epoch 70/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5940 - acc: 0.6877Epoch 00070: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.5940 - acc: 0.6877 - val_loss: 0.6215 - val_acc: 0.6713\n",
      "Epoch 71/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5944 - acc: 0.6873Epoch 00071: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.5943 - acc: 0.6873 - val_loss: 0.6201 - val_acc: 0.6704\n",
      "Epoch 72/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5936 - acc: 0.6879Epoch 00072: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.5937 - acc: 0.6877 - val_loss: 0.6254 - val_acc: 0.6694\n",
      "Epoch 73/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5952 - acc: 0.6859Epoch 00073: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.5952 - acc: 0.6860 - val_loss: 0.6233 - val_acc: 0.6707\n",
      "Epoch 74/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5931 - acc: 0.6878Epoch 00074: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 548us/step - loss: 0.5931 - acc: 0.6877 - val_loss: 0.6245 - val_acc: 0.6723\n",
      "Epoch 75/1000\n",
      "170000/171945 [============================>.] - ETA: 0s - loss: 0.5939 - acc: 0.6876Epoch 00075: val_loss did not improve\n",
      "171945/171945 [==============================] - 94s 549us/step - loss: 0.5939 - acc: 0.6876 - val_loss: 0.6215 - val_acc: 0.6718\n",
      "Epoch 00075: early stopping\n",
      "Wall time: 1h 59min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history50_trained = nn.run_model(model=model50_trained, out_path=\"models/nn_50d_trained.hdf5\",**run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5 - Train 300d model with trainable embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "joke_seq (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 300)          8218800   \n",
      "_________________________________________________________________\n",
      "mask_paddings (Masking)      (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "drop_words (SpatialDropout1D (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "mask_dropped_words (Masking) (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "reccurrent_layer (LSTM)      (None, 150)               270600    \n",
      "_________________________________________________________________\n",
      "drop_dense (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_sigmoid (Dense)        (None, 75)                11325     \n",
      "_________________________________________________________________\n",
      "avg_pred (GlobalAverage)     (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,500,725\n",
      "Trainable params: 8,500,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM, average final\n",
    "model300_trained = nn.create_model(embedding_matrix=embedding_matrix300, n_hidden=150, train_embed=True)\n",
    "model300_trained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171945 samples, validate on 24564 samples\n",
      "Epoch 1/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6627 - acc: 0.5973Epoch 00001: val_loss improved from inf to 0.64236, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 173s 1ms/step - loss: 0.6626 - acc: 0.5975 - val_loss: 0.6424 - val_acc: 0.6341\n",
      "Epoch 2/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6435 - acc: 0.6316Epoch 00002: val_loss improved from 0.64236 to 0.63137, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 108s 627us/step - loss: 0.6434 - acc: 0.6317 - val_loss: 0.6314 - val_acc: 0.6519\n",
      "Epoch 3/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6299 - acc: 0.6502Epoch 00003: val_loss improved from 0.63137 to 0.62617, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.6298 - acc: 0.6503 - val_loss: 0.6262 - val_acc: 0.6617\n",
      "Epoch 4/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6234 - acc: 0.6584Epoch 00004: val_loss improved from 0.62617 to 0.62221, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 108s 627us/step - loss: 0.6235 - acc: 0.6582 - val_loss: 0.6222 - val_acc: 0.6634\n",
      "Epoch 5/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6167 - acc: 0.6658Epoch 00005: val_loss improved from 0.62221 to 0.61895, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 108s 627us/step - loss: 0.6167 - acc: 0.6658 - val_loss: 0.6190 - val_acc: 0.6690\n",
      "Epoch 6/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6124 - acc: 0.6701Epoch 00006: val_loss did not improve\n",
      "171945/171945 [==============================] - 107s 625us/step - loss: 0.6122 - acc: 0.6702 - val_loss: 0.6198 - val_acc: 0.6702\n",
      "Epoch 7/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6070 - acc: 0.6750Epoch 00007: val_loss improved from 0.61895 to 0.61872, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 108s 627us/step - loss: 0.6071 - acc: 0.6748 - val_loss: 0.6187 - val_acc: 0.6711\n",
      "Epoch 8/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.6029 - acc: 0.6795Epoch 00008: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.6030 - acc: 0.6795 - val_loss: 0.6234 - val_acc: 0.6700\n",
      "Epoch 9/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5996 - acc: 0.6821Epoch 00009: val_loss improved from 0.61872 to 0.61851, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 108s 628us/step - loss: 0.5995 - acc: 0.6822 - val_loss: 0.6185 - val_acc: 0.6722\n",
      "Epoch 10/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5966 - acc: 0.6843Epoch 00010: val_loss improved from 0.61851 to 0.61675, saving model to models/nn_300d_trained.hdf5\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5966 - acc: 0.6843 - val_loss: 0.6167 - val_acc: 0.6745\n",
      "Epoch 11/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5935 - acc: 0.6867Epoch 00011: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5937 - acc: 0.6864 - val_loss: 0.6214 - val_acc: 0.6748\n",
      "Epoch 12/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5903 - acc: 0.6906Epoch 00012: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5904 - acc: 0.6906 - val_loss: 0.6272 - val_acc: 0.6735\n",
      "Epoch 13/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5874 - acc: 0.6933Epoch 00013: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5876 - acc: 0.6930 - val_loss: 0.6238 - val_acc: 0.6716\n",
      "Epoch 14/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5858 - acc: 0.6936Epoch 00014: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 627us/step - loss: 0.5858 - acc: 0.6937 - val_loss: 0.6262 - val_acc: 0.6722\n",
      "Epoch 15/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5832 - acc: 0.6973Epoch 00015: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5830 - acc: 0.6973 - val_loss: 0.6290 - val_acc: 0.6718\n",
      "Epoch 16/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5800 - acc: 0.6998Epoch 00016: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5801 - acc: 0.6998 - val_loss: 0.6329 - val_acc: 0.6722\n",
      "Epoch 17/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5786 - acc: 0.7009Epoch 00017: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 625us/step - loss: 0.5787 - acc: 0.7008 - val_loss: 0.6279 - val_acc: 0.6724\n",
      "Epoch 18/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5754 - acc: 0.7033Epoch 00018: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 625us/step - loss: 0.5755 - acc: 0.7032 - val_loss: 0.6319 - val_acc: 0.6737\n",
      "Epoch 19/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5730 - acc: 0.7049Epoch 00019: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5731 - acc: 0.7048 - val_loss: 0.6264 - val_acc: 0.6738\n",
      "Epoch 20/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5719 - acc: 0.7054Epoch 00020: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5718 - acc: 0.7055 - val_loss: 0.6311 - val_acc: 0.6727\n",
      "Epoch 21/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5692 - acc: 0.7079Epoch 00021: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 627us/step - loss: 0.5693 - acc: 0.7080 - val_loss: 0.6309 - val_acc: 0.6740\n",
      "Epoch 22/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5677 - acc: 0.7085Epoch 00022: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5677 - acc: 0.7086 - val_loss: 0.6323 - val_acc: 0.6725\n",
      "Epoch 23/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5645 - acc: 0.7123Epoch 00023: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5644 - acc: 0.7123 - val_loss: 0.6349 - val_acc: 0.6731\n",
      "Epoch 24/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5635 - acc: 0.7126Epoch 00024: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 627us/step - loss: 0.5637 - acc: 0.7124 - val_loss: 0.6328 - val_acc: 0.6727\n",
      "Epoch 25/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5615 - acc: 0.7139Epoch 00025: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5615 - acc: 0.7139 - val_loss: 0.6298 - val_acc: 0.6733\n",
      "Epoch 26/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5605 - acc: 0.7141Epoch 00026: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 627us/step - loss: 0.5606 - acc: 0.7141 - val_loss: 0.6400 - val_acc: 0.6723\n",
      "Epoch 27/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5586 - acc: 0.7158Epoch 00027: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5586 - acc: 0.7158 - val_loss: 0.6381 - val_acc: 0.6736\n",
      "Epoch 28/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5550 - acc: 0.7179Epoch 00028: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5550 - acc: 0.7179 - val_loss: 0.6405 - val_acc: 0.6730\n",
      "Epoch 29/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5547 - acc: 0.7183Epoch 00029: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5545 - acc: 0.7185 - val_loss: 0.6386 - val_acc: 0.6745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5517 - acc: 0.7211Epoch 00030: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5518 - acc: 0.7209 - val_loss: 0.6446 - val_acc: 0.6742\n",
      "Epoch 31/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5510 - acc: 0.7208Epoch 00031: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 627us/step - loss: 0.5512 - acc: 0.7207 - val_loss: 0.6472 - val_acc: 0.6751\n",
      "Epoch 32/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5485 - acc: 0.7221Epoch 00032: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5484 - acc: 0.7222 - val_loss: 0.6429 - val_acc: 0.6760\n",
      "Epoch 33/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5469 - acc: 0.7247Epoch 00033: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5467 - acc: 0.7248 - val_loss: 0.6479 - val_acc: 0.6753\n",
      "Epoch 34/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5452 - acc: 0.7259Epoch 00034: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5455 - acc: 0.7257 - val_loss: 0.6509 - val_acc: 0.6756\n",
      "Epoch 35/1000\n",
      "170000/171945 [============================>.] - ETA: 1s - loss: 0.5433 - acc: 0.7280Epoch 00035: val_loss did not improve\n",
      "171945/171945 [==============================] - 108s 626us/step - loss: 0.5434 - acc: 0.7279 - val_loss: 0.6481 - val_acc: 0.6746\n",
      "Epoch 00035: early stopping\n",
      "Wall time: 1h 4min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history300_trained = nn.run_model(model=model300_trained, out_path=\"models/nn_300d_trained.hdf5\", **run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 -  Analyze Best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
