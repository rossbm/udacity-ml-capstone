{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Prelim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages and run requisite tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import luigi\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV, LassoLarsCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk import word_tokenize\n",
    "PROJECT_DIR = os.path.join(os.getcwd(), os.pardir)\n",
    "os.chdir(PROJECT_DIR)\n",
    "from src.data.clean import CleanData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Checking if CleanData() is complete\n",
      "INFO: Informed scheduler that task   CleanData__99914b932b   has status   DONE\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Done\n",
      "DEBUG: There are no more tasks to run at this time\n",
      "INFO: Worker Worker(salt=278942626, workers=1, host=DESKTOP-6UJS098, username=wertu, pid=8132) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 1 tasks of which:\n",
      "* 1 present dependencies were encountered:\n",
      "    - 1 CleanData()\n",
      "\n",
      "Did not run any tasks\n",
      "This progress looks :) because there were no failed tasks or missing external dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook will train a baseline linear logistic regression model. The features will be created using the bag of words technique. This means that the input will be known as a document term matrix. The document term matrix will be weighted using term frequency-inverse document (tf-idf) scaling.\n",
    "\n",
    "The logistic regression will be regularized using the l2 norm. This means that a penalty will be applied to the l2 norm of the coefficients. This will shrink the coeficent towds 0 and towards each other. The use of the l2 penalty in a regresion is also known as ridge regression. The optimal regularization penalty will be determined by 10 fold cross validation. In addition to using cross-fold validation to determine the regularization strnegth, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Prep the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This luigi task ensures that the cleaned train and test sets are available.\n",
    "luigi.build([CleanData()], local_scheduler = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "train = joblib.load('data/interim/train.pkl')\n",
    "test = joblib.load('data/interim/test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram selection through cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_dtm(ngram_range):\n",
    "    tfidf = TfidfVectorizer(analyzer = 'word', ngram_range = (1,ngram_range+1), max_df = 0.8, min_df = 5)\n",
    "    dtm_train = tfidf.fit_transform(train.full_text)\n",
    "    vocab_len = len(tfidf.vocabulary_)\n",
    "    print(\"DTM {} has {} words\".format(ngram_range, vocab_len))\n",
    "    mdl = LogisticRegressionCV(cv = 10, solver = 'lbfgs', max_iter=1000, n_jobs = 2,\n",
    "                                   verbose = True, random_state = 10222017)\n",
    "    mdl.fit(dtm_train, train.funny)\n",
    "    \n",
    "    return pd.DataFrame(mdl.scores_[True]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngram_cv(ngram_range):\n",
    "    ngram_results = {}\n",
    "    for i in range(ngram_range):\n",
    "        print(\"Starting DTM {}\".format(i))\n",
    "        reg_results = validate_dtm(i)\n",
    "        ngram_results[i] = reg_results\n",
    "    return ngram_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DTM 0\n",
      "DTM 0 has 26667 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed: 16.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DTM 1\n",
      "DTM 1 has 223483 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed: 53.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DTM 2\n",
      "DTM 2 has 472114 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed: 82.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DTM 3\n",
      "DTM 3 has 654041 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed: 103.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DTM 4\n",
      "DTM 4 has 792235 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed: 119.6min finished\n"
     ]
    }
   ],
   "source": [
    "results = ngram_cv(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0    0.538029\n",
       " 1    0.600718\n",
       " 2    0.611911\n",
       " 3    0.634725\n",
       " 4    0.661174\n",
       " 5    0.664074\n",
       " 6    0.655812\n",
       " 7    0.649206\n",
       " 8    0.645745\n",
       " 9    0.644843\n",
       " dtype: float64, 1: 0    0.513502\n",
       " 1    0.592812\n",
       " 2    0.605269\n",
       " 3    0.633961\n",
       " 4    0.676118\n",
       " 5    0.685680\n",
       " 6    0.666393\n",
       " 7    0.645414\n",
       " 8    0.633573\n",
       " 9    0.628308\n",
       " dtype: float64, 2: 0    0.513456\n",
       " 1    0.584642\n",
       " 2    0.601120\n",
       " 3    0.632426\n",
       " 4    0.677459\n",
       " 5    0.688051\n",
       " 6    0.670043\n",
       " 7    0.652799\n",
       " 8    0.643864\n",
       " 9    0.638645\n",
       " dtype: float64, 3: 0    0.513451\n",
       " 1    0.576374\n",
       " 2    0.598414\n",
       " 3    0.632630\n",
       " 4    0.678055\n",
       " 5    0.687668\n",
       " 6    0.670624\n",
       " 7    0.654430\n",
       " 8    0.645628\n",
       " 9    0.640719\n",
       " dtype: float64, 4: 0    0.513446\n",
       " 1    0.570482\n",
       " 2    0.597318\n",
       " 3    0.633884\n",
       " 4    0.678157\n",
       " 5    0.687464\n",
       " 6    0.670506\n",
       " 7    0.654772\n",
       " 8    0.646270\n",
       " 9    0.640429\n",
       " dtype: float64}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.features.dtm import CreateDTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "seems like  max_ngram of 3 is best...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.842301231227086"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log(470000,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685.5654600401044"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "470000 ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0014585106382978723"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(685.5/470000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4e-05"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(18.8/470000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "470000 * 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.05263157894737"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "685 / 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
